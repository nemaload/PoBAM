\input preamble
\addbibresource{pobam_.bib}

\title{Physical Principles for Scalable Neural Recording}

\author[1,2]{\ \lift{$\jointfirst\,$}Adam~H.~Marblestone\rlap{,}}
\author[3]{\lift{$\jointfirst\,$}Bradley~M.~Zamft\rlap{,}}
\author[3,4]{Yael~G.~Maguire\rlap{,}}
\author[5]{Mikhail~G.~Shapiro\rlap{,}}
\author[6]{Thaddeus~R.~Cybulski\rlap{,}}
\author[6]{Joshua~I.~Glaser\rlap{,}}
\author[3]{Ben~Stranges\rlap{,}}
\author[3]{Reza~Kalhor\rlap{,}}
\author[1,7,8]{David~A.~Dalrymple\rlap{,}}
\author[9]{Dongjin Seo\rlap{,}}
\author[9]{Elad Alon\rlap{,}}
\author[9]{Michel M. Maharbiz\rlap{,}}
\author[9]{Jose Carmena\rlap{,}}
\author[9]{Jan Rabaey\rlap{,}}
\author[$\jointlast$8,10]{Edward~S.~Boyden\rlap{,}}
\author[$\jointlast$1,2,3]{George~M.~Church\rlap{,}}
\author[$\jointlast$11,12]{Konrad~P.~Kording}

\affil[$\jointfirst$]{Joint first authors}
\affil[$\jointlast$]{Joint last authors}

\newcommand\et{{\em \&}}

\definecolor{deemph}{gray}{0.48}
\affil[1]{Biophysics {Program,} Harvard {Univ., Boston,~MA~02115, USA}}
\affil[2]{Wyss Institute {for Biologically Inspired Engineering at} Harvard {Univ., Boston,~MA~02115, USA}}
\affil[3]{{ Dept.\ of Genetics,} Harvard Medical School{, Boston,~MA~02115, USA}}
\affil[4]{Plum Labs LLC, Cambridge,~MA{~02142, USA}}
\affil[5]{Division of Chemistry and Chemical Engineering, California Institute of Technology{, Pasadena,~CA~91125, USA}}
\affil[6]{{Interdepartmental} Neuroscience {Program,} Northwestern Univ.{, Chicago,~IL~60611, USA}}
\affil[7]{Nemaload, San Francisco, CA{~94107, USA}}
\affil[8]{Media Lab{oratory,} Massachusetts Institute of Technology{, Cambridge,~MA~02139, USA}}
\affil[9]{{Dept.\ of} Electrical Engineering and Computer Science{, Univ. of California at} Berkeley{, Berkeley,~CA~94720, USA}}
\affil[10]{{Depts.\ of} Brain and Cognitive Sciences {\et\ of} Biological Engineering, Massachusetts Institute of Technology{, Cambridge,~MA~02139, USA}}
\affil[11]{{Depts.\ of} Physical Medicine and Rehabilitation {\et\ of} Physiology, Northwestern Univ.{\ Feinberg} School of Medicine{, Chicago,~IL~60611,~USA}}
\affil[12]{{Sensory Motor Performance Program,} The Rehabilitation Institute of Chicago{, Chicago,~IL~60611,~USA}}

\renewcommand{\maketitlehookc}{{\small\raggedright Correspondence to: \texttt{adam.h.marblestone\,\textnormal{(at)}\,\,gmail.com}}}

\begin{document}
\fontfamily{ugm}\selectfont
\maketitle
\pagestyle{plain}
\thispagestyle{empty}
%\captionwidth{0.8\linewidth}
%\changecaptionwidth

\begin{fquote}[Freeman Dyson][Imagined Worlds][1997]To understand in depth what is going on in a brain, we need tools that can fit inside or between neurons and transmit reports of neural events to receivers outside. We need observing instruments that are local, nondestructive and noninvasive, with rapid response, high band-width and high spatial resolution\ldots\hfill\ There is no law of physics that declares such an observational tool to be impossible.\end{fquote}

\begin{abstract}
\noindent
Simultaneously measuring the activities of all neurons in a mammalian brain at millisecond resolution is a challenge beyond the limits of existing techniques in neuroscience.
Entirely new approaches may be required, motivating an analysis of the fundamental physical constraints on the problem.
We outline the physical principles governing brain activity mapping using optical, electrical, magnetic resonance, and molecular modalities of neural recording.
Focusing on the mouse brain, we analyze the scalability of each method, concentrating on the limitations imposed by spatiotemporal resolution, energy dissipation, and volume displacement.
Based on this analysis, all existing approaches require orders of magnitude improvement in key parameters.
Electrical recording is limited by the low multiplexing capacity of electrodes and their lack of intrinsic spatial resolution,
optical methods are constrained by the scattering of visible light in brain tissue,
magnetic resonance is hindered by the diffusion and relaxation timescales of the spin species,
and the implementation of molecular recording is complicated by the stochastic kinetics of enzymes.
Understanding the physical limits of brain activity mapping may provide insight into opportunities for novel solutions.
For example, unconventional methods for delivering electrodes may enable unprecedented numbers of recording sites,
embedded optical devices could allow optical detectors to be placed within a few scattering lengths of the measured neurons,
and new classes of molecularly engineered sensors might obviate cumbersome hardware architectures.
We also study the physics of powering and communicating with microscale devices embedded in brain tissue and find that, while radio-frequency electromagnetic data transmission suffers from a severe power--bandwidth tradeoff, communication via infrared light or ultrasound may allow high data rates due to the possibility of spatial multiplexing.
The use of embedded local recording and wireless data transmission would only be viable, however, given major improvements to the power efficiency of microelectronic neural recording devices.
\end{abstract}

\section{Introduction}
Progress in neuroscience depends on recording the electrical activities of neurons within functioning brains.
The classical technique of electrical recording with wired electrodes has made remarkable progress: the number of simultaneously recorded neurons has doubled every seven years since the 1950s, currently allowing electrical observation of hundreds of neurons at millisecond timescales~\cite{stevenson11}.

Recording techniques have recently diversified beyond their roots in electrical recording.
For example, activity-dependent optical signals from neurons endowed with fluorescent indicators can be measured by photodetectors, and radio-frequency emissions from excited nuclear spins allow the construction of magnetic resonance images modulated by activity-dependent contrast mechanisms.
Other methods have been proposed, including direct recording of neural activities into information-bearing biopolymers~\cite{zamft12,glaser13,kording11a}.

Each modality of neural recording has characteristic advantages and disadvantages.
Multi-electrode arrays enable the recording of \num{\ca 250} neurons at sub-millisecond temporal resolutions.
Optical microscopy can currently record \num{\ca 100000} neurons at a \SI{1.25}{\second} timescale in behaving larval zebrafish~\cite{ahrens13} using light-sheet illumination, or hundreds to thousands of neurons at a \SI{\ca100}{\milli\second} timescale in behaving mice~\cite{ziv13} using two-photon scanning.
Magnetic resonance imaging (MRI) allows non-invasive whole brain recordings at a \SI{1}{\second} timescale in humans, but is far from single neuron spatial resolution.
Molecular recording devices have been proposed for scalable physiological signal recording but have not yet been demonstrated in neurons~\cite{zamft12,glaser13,kording11a}.

\autoref{fig:modalities} illustrates the recording modalities studied here.
While further development of these methods promises to be a crucial driver for future neuroscience research, their fundamental scaling limits are not immediately obvious.

\begin{figure}[htbp]
\centering
\caption{Four generalized neural recording modalities. (a) \emph{Extracellular electrical recording} probes the voltage due to nearby neurons. (b) \emph{Optical microscopy} detects light emissions from activity-dependent indicators. In two-photon laser scanning microscopy, shown here, an excitation beam at 1/2 the peak excitation wavelength of the fluorescent indicator is scanned across the sample, while an integrating detector captures the emitted fluorescence. (c) \emph{Magnetic resonance imaging} detects radio-frequency magnetic induction signals from proton spins in water, after weak thermal alignment by a static magnetic field. A resonant radio-frequency pulse tips the spins into a plane perpendicular to the static field, causing the net magnetization to precess. (d) \emph{Molecular recording} devices have been proposed, in which a “ticker-tape” record of neural activity is encoded in the monomer sequence of a biomolecular polymer – a form of nano-scale local data storage. This could be achieved by coupling correlates of neural activity to the nucleotide misincorporation probabilities of a DNA or RNA polymerase as it replicates or transcribes a known DNA strand.}  \label{fig:modalities}
\subfloat[Electrical]{\includegraphics[width=2.5in, clip=false]{figs/electrode_sketch_tc.eps}}
\hspace{0.1in}
\subfloat[Optical]{\includegraphics[width=2.5in, clip=false]{figs/optical_sketch_tc.eps}}
\\
\subfloat[MRI]{\includegraphics[width=3in,clip=false]{figs/mr_sketch_tc.eps}}
\hspace{0.5in}
\subfloat[Molecular]{\includegraphics[width=2.5in,clip=false]{figs/molecular_sketch_tc.eps}}
\end{figure}

Our analysis is predicated on assumptions that enable us to estimate scaling limits.
These include assumptions about basic properties of the brain, which are treated in \anref{sec:constraints}, as well as those pertaining to the required measurement resolution and the limits to which a neural recording method may perturb brain tissue, which are treated in \anref{sec:challenges}.
Together, these considerations form the basis for our estimates of the prospects for scaling of neural recording technologies.
We analyze four modalities of brain activity mapping---electrical, optical, magnetic resonance and molecular---in light of these assumptions, and conclude with discussion on opportunities for new developments.

Importantly, our assumptions, analyses and the conclusions thereof are intended as \emph{first approximations and are subject to debate}.
We anticipate that as much can be learned from where our logic breaks down as from where it succeeds, and from methods to work around the limits imposed by our assumptions.

\section{Basic Constraints}
\label{sec:constraints}

\paragraph{Mouse brain}
The mouse brain contains \num{\ca 7.5e7} neurons in a volume of \SI{\ca 420}{\milli\meter\cubed}~\cite{vincent10} and weighs about \SI{0.5}{\gram}.
For comparison, the human brain has roughly \num{8e10} neurons~\cite{azevedo09} in a volume of \SI{1200}{\centi\meter\cubed}~\cite{allen02}.
The human brain consumes \SI{\ca 15}{\watt} of power (performing the equivalent of roughly \num{1e17} floating point computational operations on that power budget)~\cite{sarpeshkar10}.
Because power consumption scales approximately linearly with the number of neurons~\cite{houzel11}, the mouse brain is expected to utilize \SI{\ca 15}{\milli\watt} (for comparison, the metabolic rate of the \SIrange{\ca 20}{30}{\gram} mouse is \SIrange{\ca 200}{600}{\milli\watt} depending on its degree of physical activity~\cite{speakman13}).

\paragraph{Neural activities}
Action potentials (spikes) last \SI{\ca 2}{\milli\second}.
The average rate of neuronal spiking is \SI{\ca 5}{\hertz}~\cite{sarpeshkar10}, but some neurons spike at \SI{500}{\hertz} or even faster~\cite{gittis10}.
The activities of nearby neurons can be highly correlated.

\paragraph{Absorption and scattering of radiation}
All existing methods of neural recording utilize electromagnetic waves, from the near-DC frequencies of wired electrical recordings (\SI{\ca 1}{\kilo\hertz}) to the radio-frequencies of wireless electronics and fMRI (MHz--GHz) to visible light in optical approaches (\SI{\ca 500}{\tera\hertz}).
Electromagnetic waves are attenuated in brain tissue by absorption and scattering.
As an approximation to the electromagnetic absorption of brain tissue, we treat the absorption by water, the brain's main constituent (\SIrange{68}{80}{\percent} by mass in humans \cite{dobbing73,fatouros99}).
At visible and IR wavelengths, there is far worse scattering than absorption: absorption lengths range from \SI{\ca 1.5}{\milli\meter} (blue light) to about \SI{\ca 1}{\centi\meter} (infrared light), while scattering lengths are in the hundreds of microns.
The combined effect of absorption and scattering is measured by the attenuation length, the distance over which the signal strength is reduced by $1/e$ along a path.
\autoref{fig:attenuation} shows the absorption length of water~\cite{kou93}, and the attenuation length in a Mie scattering model (from \cite{horton13}) intended to approximate the scattering properties of cortical tissue (and see \cite{gabriel1996} for tissue skin depth measurements in the \SI{10}{\hertz} to \SI{100}{\giga\hertz} range).
This gives a preliminary indication of which wavelengths can be used to measure deep-brain signals.

\begin{figure}[htbp]
\caption{%
Penetration depth (attenuation length) of electromagnetic radiation in water vs. wavelength (data from \cite{jonasz07}).
Black dashed line: the approximate diameter of the mouse brain.
Inset: approximate tissue model based on Mie scattering theory and water absorption. Absorption length of water~\cite{kou93} (blue), tissue scattering length in a simple Mie scattering model (red) and the attenuation length (green) of infrared light calculated based on these approximations (inset reproduced from \cite{kou93}, with permission).}
\label{fig:attenuation}
\centering
\includegraphics[width=0.5\linewidth]{figs/Fig2.eps}
\end{figure}

\section{Challenges for Brain Activity Mapping}
\label{sec:challenges}
Any activity mapping technology must extract the required information without disrupting normal neuronal activity.
As such, we consider three primary challenges:

\subsection{Spatiotemporal Resolution}

A sampling rate of \SI{1}{\kilo\hertz} is necessary to capture the fastest trains of action potentials at single-spike resolution.
A minimal data rate of \num{7.5e10} bits processed per second is then required to record 1 bit per mouse neuron at \SI{1}{\kilo\hertz}.

In electrical recording, higher sampling rates (e.g. \SIrange{10}{40}{\kilo\hertz}) are often necessary to distinguish neurons based on spike shapes when each electrode monitors multiple neurons.
More fundamentally, one bit per neuron sampling at \SI{1}{\kilo\hertz} would likely not be sufficient to reliably distinguish spikes above noise: transmitting \SI{\ca 10}{\bit} samples at \SI{\ca 10}{\kilo\hertz} (full waveform) or \SIrange{\ca 10}{20}{\bit} time-stamps upon spike detection would be more realistic.
On the other hand, it may be possible to locally compress measurements of a spike train before transmission.
In the blowfly Calliphore vicina, the entropy of spike trains has been measured to be up to \SI{\ca 180}{\bit\per\second}, and the information about a stimulus encoded by a spike train (mutual information) was as high as \SI{\ca 90}{\bit\per\second}~\cite{strong98}. This would suggest that in the worst case, a compression factor of 5$\times$--10$\times$ should be possible, relative to a \SI{1000}{\bit\per\second} raw binary sampling. As a na\"{\i}ve estimate of the entropy as a function of firing rate, one can write the entropy $H$ in \si{\bit\per\second}, assuming \SI{1}{\milli\second} long spikes and \SI{1000}{\hertz} sampling rate, as
\[H \approx \left(-P\sub{spike}\cdot\log_2\!\left(P\sub{spike}\right) - \left(1 - P\sub{spike}\right)\cdot\log_2\!\left(1 - P\sub{spike}\right)\right) \cdot \SI{1000}{\bit\per\second}\]

where $P\sub{spike}$ is the probability of spiking during the sampling interval.
For the average firing rate of \SI{5}{\hertz}, $P\sub{spike}=0.005$ and $H=\SI{45}{\bit\per\second}$, corresponding to a compression factor of $\ca 20\times$.
However, at \SI{500}{\hertz}, $P\sub{spike}=0.5$ with $H\approx\SI{1000}{\bit\per\second}$, i.e., no compressibility. 
Therefore, compression could conceivably reduce the data transmission burden for activity mapping by 1--2 orders of magnitude, depending on the neurons and activity regimes under consideration.
Based on the above, we assume \SI{1}{\bit\per neuron\per\milli\second} or \SI{100}{\giga\bit\per\second} for the entire mouse brain, as a ``minimal whole brain data rate'' in what follows.
In many cases, this constitutes a lower bound on what will be feasible in practice.

\subsection{Energy Dissipation}

Brain tissue can sustain local temperature increases ($\Delta T$) of \SI{\ca 2}{\celsius} without severe damage \cite{azevedo09}.
Assuming that the brain is receiving a constant power influx $P\sub{delivered}$ and that the local thermal transport properties of mouse brains are similar to those of humans \cite{allen02}, we can approximate the temperature change in deep-brain tissue as a function of the applied power \cite{sotero11}:
\[\frac{\od T}{\od t} = \left.\left(P\sub{delivered} + P\sub{metabolic} - \rho\sub{blood} C\sub{blood}\,f\sub{blood} \Delta T\right)\right/C\sub{tissue}\]
where $P\sub{metabolic} = \SI{0.0116}{\watt\per\gram}$ is the power per unit mass of basal metabolism, $C\sub{tissue} \approx \SI{3.7}{\joule\per\kelvin\per\gram} \approx 0.88\cdot C\sub{water}$ is the specific heat capacity of brain tissue, $\rho\sub{blood}=\SI{1.05}{\gram\per\centi\meter\cubed}$ is the density of blood, $C\sub{blood} = \SI{3.9}{\joule\per\kelvin\per\gram}$ is the specific heat capacity of blood, $f\sub{blood} = \SI{9.3e-9}{\meter\cubed\per\gram\per\second}$ is the volume flow rate of blood, and $\Delta T$ is the temperature difference between the brain tissue and the blood (at temperature \SI{37}{\celsius}).
A steady-state temperature increase ($\od T/\od t = 0$) of \SI{2}{\celsius} corresponds to a power dissipation of \SI{\ca 40}{\milli\watt} per \SI{500}{\milli\gram} mouse brain.
Therefore, a recording technique should not dissipate more than \SI{\ca 40}{\milli\watt} of power in a mouse brain at steady state.

Higher power levels may be introduced transiently.
According to the above equation, if a neural recorder dissipates \SI{\ca 40}{\milli\watt} per \SI{500}{\milli\gram} mouse brain, then the brain approaches the steady-state temperature in \SIrange{2}{3}{\minute}, so shorter experiments may be feasible.
Increasing convective heat loss from the brain by increasing blood flow (e.g. via increased heart rate) or cooling~\cite{polderman2004} the brain, the blood, the cerebrospinal fluid (CSF), or the whole animal, could increase the allowable power dissipation.
Note that radiative loss of heat from the brain was ignored here since infrared light emitted by deep-brain tissue is quickly re-absorbed by nearby tissue.
We have also assumed that conductive heat loss is negligible compared to the heat extracted by blood flow.

In addition to the whole-brain steady-state power, there are limits on the acceptable applied power density.
For radio-frequency electromagnetic radiation, the specific absorption rate (SAR) limit on the power density exposed to tissue (calibrated for \SI{\ca 1}{\celsius} temperature change) is  \SI{\ca 10}{\milli\watt\per\centi\meter\squared}, while for ultrasound (which couples less strongly to dissipative loss mechanisms in tissue) the SAR limits are up to 72$\times$ higher.
The power density limit for visible and near-IR light exposures are also in the \SIrange{\ca 10}{100}{\milli\watt\per\centi\meter\squared} range for \SI{\ca 1}{\milli\second} long exposures, decreasing as the exposure time lengthens (based on the IEC 60825 formulas~\cite{iec60825}).
High local power dissipation (transient or steady-state) can also modify the electrical properties of excitable membranes, altering neuronal activity patterns.
For example, heating of cell membranes and surrounding solution by millisecond optical pulses leads to changes in membrane electrical capacitance mediated by the ionic double layer~\cite{shapiro12}.
Slower temperature changes (on a scale of seconds) resulting from RF radiation lead to accelerated ion channel and transporter kinetics~\cite{shapiro13}.
Both of these effects are appreciable when the temperature changes are on the order of \SIrange{1}{10}{\degreeCelsius}.

\subsection{Sensitivity to Volume Displacement}

To prevent damage to the brain, we assume that a recording technique should not cause a brain volume change of \SI{> 1}{\percent}. The appropriate damage threshold is not yet established, however, so this constitutes a first guess.

The nature of the volume displacement is important---sheets of instrumentation that sever long-range connectivity, for example, would disrupt normal brain function regardless of the degree of volume displacement.
Conversely, higher volume displacement might be possible if introduced during the early development of the brain, so that the brain can adapt.

\section{Evaluation of Modalities}

We next evaluate neural recording technologies with respect to the above challenges, using the mouse brain as a model system.
\autoref{table:strategies} lists the modalities studied, the assumptions made, the analysis strategies applied, and the conclusions derived.

\begin{table}[htbp]
\caption{Summary of modalities, models, assumptions and conclusions}
\label{table:strategies}
\centering
\footnotesize
\tabulinesep=1mm
\newcommand{\iskip}{\par\vspace{3pt}}
\begin{tabu} to\linewidth{>{\itshape}X[2,l]X[2.5]X[4,l]X[5]}
\toprule
\rowfont[C]{\upshape\bfseries\small}
Modality & Analysis Strategy & Assumptions & Conclusions \\
\cmidrule[0.4pt](lr){1-1}
\cmidrule[0.4pt](lr){2-3}
\cmidrule[0.4pt](lr){4-4}

Extracellular electrical recording &
Compute minimal number recorders based on max distance from recorder to recorded neuron &
{Decay profile of extracellular voltage
\iskip Approximate noise levels at recording site}
&
{Maximum recording distance $r\sub{max}\approx\SIrange{100}{200}{\micro\meter}$ from electrode to neuron measured
\iskip \num{\ca 100000} recording sites are required per mouse brain at current noise levels
\iskip However, $\ca\num{1e7}$ electrodes are required in practice to enable sorting of noisy, temporally overlapping spikes using current algorithms}
\\

Implanted electrical recorders &
Compute power dissipation of electronic devices that digitally sample neuronal activity &
Physical limit: $\left.\kb T\ln\left(2\right)\right/\si{\bit}$ erased \iskip
Practical limit: $\left.\ca 10 \kb T\right/\si{\bit}$ processed \iskip
Current CMOS digital circuits: $\left.\num{>1e5}\kb T\right/\si{\bit}$ processed &
Requires at least 2--3 orders of magnitude increase in the power efficiency of electronics relative to current devices to scale to whole-brain simultaneous recordings \iskip
Minimalist architectures should be developed to reduce local data processing overhead
\\

Wireless data transmission &
Compute tradeoff between power efficiency and channel bandwidth using information theory &
Transmitter must supply enough power to overcome noise and path loss &
Data transmission at optical or near-optical frequencies is necessary to achieve sufficient single-channel data rates using electromagnetic radiation. Radio-frequency (RF) electromagnetic transmission of whole-brain data would draw excessive power due to bandwidth constraints. 
\iskip Bandwidth cannot effectively be split over multiple independent RF channels, but IR light or ultrasound may allow spatial multiplexing.
\\

Optical imaging &
Relate the scattering and absorption lengths of optical wavelengths in brain tissue to signal-to-noise ratios for optical imaging &
Approximate values of scattering and absorption lengths as a function of wavelength &
Light scattering imposes severe limits on optical techniques, but strategies exist which could negate the effects of scattering, such as implantable optics, infrared fluorescence or bioluminescence, and online inversion of the scattering matrix
\\

Multi-photon optics &
Compute minimum total excitation light power to excite multi-photon transitions from indicators within each neuron in every imaging frame &
Approximate values of multi-photon cross-sections \iskip
Pulse durations similar to those currently used in multi-photon imaging &
Multi-photon pulsed-laser excitation of a whole mouse brain will over-heat the brain except in very short experiments
\\

Beam scanning microscopies &
Calculate device and indicator parameters necessary for fast beam re-positioning and signal detection &
Fast optical phase modulators could re-position beams at \SI{\ca 1}{\giga\hertz} switching rates \iskip
Fluorescence lifetimes in the \SIrange{0.1}{1.0}{\nano\second} range &
Beam re-positioning time limits the speed of current systems but we are far from the physical limits of scan speed \iskip
Fluorescence lifetimes of indicators may constrain design of ultra-fast scanning microscopies
\\

Magnetic resonance imaging &
Calculate spatial and temporal resolution of MRI based on spin relaxation times and spin diffusion &
Proton MRI using tissue water \iskip
Approximate values of $T_1$ and $T_2$ relaxation times and self-diffusion times for tissue water &
To a first approximation, proton MRI is limited by the $T_1$ relaxation time of water to \SI{\ca 100}{\milli\second} temporal resolution and by the self-diffusion of water to spatial resolutions of \SI{\ca 40}{\micro\meter}. $T_1$ pre-mapping could allow $T_2$ contrast on a \SI{\ca 10}{\milli\second} timescale.
\\

Ultrasound &
Calculate spatial resolution, signal strength and bandwidth limits on ultrasound imaging &
Speed of sound in brain \iskip
Attenuation rate of ultrasound in brain &
Attenuation of ultrasound by brain tissue and bone may be prohibitive at the \SI{\ca 100}{\mega\hertz} frequencies needed for single-cell resolution ultrasound imaging \iskip
Ultrasound may be a viable medium for spatially multiplexed data transmission from embedded devices
\\

Molecular recording &
Compute metabolic load and DNA volume for rapid synthesis of large nucleic acid polymers \iskip
Evaluate temporal resolution in simulated experiments using kinetic models &
Polymerase biochemical parameter ranges \iskip
Metabolic requirements of genome replication &
Molecular recording devices fall within physical limits but their development poses major challenges in synthetic biology

\\\bottomrule
\end{tabu}
\end{table}

\subsection{Electrical Recording}

In the oldest strategy for neural recording, an electrode is used to measure the local voltage at a recording site, which conveys information about the spiking activity of one or more nearby neurons.
The number of recording sites may be smaller than the number of neurons recorded since each recording site may detect signals from multiple neurons.
Typical electrical recording techniques keep active devices such as amplifiers outside the skull and therefore do not pose a heat dissipation challenge.

\subsubsection{Spatiotemporal Resolution}

One way to estimate the minimal number of electrodes required to record from the entire mouse brain is to extrapolate the state of the art in spike sorting.
In an optimistic scenario, $\ca 10$ neurons per electrode may be distinguishable using current spike-sorting algorithms \cite{pedreira12,sahani99,camunas13}, although the theoretical upper bound is unknown.
Indeed, most current techniques (e.g. hand-positioned tetrodes) optimize for signal separability, not for total number of recorded neurons.
This scenario would necessitate $N=\num{7.5e6}$ electrodes to record from all mouse neurons.
This could correspond to recording sites spaced on the vertices of a \num{\ca 200 x 200 x 200} site cubic lattice with \SI{\ca 40}{\micro\meter} edge length.

A more optimistic estimate, neglecting difficulties with spike sorting, derives from the maximum distance between an extracellular electrical recorder and a neuron from which it records spikes.
In a first approximation, this is determined by two factors: the decay of the signal with distance from the spiking neuron and the background noise level at the recording site.
We assume that for an electrode to reliably detect the signal from a given neuron, the magnitude of that neuron's signal must be larger than the electrode's noise level.

The peak signals of spikes from neurons immediately adjacent to an electrode are in the \SIrange{0.1}{1.0}{\milli\volt} range and scale roughly as $e^{-r/r_0}$, where $r$ is the distance from the cell surface and the $1/e$ falloff distance $r_0$ has been experimentally measured at \SI{\ca 28}{\micro\meter} in both salamander retina~\cite{segev04} and cat cortex~\cite{gray95}, and computed at \SI{\ca 18}{\micro\meter} in a biophysically realistic simulation~\cite{gold07}.
However, this decay is strongly influenced by the detailed geometry of neuronal currents and the properties of the extracellular space, making analytical calculation of the decay rate difficult (at large distances, a $1/r^2$ dipole falloff is expected).

Several sources of background noise enter the recordings.
Johnson noise, which arises from thermal fluctuations in the electrode, is \[V\sub{johnson} = \left(4\kb T Z \BW\right)^{1/2}\]
which for physiological temperature, electrodes of impedance $Z = \SI{0.5}{\mega\ohm}$, and $BW = \SI{10}{\kilo\hertz}$ bandwidth is $V\sub{johnson} \approx \SI{9}{\micro\volt}$.
The recordings are also affected by interference from other neurons, which has been reported to exceed the Johnson noise, and is non-stationary due to changes in the cells' firing properties~\cite{sahani99}. 
The noise and interference from these sources realistically produces \SIrange{>10}{20}{\micro\volt} of voltage fluctuations~\cite{camunas13}.
Current recording setups thus have signal to interference-plus-noise ratios (SINRs) of \num{<100}, where the SINR is defined as the ratio of the peak voltage from immediately adjacent neurons to the voltage fluctuation floor of the electrode.

Importantly, this calculation underestimates the required number of electrodes in practice, because sorting spikes from all neurons within the \SI{6e6}{\micro\meter\cubed} cube corresponding to a single electrode is likely to be unrealistic for several reasons.
First, signals from the weakest cells are far weaker than those from the strongest cells and the signals from some cells decay much faster than others~\cite{gray95}.
Second, because of neuronal synchronization, the local noise produced by nearby neurons may sometimes be large. 
Finally, with many neurons per electrode or at high firing rates, spikes from detectable neurons will often temporally overlap, making spike sorting difficult.
This would be exacerbated by correlated firing patterns of nearby neurons.

\subsubsection{Volume Displacement}

We require \SI{<1}{\percent} total volume displacement from $N$ recorders.
Wires from each electrode must make it to the surface of the brain, which implies an average length $\ell\approx\SI{4}{\milli\meter}$ for the mouse brain (depending on assumptions about the wiring geometry).

As a rough approximation we consider each recorder to produce a volume displacement associated with a single cylindrical wire, with length $\ell$ and radius $r$.
Thus $r$ must satisfy \[\pi r^2\ell N\sub{min,rd} < 0.01V\sub{brain}\]
Using $N\sub{min,rd} = 110000$ or $21000$ recording sites and $\ell\approx\SI{4}{\milli\meter}$ requires wires of radius $r\sub{max} \approx \SI{8.0}{\micro\meter}$, or \SI{3.4}{\micro\meter}, respectively.
While these dimensions are readily achievable using lithographic micro-fabrication, there would be a challenge to produce \emph{isolated} wires of such dimensions at scale.
Still, the volume constraints are unlikely to limit whole-mouse-brain electrical recording even in the most pessimistic scenario.

\autoref{fig:snrlimits} illustrates the above considerations as a function of the electrode SINR.

\begin{figure}[htbp]
\caption{
The voltage signal to interference-plus-noise ratio (SINR) at the recording site sets an approximate upper bound on the distance $r\sub{max}$ between the recording site and the farthest neuron it can sense (blue).
Assuming at least one electrode per cube of edge length $\sqrt{2}r\sub{max}$ in the mouse brain in turn limits the number of neurons per recording site (gold), the total number of recording sites (red) and the diameter of wiring consistent with \SI{<1}{\percent} total brain volume displacement (turquoise).
SINR values for current recording setups are \num{<1e2}.
In practice, the number of neurons per electrode distinguishable by spike-sorting algorithms is only \num{\ca 10}, so these curves greatly under-estimate the number of electrodes which would be required based on current spike-sorting approaches.
}
\label{fig:snrlimits}
\centering
\includegraphics[width=0.7\textwidth]{figs/Fig3.eps}
\end{figure}

\subsubsection{Implanting Electrodes in the Brain}

There are several technology options for introducing many electrodes into a brain.
For example, flexible nanowire electrodes could be threaded through the capillary network~\cite{llinas05}.
Capillaries are present in the brain at a density of \SIrange{2500}{3000}{\per\milli\meter\cubed}~\cite{schmidt89}, which equates to one capillary per \SI{73}{\micro\meter}, with each neuron lying within \SI{\ca 200}{\micro\meter} of a capillary~\cite{loffredo08}. 
The cerebrospinal ventricles may also provide a convenient location for recording hardware.
Neural tissues could be grown around pre-fabricated electrode arrays~\cite{jadhav12}, or silicon probes arrays with many nano-fabricated recording sites per probe~\cite{du11} could be inserted into the brain.

Mechanical forces during insertion and retraction of silicon and tungsten microelectrodes from brain tissue have been measured in rat cortex at \SI{\ca 1}{\milli\newton} for electrodes of \SI{\ca 25}{\micro\meter} radius~\cite{jensen03}.
These forces are comparable to the Euler bucking force $F$ of a \SI{2}{\milli\meter} long cylindrical tungsten rod of \SI{5}{\micro\meter} radius
\[F=\frac{\pi^2 E I}{(K L)^2} \approx \SI{1}{\milli\newton}\]
where $E=\SI{411}{\giga\pascal}$ is the elastic modulus of tungsten, $I=(\pi/2)(\SI{5}{\micro\meter})^4$ is the area moment of inertia of the cylindrical wire cross-section, $L\approx\SI{2}{\milli\meter}$ is the length of the wire, and $K$ is the column effective length factor which depends on the boundary conditions and is set to $K=1$ here for simplicity.
This suggests that it may be possible to push structures of \SI{<10}{\micro\meter} diameter into brain tissue (see \cite{najafi90} for related calculations).

\subsubsection{Conclusions and Future Directions}

The main challenge for electrical recordings is the large number of required recording sites.
Ongoing innovations which could enable viable all-electrical recording methods include
the development of highly multiplexed probes, thinner wires, smaller electrode impedances,
amplifiers with lower input-referred noise levels, novel methods to implant large numbers of electrodes,
multilayer lithography for routing electrical traces, spike sorting algorithms capable of handling temporally overlapping, non-independent spikes and adaptively modeling the noise, and hybrid systems integrating electrical recording with
implantable optics or other methods.

A caveat, however, pertains to the ability to relate the measured electrical signals to specific cells within a circuit.
As the set of neurons recorded by each electrode grows to encompass a large volume around the electrode, it will become more difficult to attribute the recorded spikes to particular neurons.
Furthermore, given the complex geometries of neuronal processes, it is not obvious how to determine the spatial position or layout of a neuron from its electrical signature on a nearby electrode (unless the spatial density of recording sites is increased such that many electrodes sample the same neuron).
A given electrode will be positioned near the axons or dendrites of some neurons, and near the cell bodies of other neurons, complicating data interpretation.
Until these issues can be resolved, readouts with intrinsic spatial resolving power may be more appropriate than pure electrical recording for the goal of whole-brain activity mapping (as opposed to sparsely sampling neural activities at high temporal resolutions).

\subsection{Optical Recording}

Optical techniques measure activity-dependent light emissions from neurons, generated by fluorescent indicator proteins (although activity-dependent bioluminescent emissions are an emerging possibility).
Calcium indicators can only distinguish spikes below \SIrange{\ca 50}{100}{\hertz} firing rates without averaging~\cite{Smetters99}, but the field of high-speed fluorescent voltage indicators is advancing quickly~\cite{Barnett2012}.
Note that many optical techniques place the optical hardware outside of the brain and do not pose challenges due to volume displacement.

\subsubsection{Spatiotemporal Resolution}

Recording all neurons requires separation of the signal from each neuron from background noise originating from other points in the brain.
Epi-fluorescence microscopy focuses the detector on one plane in the specimen, while all neurons in a 3D volume are illuminated.
Out-of- focus neurons then add background noise.
Light sheet imaging illuminates only those neurons that are near the focal plane, reducing the amount of noise from out-of-focus neurons, and has been successfully used in transparent zebrafish brains~\cite{ahrens13}.
In both traditional imaging and light sheet imaging, the focal plane is scanned through the sample to achieve signal separation and 3D coverage.
Multi-photon and confocal techniques restrict the detected photons to those originating from a region of interest.
In multi-photon techniques, nonlinear optical effects result in fluorescence being excited only near the focal point of the excitation laser.
The detector can then integrate over all multiple-scattering paths of photons emitted from the focal volume to measure its total fluorescence.
In confocal techniques only photons from the point of interest are measured due to geometric constraints (e.g., pinholes).
Multi-photon and confocal techniques scan the focal spot in order to isolate the signals from different neurons.
Optical techniques therefore achieve spatial resolution by multiplexing spatially (e.g., epi-fluorescence imaging) or temporally (e.g., beam scanning), and often by a combination of the two.

Single-photon techniques including epi-fluorescence, light sheet and confocal techniques only allow imaging to a depth defined by the scattering lengths of the visible-wavelength photons (matched to the excitation and emission spectra of current indicators).
Importantly, scattering not only causes signal attenuation, but also causes noise and impairs signal separation (e.g., by expanding width of the point spread function due to photon diffusion).
The scattering length of visible light in brain tissue is \SI{>200}{\micro\meter}~\cite{horton13} while some wavelengths of infrared light have attenuation lengths of \SI{\ca 500}{\micro\meter} (see \autoref{fig:attenuation}).
Infrared light may thus pass through \SIrange{\ca 1}{2}{\milli\meter} of tissue without prohibitively strong scattering~\cite{horton13,kobat09}, while depths of \SI{>500}{\micro\meter} cannot easily be reached for dyes with absorption and emission peaks in the visible range.
Activity dependent dyes operating in the infrared~\cite{filonov11,shcherbakova13} could thus be decisive for improvements in imaging depth.

Multi-photon techniques allow deeper penetration.
Two or more infrared photons can combine to excite a fluorophore with an excitation peak in the visible range, leading to the emission of a visible photon.
Because only one neuron is illuminated at a time, all of the light emissions captured by the detector originate from the illuminated neuron, regardless of the extent of scattering of the outgoing light.
Therefore, the emission pathway is limited less by scattering than by absorption and a single detector may collect a large number of scattered emission photons to obtain a sufficiently large integrated signal.
Exploiting these ideas has resulted in imaging at \SI{>1}{\milli\meter} depth~\cite{horton13,kobat09} and allows multi-photon techniques to largely sidestep the signal separation challenge insomuch as the excitation spot is sufficiently well-focused.

There are at least four options for overcoming the scattering of visible light to enable signal-separation from deep-brain neurons:

\begin{enumerate}
\item Infrared light can excite multi-photon fluorescence in an excitation-scanning architecture.
\item Fluorophores with both excitation and emission wavelengths in the infrared could be developed.
\item Emerging techniques based on beam shaping allow transmission of focused light through random scattering media by inverting the scattering matrix~\cite{conkey12}.
Because the scattering properties change over time, this must be done quickly, possibly faster than the imaging frame rate, necessitating high-speed wavefront modulation.
This can currently be achieved with digital micro-mirror devices (DMDs), but not with phase-only spatial light modulators (SLMs), although GHz switching of phase modulators appears feasible in principle ~\cite{alivisatos13}. High speed focusing through turbid media is also achievable using all-optical feedback in a laser cavity~\cite{Nixon2013}.
It is possible to measure the scattering matrix non-invasively~\cite{Chaigne2013} using a photo-acoustic microscopy based on focused ultrasound.
\item Light sources and/or detectors could be positioned close to the measured neurons, necessitating the use of embedded optical devices.
This could be done using optical fiber~\cite{mahalati13} and/or waveguide~\cite{zorzos10,zorzos12} technologies, which are developing rapidly.
For example, single-mode fiber cables can support \SI{>1}{\tera\byte\per\second} data rates with low light loss over hundreds of kilometers.
\end{enumerate}

While implanted optics might seem to require a number of implanted photodetectors, fibers or waveguide ports comparable to the number of neurons, new developments suggest ways of imaging with fewer elements.
For example, compressive sensing or ghost imaging techniques based on random mask projections~\cite{wakin06,studer12,tian11,sun13} might allow a smaller number of photodetectors to be used.
In an illustrative case, an imaging system may be constructed simply from a single photodetector and a transmissive LCD screen presenting a series of random binary mask patterns~\cite{huang13}, where the number of required mask patterns is much smaller than the number of image pixels due to a compressive reconstruction.
Furthermore, it is possible to directly image through gradient index of refraction (GRIN) lenses~\cite{murray12} or optical fibers~\cite{mahalati13,kang10,flusberg05}, thus multiplexing multiple observed neurons per fiber.

Hybrid techniques combining optics with other modalities may also provide new ways to overcome scattering.
For example, ultrasound encoding~\cite{wang12}, which frequency-tags light emissions emerging from a known location via a mechanical Doppler shift of the emitter~\cite{mahan98}, is powerful in that it provides a generic mechanism to sidestep problems of elastic optical scattering, but it requires distinguishing MHz frequency modulations in THz light waves (part per million frequency discrimination) and tags only a small fraction of the emitted photons.

\paragraph{Speed of beam scanning}
Multi-photon and confocal approaches rely on the serial scanning of an excitation beam across the sample.
The speed of scanning microscopes is limited by beam re-positioning times (\SI{\ca 0.1}{\micro\second} for spinning disk~\cite{mahalati13,kang10,flusberg05}, \SI{\ca 3}{\micro\second} for piezo-controlled linear scan mirrors, \SI{\ca 10}{\micro\second} for acousto-optic deflectors~\cite{vucinic07}, \SI{\ca 8}{\kilo\hertz} line scans for resonant galvanometer mirrors), and the fluorescence lifetimes of activity indicators (\SI{\ca 1}{\nano\second}).
Note that \SI{0.1}{\micro\second} repositioning time for current spinning-disk confocal techniques would require 10 seconds per frame for whole mouse brain imaging with a single scanned beam: $\left(\SI{1e-7}{\second\per site}\right)\left(\SI{1e8}{site\per brain}\right) = \SI{10}{\second\per brain}$. There is therefore a need for a \num{1e4} fold improvement in beam re-positioning time and/or beam parallelization in order to achieve \SI{1}{\kilo\hertz} imaging frame rates for whole mouse brains.
The \SI{10}{\micro\second} repositioning time for acousto-optic deflectors is set by the speed of sound in the deflector crystal, while scanning mirrors and spinning disks are limited by inertia.
In principle, however, optical phase modulators could switch at GHz rates~\cite{alivisatos13} and arrays of such phase modulators could arbitrarily re-shape coherent optical wavefronts to re-position beamlets.
Moreover, parallelization of beamlets and detectors could allow further speedups.
The speed of beam scanning is thus far from its physical limits.
Fluorescence lifetimes in the \SIrange{0.1}{1}{\nano\second} range~\cite{striker99} may ultimately constrain the design of scanning microscopies: a delay of \SI{0.1}{\nano\second} per mouse neuron per frame corresponds to \SI{100}{\hertz} frame rate with no parallelization.

\paragraph{Diffraction}
Due to diffraction, a lens (or other limiting optical aperture) of a certain size is necessary to
achieve a given angular resolution, and it might be hypothesized that this would be limiting
factor for optical methods.
However, this is not the case.
To illustrate, at a depth of \SI{10}{\milli\meter} we must be able to distinguish two neurons which are \SI{10}{\micro\meter} apart.
In the small angle approximation, we have $\theta \approx (\SI{10}{\micro\meter})/(\SI{10}{\milli\meter}) \approx \lambda/D$. Therefore, using light of wavelength $\lambda\approx\SI{1}{\micro\meter}$ requires a lens aperture $D$ of only \SI{1}{\milli\meter}.
As such, it seems that diffraction is not a significant limiting factor for cellular resolution imaging, at least outside the context of microscale apertures that might find use in embedded optics approaches.


\subsubsection{Energy Dissipation}

Light that does not leave the brain is ultimately dissipated as heat.
The total light power requirements for optical measurement of neuronal activity using fluorescent indicators depend on factors including
fluorophore quantum efficiency,
absorption cross-section,
activity-dependent change in fluorescence,
background fluorescence,
labeling density,
activation kinetics,
detector noise,
scattering and absorption lengths,
and others. Unfortunately, many of these variables are unknown or highly dependent on particular experimental parameters.

A statistical analysis of photon count requirements for spike detection (in the context of calcium imaging) can be found in~\cite{wilt13}, which derived a relationship between the number of background photon counts ($N\sub{bg}$) and the required number of signal photon counts required for high fidelity spike detection given photon shot noise, scaling roughly as $N\sub{signal} > 3\sqrt{2N\sub{bg}}$, even at low absolute photon count rates.
While this analysis governs the number of detected photons, the number of emitted photons will be higher due to losses.
In one example using two-photon excitation, \SI{5}{\percent} of the emitted photons were captured by the photodetector~\cite{kim99}.

\paragraph{Multi-photon: current technology}
Multi-photon excitation poses a particularly severe power problem due to the high light intensities required to excite nonlinear optical processes.
In typical multi-photon experiments on mice, \SI{\ca 50}{\milli\watt} of time-averaged laser power is used with a dwell time of \SI{\ca 3}{\micro\second}~\cite{wilson07}.
This would allow imaging \num{\ca 300} neurons at millisecond resolution with a single scanned excitation beam.
Current multi-photon imaging experiments are already near the permissible energy dissipation limit and improvements cannot come at the cost of greatly increased light power delivery.

\paragraph{Multi-photon: theoretical calculations}
Multi-photon experiments rely on short laser pulses with high peak light intensities at a focused excitation spot to excite nonlinear transitions~\cite{kim99}.
This imposes an experimentally relevant physical limit: at least one excitation pulse of sufficient intensity per neuron per frame is required in order to excite multi-photon fluorescence during each frame.
Assuming \SI{1}{\kilo\hertz} frame rate and \SI{0.1}{\nano\joule} pulses, delivering only one pulse per neuron per frame would dissipate roughly $\left(\num{1e8}\right)\left(\SI{1}{\kilo\hertz}\right)\left(\SI{0.1}{\nano\joule}\right)=\SI{10}{\watt}$ in the mouse brain, which is clearly prohibitive.
This is a lower bound because, in general, more than one excitation pulse per neuron per frame will be required to excite detectable fluorescence (e.g., one reference reported 12 pulses per spot~\cite{kim99}).
For three-photon excitation, the situation will be even worse as higher peak light intensities are required to excite three-photon fluorescence.

Could the single-pulse energy be reduced while maintaining efficient two-photon excitation? The number of two-photon (2P) transitions excited per fluorophore per pulse is $n_a = F^2 C / t$, where $F$ is the number of photons per pulse per area, in units of \si{photon\per\centi\meter\squared}, $C$ is the two-photon cross-section in units of \si{\centi\meter\tothe{4}\second\per photon}, and $t$ is the pulse duration in \si{\second}.
This can be approximated as
\[n_a = \left(\frac{4E\left(\NA\right)^2}{h c \lambda}\right)^2 \frac{C}{t}\]
where $\NA$ is the numerical aperture of the focusing optics, $E$ is the pulse energy and $\lambda$ is the stimulation wavelength.
For a 2P experiment with \SI{100}{\femto\second}, \SI{0.1}{\nano\joule} pulses, assuming a 2P cross section~\cite{masters06} of \SI{1e-49}{\centi\meter\tothe{4}\second\per photon}, $\lambda=\SI{900}{\nano\meter}$ and $\NA=1.0$, $n_a \approx \frac{1}{20}$.
While multiple pulses per neuron per frame are thus required to excite each fluorophore in every frame, a single pulse per neuron per frame will likely excite at least one fluorophore when there are \num{>20} fluorophores per excitation spot.
If the single-pulse energy is reduced much further at fixed pulse duration, however, the excitation efficiency will become unacceptably low.
To improve this situation, shorter pulses could be used to achieve the same excitation rate with lower pulse energy, or indicators with improved 2P or 3P cross-sections could be developed.

\subsubsection{Bioluminescence}
To work around the requirement for large amounts of excitation light, bioluminescent rather than fluorescent activity indicators could be used.
Consider a hypothetical activity-dependent bioluminescent indicator emitting at \SI{\ca 1700}{\nano\meter} (IR), in order to evade light scattering.
As a crude estimate, assuming that 100 photons must be collected by the detector per neuron per \SI{1}{\milli\second} frame, and \SI{1}{\percent} light collection efficiency by the detector relative to the emitted photons, \SI{\ca 100}{\micro\watt} of emitted bioluminescent photons emissions are required for the entire mouse brain.
This would be feasible from the perspective of heat dissipation.
By contrast, in a 1-photon fluorescent scenario, if 100 excitation photons must be delivered into the brain to generate a single fluorescent emission photon, the power requirement becomes \SI{10}{\milli\watt}, which is on the threshold of the steady-state heat dissipation limit.
Therefore, bioluminescent indicators could potentially circumvent problems of heat dissipation associated with whole-brain optical imaging even in the 1-photon case.

The widely used bioluminescent protein firefly luciferase is \SI{\ca 80}{\percent} efficient in converting ATP hydrolysis coupled with luciferin oxidation into photon production, yielding \num{\ca 0.8} photons per ATP-luciferin pair consumed~\cite{seliger60}, and has \SI{\ca 90}{\percent} energetic efficiency in converting free energy to light production.
Heat dissipation associated with the luciferase biochemistry itself is therefore not a significant overhead relative to the \SI{100}{\micro\watt} of emitted photons calculated above.
In the same scenario, however, the brain would consume \num{\ca 6e8} additional ATP molecules per minute per neuron in order to power the bioluminescence, which is within the limits of cellular aerobic respiration rates (\SI{\ca 1}{\femto\mole\ O\textsubscript{2}} per minute per cell~\cite{molter09}, with \num{\ca 30} ATP per 6 O\textsubscript{2}, hence \num{3e9} molecules ATP synthesized per minute from ADP via glucose oxidation), but not by a large margin.
Note that transient increases in metabolic rate are possible: energy dissipation more than doubles in the mouse during high physical activity~\cite{speakman13}.
Therefore, whole-brain activity-dependent bioluminescence, at speeds high enough to achieve millisecond frame rates, may be metabolically taxing for the cell but is nevertheless plausible as a light generation strategy.

\subsubsection{Conclusions and Future Directions}

Scattering of visible light in the brain creates a problem of signal-separation from deep-brain neurons.
Multi-photon techniques, which scan an infrared excitation beam, can work around this scattering problem.
However, current multi-photon techniques applied at whole brain scale would dissipate too much power to avoid thermal damage to brain tissue.
Systems (such as plasmonic nano-antennas~\cite{blanchard11}) that could locally excite multi-photon fluorescence without the need for high-energy laser pulses could conceivably ameliorate this issue.
Furthermore, scanning microscopies require orders of magnitude improvement in speed or parallelization to apply to whole brains.
This speed improvement may ultimately be limited by fluorescence lifetimes of the indicators.
New methods besides multi-photon techniques could also work around the scattering of visible light in the brain.
For example, fluorophores or bio-luminescent proteins could be developed which operate at infrared wavelengths.
A compelling example from nature is the black dragonfish, which generates far red light (\SI{\ca 705}{\nano\meter}) via a multi-step bioluminescent process (using this light to see in deep ocean waters)~\cite{widder84,campbell87}.
A large set of activity indicators with distinguishable colors, generated through a combinatorial genetic recombination mechanism such as BrainBow~\cite{livet07}, could also improve signal separation (e.g., in conjunction with static post-mortem microscopy to map between cell colors and positions).
In addition, implanted optical devices, which place emitters and detectors within a few scattering lengths of the neurons being probed, could potentially obviate the negative effects of scattering and allow visible-wavelength indicators to be used without a need for multi-photon excitation.

\subsection{Embedded Active Electronics}

The preceding sections have assumed that electrical or optical signals from the recorded neurons are shuttled out of the brain before digitization and storage, but it is also conceivable to develop embedded electronic systems that locally digitize and then store or transmit (e.g., wirelessly) measurements of the activities of nearby neurons.
This could allow for shorter wires in electrical recording approaches, and for shorter light path lengths in optical recording approaches, as well as for more facile (e.g., non-surgical) delivery mechanisms for the recording hardware.

Integrated circuits have shrunk to a remarkable degree: in about 3 years, following the Moore's law trajectory, it will likely be possible to fit the equivalent of Intel's original 4004 micro-processor in a \SI{10 x 10}{\micro\meter} chip area.
Functional wirelessly powered radio-frequency identification (RFID) chips as small as \SI{50}{\micro\meter} in diameter have been developed and tags with chip-integrated antennas function at the \SI{400}{\micro\meter} scale.
Integrated neural sensors including analog front ends are also scaling to unprecedented form factors, e.g., a \SI{250 x 450}{\micro\meter} wireless implant (operating at \SI{\ca 1}{\milli\meter} range in air from a wireless power transmitter generating \SI{\ca 50}{\milli\watt} of transmitted power) including the antenna (with \SI{\ca 1}{\milli\meter} electrode shank to separate signal from ground) drawing only \SI{2.5}{\micro\watt} per recording channel~\cite{biederman13}.
Note that for a single such embedded recording device, the heat dissipation constraint is set not by the device's own dissipation (\SI{10}{\micro\watt} for four recording channels) but rather by the RF specific absorption rate limit associated with the \SI{50}{\milli\watt} transmit power.
Remarkably, cells such as macrophages (\SI{\ca 13}{\micro\meter} in size) can engulf structures up to at least \SI{20}{\micro\meter} in diameter~\cite{cannon92} and have been studied as potential delivery vehicles for nano-particle drugs~\cite{Kadiu11}, suggesting possibilities for non-surgical delivery of embedded electronics to the brain.

If a large amount of local storage is used, the real-time transmission bandwidth requirements for neural recording could be significantly reduced if it is only desired to take a ``snapshot'' of neural activity patterns over a limited period of time.
For example, flash memory, which will likely be the densest form of electronic memory storage in the near future, can store \SI{1}{\mega\bit} of data in a device \SI{100}{\micro\meter} on a side.
Even denser forms of memory storage are under development and could perhaps be used in a one-time-write mode in the context of neural recording long before they become commercially viable for use as rewritable media in the consumer electronics industry.

Here we consider the power dissipation associated with embedded electronic recording devices, as well as the constraints on possible methods to power them.
In the next section, we describe how physics constrains the achievable data transmission rates from such devices.

\subsubsection{Power Requirements for Recording}

Any embedded system needs to process data, in preparation either for local storage or wireless transmission.
Physics defines hard limits on the required power consumption associated with data processing (neglecting the possibility of reversible logic architectures~\cite{bennett73}), arising from the entropy cost for erasing a bit of information~\cite{landauer61}:
\[E\sub{Landauer} = \ln(2)\ \kb T\approx \SI{3e-21}{\joule\per\bit} \label{eq:landauer} \tag{the Landauer limit}\]
Ambitious yet physically realistic values for beyond-CMOS logic lie in the tens of $\kb T$ per bit processed~\cite{yablonovitch08}.
Scaling \SI{40}{$\kb T$\per\bit} to record raw voltage waveforms at a minimal \SI{1}{\kilo\bit\per\second\per neuron} (e.g. \SI{1}{\kilo\hertz} sampling rate, 1 bit processed per neuron per sample), the total power consumption for whole mouse brain recording could in principle be as low as \SI{\ca 16}{\nano\watt}.
Thus, at the physical limits of power efficiency, implanted devices could in principle digitally buffer and locally store a complete record of a mammalian brain's activity.
While this leaves \num{>1e6}-fold room for overhead due to increased data processing burden (more required bit flips per second), or energetic inefficiency of the switching device (greater dissipation per bit), realistic devices in the near-term may in fact require this much overhead, if not more.
This necessitates a more detailed consideration of limiting factors for today's microelectronic devices.

In the context of electrical recording, the first step that must be performed by an embedded neural recording device is digitization of the voltage waveform.
Until \si{\milli\volt}-scale switching devices are developed (see discussion below), it is necessary to amplify the \SIrange{\ca 10}{100}{\micro\volt} spike potential in order to drive digital switching events in downstream gates.
During this sub-threshold amplification step, a CMOS (or BJT) device will dissipate static power (associated with a bias current). 
Importantly, in order to decrease the input-referred voltage noise of this amplification process, it is necessary to increase the bias current and hence the static power dissipation.
For a simple differential transistor amplifier, the minimal bias current scales as
\[I\sub{d} = \frac{\pi}{2} \frac{4\kb T}{V\sub{n,max}^2} \frac{\kb T}{q} \BW\]
where $V\sub{n,max}$ is the input-referred voltage noise of the amplifier and $q$ is the electron charge.
For an extraceullar recording with $\BW = \SI{10}{\kilo\hertz}$ and $V\sub{n,max} = \SI{10}{\micro\volt}$, this implies a minimal bias current $I\sub{d}\approx\SI{60}{\nano\ampere}$ or a minimal static power of $\left(I\sub{d} V\sub{dd}\right)\approx\SI{6e-8}{\watt}$ at $V\sub{dd}\approx\SI{1}{\volt}$ operating voltage.
Assuming 10 neurons per recording channel, we then have 7.5 million recording channels for a mouse brain, which gives a power dissipation associated with signal amplification of \SI{\ca 500}{\milli\watt}.
Note that realistic analog front ends (which are subject to $1/f$ noise and require multiple gain stages) draw 6$\times$--10$\times$ greater bias current, quantified by the noise efficiency factor (NEF)~\cite{steyaert87}, to achieve the same input-referred noise levels.

Local on-chip digital computation also incurs an energy cost.
Current CMOS digital circuits consume 5--6 orders of magnitude~\cite{tucker11,koomey11,yablonovitch08,tucker11b} more energy per switching event (\SI{\ca 1}{\femto\joule\per\bit} including charging of the wires~\cite{tucker11}) compared to \ref{eq:landauer} (e.g., for a digital CMOS inverter, and ignoring the static power associated with the leakage current).
This corresponds to a \SI{\ca 1}{\femto\farad} total load capacitance at \SI{1}{\volt} operating voltage. For \SI{100}{\giga\hertz} switching rates ($\SI{1e8}{neurons} \times \SI{1}{\kilo\hertz}$) as above, this corresponds to \SIrange{0.01}{0.1}{\milli\watt}.
Realistic architectures, however, will incur overhead in the number of switching events required to store, compress and/or transmit neural signals, likely bringing the power consumption into an unacceptable range (e.g., \num{1000} bits processed per sample would be \SI{100}{\milli\watt} here).
To take a concrete example, commercial RFID tags consume \SI{\ca 10}{\micro\watt}~\cite{rfidsheet}.
At a chip rate of \SI{256}{\kilo\bit\per\second} with a Miller encoding of 2, this yields \SI{7.8e-11}{\joule\per\bit}, which is \num{\ca 10} orders of magnitude higher than \ref{eq:landauer}.
Applying current RFID technology to whole mouse brain recording at \SI{1}{\kilo\bit\per\second\per neuron} would thus draw \SI{\ca 8}{\watt} of power.
Therefore, at least 2--3 orders of magnitude reduction in power consumption will be necessary in order to apply embedded electronics for whole-brain neural recording.

Until recently, the energy efficiency of digital computing has scaled on an exponential improvement curve~\cite{koomey11}.
This was a consequence of Moore's law and Dennard scaling, where both the capacitance of each transistor and its associated interconnect, as well as the operating voltages, were reducing with the device dimensions.
Unfortunately however, issues related to device variability and the 3D structures needed to maintain good transistor performance in terms of on-to-off current ratio have largely stopped the reduction in effective capacitance per device; current devices are stuck at \SIrange{\ca 100}{200}{\atto\farad} for a minimum sized transistor.
Furthermore, the exponential increase in leakage current that comes along with the scaling of the threshold voltage in this scenario also have precluded substantial further decreases in voltage at a given performance level.
Indeed, for the past several technology generations (since about 2005), CMOS devices have operated at a supply voltage of \SI{\ca 1}{\volt}.
While neural signal processing does not demand very stringent transistor speeds and so reductions below \SI{\ca 1}{\volt} are certainly feasible, a fundamental limitation in scaling the supply voltage still remains.
Specifically, CMOS has a well-defined minimum-energy per bit and an associated minimum- energy operating voltage that is defined by the tradeoff between static (leakage) and dynamic (switching) energy:
as the operating voltage is decreased, the capacitive switching energy decreases, but the ratio of currents in the on and off states, $I\sub{off}/I\sub{on}$, increases exponentially, increasing the energy associated with leakage (this effect is independent of the threshold voltage in the sub-threshold regime).
For practical circuits, the supply voltage that leads to this minimum energy is on the order of \SIrange{300}{500}{\milli\volt}, and thus supply voltage scaling will at most provide 3$\times$--10$\times$ improvement in energy over today's designs.
Thus, a paradigm shift in microelectronic hardware is needed to reduce power by several orders of magnitude if we are to approach the physical limits.
Developing a switching device operating in the \si{\milli\volt} range, rather than the \SI{1}{\volt} range of current transistors, would allow $\left(\SI{1}{\volt}/\SI{1}{\milli\volt}\right)^2=\num{1e6}$ fold reduction in power consumption~\cite{yablonovitch08}.
Electronic circuits constructed using analog techniques~\cite{sarpeshkar98}, which sometimes rely on bio-inspired computational architectures show promise for reducing energy costs by up to five orders of magnitude~\cite{rapoport09,sarpeshkar98,mandal07}, depending on the nature of the computation and the required level of precision.

\autoref{fig:cmos} shows the power consumption per bit processed for several technology classes as well as the corresponding total power consumption required for whole brain readout, assuming a minimal whole-brain bit rate of \SI{100}{\giga\bit\per\second}.

\begin{figure}[htbp]
\caption{
Energy cost of elementary operations across a variety of recording and data transmission modalities, expressed in units of the thermal energy (left axis) and as a power assuming \SI{100}{\giga\hertz} switching rate (right axis). \hyperref[eq:landauer]{The Landauer limit} of $\kb T \ln 2$ sets the minimum energy associated with a logically irreversible bit flip. The a practical limit will likely lie in the tens of $\kb T$ per bit, comparable to the free energy release for hydrolysis of a single ATP molecule (or addition of a single nucleotide to DNA or RNA). The energy of a single infrared photon is \SI{\ca 50}{$\kb T$}. Single gates in current CMOS chips dissipate \SIrange{\ca 1e5}{1e6}{$\kb T$} per switching event, including the capacitive charging of the wires interconnecting the gates (red curve). The switching energy for the gate, not including wires, is \num{\ca 100}$\times$ lower (blue curve). The power efficiency of CMOS has been on an exponential improvement trend due to the miniaturization of components according to Moore's law (data re-digitized from~\cite{tucker11}), although power efficiency gains have slowed recently. Current RFID chips compute and communicate at \SIrange{\ca 1e9}{1e10}{$\kb T$} (\SI{>10}{\pico\joule}) per bit transmitted, while the total energy cost per floating point operation in a 2010 laptop was \SI{\ca 1e12}{$\kb T$}. The power associated with a minimal low-noise CMOS analog front end for signal amplification corresponds to \SI{\ca 500}{\milli\watt} at whole mouse brain scale. A single two-photon laser pulse at \SI{0.1}{\nano\joule} pulse energy corresponds to \SI{\ca 1e10}{$\kb T$}. For comparison, the \SI{40}{\milli\watt} approximate maximal power dissipation of a neural recording setup, according to \anref{sec:constraints} above, with its equivalent per-bit energy of \SI{\ca 1e8}{$\kb T$} at the minimal \SI{100}{\giga\bit\per\second} bit rate.
}
\label{fig:cmos}
\centering
\includegraphics[width=0.76\textwidth]{figs/Fig4.eps}
\end{figure}

\subsubsection{Powering Embedded Devices}

Embedded systems need power, which could be supplied via electromagnetic or acoustic energy transfer, or could be harvested from the local environment in the brain.

There are two key regimes for wireless electromagnetic power transfer: non-linear device rectification and photovoltaics.
If the single-photon energy is sufficient to allow electrons to move from the valence to the conduction band---that is, $\text{band gap} < h\nu/q$, where $q$ is the electron charge, $h$ is Planck's constant, and $\nu$ is the frequency of the photon---a photovoltaic effect can occur.
Otherwise, electromagnetic energy is converted to voltage by an antenna and non-linear device rectification may occur.
In this regime (single photon energy much lower than the band gap), power conversion is governed by the total RF power and by the impedances of the antenna and the rectifier, rather than by the individual photon energy.
For a monochromatic RF source, there is no thermodynamic or quantum limit to the RF to DC conversion efficiency, other than the resistive losses and threshold voltages for a semiconductor process.
For rectification, when the input voltage to the rectifier is much higher than a semiconductor process threshold, conversion efficiencies of \SI{85}{\percent} have been achieved~\cite{sun02}.
At low input voltages relative to the semiconductor process threshold, efficiencies as high as \SI{25}{\percent} and \SI{2}{\micro\watt} load have been achieved (see \cite{mandal07} for an analysis of power efficiency).
Ultimately, rectification improvements are dependent on the same improvements which will be needed for next-generation low-power computing: \si{\milli\volt} scale switching devices (promising research directions include tunnel FETs~\cite{ionescu11}, electromechanical relays~\cite{liu12} and other options).
Wireless power transfer also imposes range constraints due to the loss in power density with distance.
For directional power transfer, placing the receiver at the edge of the transmitter's near field (the Rayleigh distance $D^2/4\lambda$ where $D$ is the transmitter aperture) has advantages in terms of energy capture efficiency~\cite{ozeri10}, whereas for omni-directional antennas it is advantageous to place the receiver as close as possible to the transmitter.

Alternatively, if the photon energy is above the silicon band gap ($\lambda < \frac{h c}{qV\sub{th}} \approx \SI{3}{\micro\meter}$ or less for silicon), the chip is essentially acting as a photovoltaic cell.
There is no thermodynamic or quantum limit to the conversion efficiency of light to DC electrical power for monochromatic sources, other than resistive losses and dark currents in the material (\SI{86}{\percent} in GaAs for example~\cite{bett08}). 
In the use of infrared light for photovoltaics, the penetration of the photons through tissue is decreased compared to radio frequencies.
To supply \SI{10}{\micro\watt} (typical of current wirelessly-powered RFID chips) photovoltaically to a \SI{10 x 10}{\micro\meter} (cell sized) chip at \SI{34}{\percent} photovoltaic efficiency requires a light intensity of \SI{\ca 300}{\kilo\watt\per\meter\squared} at the chip, which is prohibitive.
Therefore, in order to be compatible with wireless power transfer, the power dissipation of embedded electronics must be decreased by several orders of magnitude.

Piezoelectric harvesting of ultrasound energy by micro-devices is also a possibility. The efficiency of electrical harvesting of mechanical strain energy in piezoelectrics can be above \SI{30}{\percent} for materials with high electromechanical coupling coefficients (e.g., PZT)~\cite{safari08, xu12}. The losses in the piezoelectric transduction process are well described by models such as the KLM model~\cite{krimholtz70,castillo03}.

An alternative to wireless energy transmission is the local harvesting of biochemical energy carriers. Implanted neural recording devices could conceivably be powered by free glucose, the main energy source used by the brain itself.
The theoretical maximum thermodynamic efficiency for a fuel cell in aqueous solution is equal to that of the hydrogen fuel cell: $\Delta G^0/\Delta H^0 = \SI{83}{\percent}$ at \SI{25}{\degreeCelsius}.
Furthermore, if glucose is only oxidized to gluconic acid, the Coulombic (electron extraction) efficiency is at most \SI{8.33}{\percent}~\cite{rapoport12}, which bounds the thermodynamic efficiency.
The blood glucose concentration in rats has been measured at \SI{\ca 7.6}{\milli\Molar}, with an extracellular glucose concentration in the brain of \SI{\ca 2.4}{\milli\Molar}~\cite{silver94}.
A hypothetical highly miniaturized neural recorder with a device area of \SI{25 x 25}{\micro\meter} and efficiency of \SI{80}{\percent}, processing a blood flow rate of \SI{\ca 1}{\milli\meter\per\second}~\cite{ivanov81} could extract $(\SI{80}{\percent})(\SI{7.6}{\milli\Molar})(\SI{25}{\micro\meter})^2(\SI{1}{\milli\meter\per\second})(\SI{2880}{\kilo\joule\per\mole})\approx \SI{11}{\micro\watt}$, which is sufficient for low-power device such as RFID chips~\cite{cho05}.
Unfortunately, current non-microbial glucose fuel cells obtain only \SI{\ca 180}{\micro\watt\per\centi\meter\squared} peak power and \SI{\ca 3.4}{\micro\watt\per\centi\meter\squared} steady state power~\cite{rapoport12}.
Thus there is a need for \num{1e4}- and \num{1e6}-fold improvements in peak and steady state power densities, respectively, for non-microbial glucose fuel cells to power brain-embedded electronics of the complexity of today's RFID chips (or better, the corresponding decrease in power requirements for the chips, as emphasized above).

\subsubsection{Conclusions and Future Directions}
The power consumption of today's microelectronic devices is more than 6 orders of magnitude higher than the physical limit for irreversible computing, and 2--3 orders of magnitude higher than would be permissible for use in whole brain millisecond resolution activity mapping, even under favorable assumptions on the required switching rates and neglecting both the power associated with noise rejection in the analog front end and the CMOS leakage current.
Thus, the first priority is to reduce the power consumption associated with embedded electronics.
In principle, methods such as infrared light photovoltaics, RF harvesting via diode rectification, or glucose fuel cells, could supply power to embedded neural recorders, but again, significant improvements in the power efficiency of electronics are necessary to enable this.
Other potential energy harvesting strategies include or materials/enzymes harnessing local biological gradients such in voltage, osmolarity, or temperature.
An analysis of the energy transduction potential of each of these systems is beyond the scope of this discussion.
Fortunately, with many orders of magnitude potential for improvement before physical limits are reached, we can expect that embedded nano-electronic devices will emerge as an energetically viable neural interfacing option at some point in the future.

\subsection{Embedded Devices: Information Theory}

Most recording methods envisioned thus far rely on the real-time transmission of neural activity data out of the brain.
Physics and information theory impose fundamental limits on this process, including a minimum power consumption required to transmit data through a medium.
The most basic of these results hold irrespective of whether the data transmission is wired or wireless, and regardless of the particular physical medium (optical, electrical, acoustic) used as the information carrier.

A communication ``channel'' is a set of transmitters and receivers that share access to a single physical medium with fixed bandwidth.
The bandwidth is the range of frequencies present in the time-varying signals used to transmit information.
In wireless communications, information is transmitted by modulating a carrier wave.
To allow modulation, the frequency of the carrier wave must be higher than the bandwidth: for example, a \SI{400}{\tera\hertz} visible light wave may be modulated at a \SI{100}{\giga\hertz} rate.
The physical medium underlying a channel could be a wire (with a bandwidth set by its capacitive RC time constant), an optical fiber, free space electromagnetic waves over a certain frequency range, or other media.

As a concrete example, consider a police department with \num{100} officers, each possessing a hand-held radio.
The radios transmit vocalizations by modulating an \SI{80}{\mega\hertz} carrier wave at \SI{\ca 10}{\kilo\hertz}.
This constitutes a single shared communications channel with \SI{10}{\kilo\hertz} bandwidth.
Simultaneously, the fire department may communicate via a separate channel, also with a bandwidth of \SI{\ca 10}{\kilo\hertz}, by modulating a \SI{90}{\mega\hertz} carrier wave.
The channels are separate because modulation introduced into one does not affect the other.
If the neighboring town's police department makes the mistake of also operating at 80 MHz carrier frequency, then they share a channel and conflicts will arise.

\subsubsection{Power Requirements for Single-Channel Data Transmission}

\begin{figure}[htbp]
\caption{%
Fundamental power requirements imposed by information theory on data transmission through a single (additive white Gaussian noise) channel with carrier frequency $\nu$ (an upper bound on the bandwidth), given thermal noise and path loss.
Bottom: absorption length of water as a function of frequency (blue), minimal power to transmit data at \SIlist{100;1000;10000}{\giga\bit\per\second} (green) as a function of frequency, assuming thermal noise but no path loss.
Top: minimal power to transmit data at \SIlist{100;1000;10000}{\giga\bit\per\second} as a function of frequency, assuming thermal noise and a path loss corresponding to the attenuation by water absorption over a distance of \SI{2}{\milli\meter}.
While formulated for a single channel, at certain wavelengths (e.g., RF) these factors also constrain multiplexed data transmissions between many transmitters and many receivers, depending on capacity of the system for spatial multiplexing.
Horizontal dashed lines: \SI{40}{\milli\watt}, the approximate maximal whole-brain power dissipation in steady state.
}
\label{fig:rfpower}
\centering
\includegraphics[width=0.78\textwidth]{figs/Fig5.eps}
\end{figure}

We first treat the case in which there is a single channel for transmitting data out of the brain. The Shannon Capacity Theorem~\cite{cover06} sets the maximal bit rate for a channel (assuming additive white Gaussian noise) to
\[R\sub{max} = \BW \log_2 \left(1 + \SNR\right)\]
where \BW is the channel bandwidth and $\SNR$ is the signal-to-noise ratio.
If there is only thermal noise the $\SNR = P/(N_0 \BW)$, where $N_0$ is the thermal noise power spectral density of $\kb T$ and $P=(\pathloss)P_0$ is the power of the transmitted signals $P_0$, weakened by path loss \pathloss.
Therefore the transmitted power $P_0$ is lower-bounded:
\[P_0 > \kb T\ \BW\ \frac{2^{R\sub{max}/\BW}-1}{\pathloss}\]
as shown in \autoref{fig:rfpower} (bottom).
In a minimal mode of a transmitter-receiver system, there thus exists a tradeoff between required signal power and the bandwidth of the carrier radiation, due to the thermal noise floor, even in the absence of path loss ($\pathloss = 1$).

Path loss weakens the proportion of the power that can reach the detector.
Using the above equation, we can calculate, as a function of bandwidth, the power necessary to transmit a target whole-brain bit rate of \SI{100}{\giga\bit\per\second} through a medium with path loss dependent on the carrier wavelength, as shown in \autoref{fig:rfpower} (top).

For RF wavelengths, the radiation penetrates deeply but the achievable data rates are low without excessive power consumption, due to the limited bandwidth.
For wavelengths intermediate between RF and infrared, the penetration depth is low and power must be expended to combat these losses, despite the high carrier bandwidth.
Only in the infrared and visible ranges do the tradeoffs between power, bandwidth and penetration depth allow transmission of \SI{>100}{\giga\bit\per\second} out of the brain through a single channel without unacceptable power consumption.

The analysis above has ignored the effects of noise sources other than thermal noise, but many additional noise sources will increase the amount of power needed to transmit data, via a decrease in the SNR at fixed input power.
For optical transmission in the brain, the noise is dominated by time-correlated ``speckle noise'' below \SI{200}{\kilo\hertz}, which arises mostly from local blood flow~\cite{carp11}.
This correlated noise, which cannot be filtered by simple averaging, could be avoided by modulating optical signals at frequencies above \SI{200}{\kHz}.

\subsubsection{Spatially Multiplexed Data Transmission}

As discussed above, transmitting information through a single channel imposes direct limits on bit rate, carrier frequency and input power.
However, it is conceivable to divide the data transmission burden over many independent channels, i.e., over many pairs of transmitters and receivers, each operating at lower bandwidth (e.g., at radio frequencies).
Indeed, this would be optimal in a scenario where many embedded devices measure and then transmit the activities of nearby neurons.
As a concrete example of such ``spatial multiplexing,'' an effective capacity of \SI{1}{\tera\bit\per\second} could conceivably be obtained by splitting the data over \num{1000} transmitter-receiver pairs each operating at \SI{1}{\giga\bit\per\second}, with the transmitters arranged in a \num{10 x 10 x 10} grid.
Importantly, in order to exceed the above limits for single-channel data transmission, it must be possible for these transmitter receiver pairs to share the same bandwidth and operate simultaneously without conflicts, for example by modulating distinguishable carrier waves or by transferring data over separate wires.
The conditions under which this may occur, however, can be counter-intuitive.
For example, for antennas to operate independently, they must be spaced apart from one another by roughly a wavelength.
For \SI{10}{\giga\hertz} microwaves, the wavelength is \SI{\ca 3}{\centi\meter}, so no more than a handful of microwave transmitters can co-occupy the mouse brain while operating independently.

Even with many non-independent transmitters co-occupying the brain and operating simultaneously over the same frequency spectrum, it may be possible under some conditions to ``factor out'' the effects of the coupling and allow an increase in channel capacity relative the single-channel result.
To treat such scenarios, a generalization to Shannon's capacity theorem to multi-input-multi-output (MIMO) channels has shown that the maximal total data rate is
\[R\sub{max} = \BW \cdot \log_2\left| \mat{I} + ( \SNR ) \mat{H}\mat{H}^* \right|\]
where $\mat{I}$ is the identity matrix, $|\cdot|$ denotes the matrix determinant, $\mat{H}$ is the ($M \times N$ for $N$ transmitters and $M$ receivers) channel matrix giving the coupling between the vector of transmitted signals and the vector of received signals and $\mat{H}^*$ denotes the matrix adjoint of $\mat{H}$ \cite{tulino04}. The vector of received signals is then $\vec{y}=\mat{H}\vec{x}+\vec{n}$ where $\vec{x}$ is the vector of transmitted signals and $\vec{n}$ is a noise vector. Any matrix can be written as $\mat{H}=\mat{U}\mat{\Sigma}\mat{V}^*$ where $\mat{U}$ and $\mat{V}$ are unitary matrices, and $\mat{\Sigma}$ is a diagonal matrix whose elements are the \emph{singular values} $\lambda_i$. One can re-write the above equation as
\[R\sub{max} = \BW \cdot \sum_{i=1}^{\min(M,N)} \log_2\left(1+\SNR \cdot \lambda_i^2\right)\]
If the matrix H is of full rank, then the capacity for the multi-channel system can increase over the single-input-single-output (SISO) result by min(M,N) times~\cite{shiu00}.
Note that the rank of the matrix corresponds to the number of non-zero singular values, so an analysis of the singular values of channel matrices can inform us about the multiplexing capacity of the channel.
Furthermore, this multiplexing capacity can in principle be achieved even when the transmitters are not in communication with each other, which could potentially be important for scenarios involving many brain embedded transmitters~\cite{spencer04}.

Transmission through a medium with negligible scattering is the simplest situation to analyze.
In this case, evaluating the matrix $\mat{H}$ requires knowledge of the transmitter-transmitter, transmitter- receiver, and receiver-receiver distances, as well as the orientations and radiation patterns of the antennas (e.g., high gain antennas will have a highly directional radiation pattern).
Depending on these factors, the beam from each transmitter will spread to impinge upon multiple receivers and the effective number of spatially independent beams will be reduced.
With transmitter-transmitter and receiver-receiver distances larger than the wavelength, and highly directional antennas with appropriately chosen orientations, it is possible to increase the channel capacity linearly with $\min(M,N)$.

Random scattering, in a coherent disordered medium where the mean free-path $\ell$ is much larger than the wavelength $\lambda$ and much smaller than the size of the disordered medium, is another condition where the matrix $\mat{H}$ is a random scattering matrix of full rank~\cite{moustakas00,popoff10}.
Intuitively, for the case of two transmitters and two receivers separated by a disordered medium larger than the mean free path:
if transmitter 1 is at least a mean-free path from transmitter 2 (or potentially as close as a few wavelengths~\cite{berkovits91}) the path from transmitter 1 to receiver 1 and the path from transmitter 2 to receiver 2 would be uncorrelated with respect to one another (in terms of physical path, phase, amplitude fluctuations, and other properties).
The rank of the matrix $\mat{H}$ would then be 2.
Devising a code on the transmitter such that the receivers can distinguish between these two uncorrelated streams results in a doubling of the capacity, rather than simply averaging the noise floor, which would provide only a logarithmic capacity gain due to the increased SNR.

Thus, contrary to intuition, a high degree of random scattering can potentially be useful for data transmission, by enabling spatial multiplexing of channels.
This idea has been demonstrated experimentally in the context of ultrasound transmissions~\cite{derode03}.
Biological tissue in the infrared range is well described as such a random scattering medium (e.g., mean free path \SI{\ca 200}{\micro\meter} at \SI{\ca 800}{\nano\meter} \emph{in vivo}).
Therefore infrared light could be used for spatially multiplexed data transmission out of the brain.
At wavelengths $\lambda$ comparable to critical brain dimensions in the mouse, however, an insufficient number of scattering events will occur to create multiple independent pathways for $N$ transmitters.
Mathematically, the matrix $\mat{H}$ will have one highly dominant singular value and a number of much smaller remaining terms, such that the signals appearing at a receiver from two separate transmitters will be highly linearly dependent, differing by only a small phase angle.
Therefore, there will be no capacity gain from multiple transmitters, and distinct transmitters will effectively share a single channel (reducing to the SISO result).

Little is known about the biological interaction with electromagnetic fields at wavelengths much shorter than the critical brain dimensions but beyond the infrared, approximately \SI{100}{\giga\hertz} (\SI{\ca 3}{\milli\meter}) to \SI{100}{\tera\hertz} (\SI{\ca 3}{\micro\meter}) in the mouse.
However, if multiple scattering occurs and the absorption is low, this may also be a regime conducive to MIMO communications~\cite{bakopoulos09,helmchen05}.
Efficiently generating and processing radiation in this regime by embedded devices is an outstanding problem, however.
The so-called ``THz-gap''~\cite{tonouchi07} exists because (moving towards higher frequencies starting from DC electronics), parasitic capacitances and passive losses limit the maximum frequency at which a field-effect transistor (FET) may oscillate and on the other hand (moving downward in frequency starting from optics), the band-gaps of opto-electronic devices limit the minimum frequency at which quantum transitions occur.
Thus there is no high-power, low-cost, portable, room temperature \si{THz} source available.
Advances in \si{THz} light generation, e.g. through the use of tunneling transistors, could be enabling.

\subsubsection{Ultrasound as a Data Transmission Modality}
An important caveat to these conclusions on wireless data transfer occurs if we consider the use of ultrasound rather than electromagnetic radiation
Because the speed of sound is dramatically slower than that of light, the wavelength of \SI{10}{\mega\hertz} ultrasound is only \SI{\ca 150}{\micro\meter} (approximating the speed of sound in brain as the speed of sound in water, \SI{\ca 1500}{\meter\per\second}).
Thus, many \SI{10}{\mega\hertz} ultrasound transmitters/receiver could be placed inside a mouse brain while maintaining their spatial separation above the wavelength, and a linear scaling of the MIMO channel capacity with the number of devices is likely possible in this regime, assuming that appropriate antenna gains and orientations can be achieved inside brain tissue. Beam orientation could present a challenge if micro-devices are oriented randomly after implantation.
With an attenuation of \SI{0.5}{\dB\per\centi\meter\per\mega\hertz}~\cite{hoskins10}, the attenuation at \SI{10}{\mega\hertz} is only \SI{5}{\dB\per\centi\meter}.
Thus ultrasound-baed transmission of power and data from embedded recording devices may be viable.

In contrast, direct imaging of neural activity by ultrasound (e.g., using contrast agents which create local variations in tissue elastic modulus or density) may be more difficult.
The wavelength of \SI{100}{\mega\hertz} ultrasound is \SI{\ca 15}{\micro\meter}, providing a theoretical diffraction limited spatial resolution that would be sufficient for resolving neuronal somas.
Practical transducer designs operating at this frequency achieve axial and lateral resolutions in the range of \SIrange{15}{60}{\um}~\cite{foster00}.
However, at these frequencies, power is attenuated by brain tissue with a coefficient of \SI{\ca 50}{\dB\per\centi\meter}~\cite{hoskins10} (\num{1e5}-fold attenuation per cm), which imposes a penetration limit (e.g., for
measurements with a dynamic range of 80 dB~\cite{foster00}).
Attenuation of ultrasound by bone is stronger still, at \SI{22}{\dB\per\cm\per\MHz}~\cite{hoskins10}.
Attenuation could therefore limit the use of ultrasound as a high-resolution neural recording modality in direct imaging modes, but multiplexed transmission of lower-frequency ultrasound from embedded devices could sidestep this issue.

\subsubsection{Conclusions and Future Directions}

Physics and information theory impose a tradeoff between bandwidth and power consumption in sending data through any communication channel.
Considering only thermal noise and no path loss, achieving \SI{100}{\giga\bit\per\second} data rates through a single channel necessitates either a bandwidth above a few \si{\giga\hertz} or a transmitted power above \SI{\ca 100}{\milli\watt}, the latter of which may be prohibitive from a heat dissipation perspective if the signals are to be generated by dissipative microelectronic devices.
Researchers have proposed to use thousands or millions of tiny~\cite{gomez10} wireless transmitters embedded in the brain to transmit local neural activity measurements to an external receiver via microwave radiation~\cite{dyson09}.
However, based on the above power-bandwidth tradeoff, this will require a bandwidth above a few \si{\giga\hertz}.
At the corresponding carrier frequencies, the penetration depth of the microwave radiation drops significantly, requiring increased power to combat the resulting signal loss.
While one might hope that multiple independent channels could be multiplexed inside the brain, reducing the bandwidth and power requirements for each individual channel, the long wavelengths of microwave radiation compared to the mouse brain diameter suggest that such channels cannot be independent, as is confirmed by an analysis of the multi-input-multi-output (MIMO) channel capacity for this scenario.
Therefore, radio-frequency electromagnetic transmission of whole brain activity data from embedded devices does not appear to be a viable option for brain activity mapping.
On the other hand, an analysis of the channel capacity for IR transmissions in a diffusive medium suggests that, because of its high frequency and decent penetration depth, infrared radiation may provide a viable substrate for transmitting activity data from embedded devices.
For example, data could be transmitted via modulating the multiple-scattering speckle pattern of infrared light by varying the backscatter from an embedded optical device, such as an LCD pixel, in an activity-dependent fashion.
Because the speckle pattern is sensitive to the motion of a single scatterer~\cite{berkovits91}, coherent multiple scattering could effectively act as an optical amplifier. Furthermore, multiplexed data transmission via ultrasound is likely possible because of its short wavelength in tissue at reasonable carrier frequencies.
It may also be of interest to explore network architectures~\cite{Bush2011} in which data is transmitted at low transmit power over short distances via local hops between neighboring nodes capable of signal restoration.

\subsection{Magnetic Resonance Imaging}

Magnetic resonance imaging (MRI) uses the resonant behavior of nuclear spins in a magnetic field to non-invasively probe the spatiotemporally varying chemical and magnetic properties of tissues.
Although originally conceived as a means to image anatomy, MRI can be used to observe neural activity provided such activity is reflected in dynamic changes in local chemistry or magnetism.

In an MRI study, a strong static field ($B = \SIrange{1}{15}{\tesla}$) is applied to polarize nuclear spins (usually \textsuperscript{1}H), causing them to resonate at a field-dependent Larmor frequency, $f=\gamma B$, where $\gamma$ is the gyromagnetic ratio of the nucleus (\SI{267.5222}{\mega\hertz\per\tesla} for \textsuperscript{1}H~\cite{codata10}).
To obtain positional information, spatial field gradients are applied such that nuclei at different positions in the sample resonate at slightly different frequencies.
Sequences of RF pulses and gradients are then applied to the sample, eliciting resonant emissions that contain information about spins' local chemical environment, magnetic field anisotropy and various other properties.

Most functional studies rely on dynamic changes in two forms of relaxation experienced by RF-excited spins.
The first form results from energy dissipation through interactions with other species (e.g. other spins or unpaired electrons), causing the spins to recover their lowest energy state on a timescale $T_1$ of \SIrange{100}{1000}{\milli\second}~\cite{rooney07}.
The second form of relaxation reflects the dephasing of spin signals in a given sampling volume (voxel) over a timescale $T_2$ of \SIrange{10}{100}{\milli\second}~\cite{deichmann95} due to non-uniform Larmor frequencies caused, e.g., by the presence of local magnetic field inhomogeneities.

In blood-oxygen level dependent functional MRI (BOLD-fMRI)---the most widely used form of neural MR imaging---increased neural activity in a given brain region alters the vascular concentration of paramagnetic deoxy-hemoglobin, which affects local magnetic field homogeneity and thereby alters $T_2$.
Although the existence of this paramagnetic reporter of oxygen metabolism is fortuitous, the data it provides is only an indirect readout of neural activity, which is limited in its spatial and temporal resolution to the dynamics of blood flow in the brain's capillary network (\SIrange{1}{2}{\second}).
A significant area of current and future work is aimed at developing new molecular reporters that can be introduced into the brain to transduce aspects of neural signaling such as calcium spikes and neurotransmitter release into MRI- detectable magnetic or chemical signals~\cite{shapiro10,koretsky12,hsieh12}.

\subsubsection{Spatiotemporal Resolution}

The temporal resolution of MRI is limited by the dynamics of spin relaxation. For sequential MR signal acquisitions to be fully independent, spins must be allowed to recover their equilibrium magnetization on the timescale of $T_1$ (\SIrange{100}{1000}{\milli\second}).
However, if local $T_1$ is static its pre- mapping could enable temporally variant $T_2$ effects to be observed at refresh rates on the faster $T_2$ timescale (\SIrange{10}{100}{\milli\second})~\cite{deichmann95}.
It may also be possible to detect events that occur on a timescale shorter than T1 and T2 if the magnitude of the resulting change in spin dynamics overcomes the lack of independence between acquisitions.
Note that these limitations on the repetition time of the underlying pulse sequence are not eliminated by ``fast'' pulse sequences such as echo-planar imaging (EPI)~\cite{stehling91} and fast low-angle shot (FLASH)~\cite{haase86} or by the use of multiple detector coils~\cite{wiesinger06}.
These techniques accelerate the acquisition of 2D and 3D images, but still require spins to be prepared for readout.

The spatial resolution of current MRI techniques is limited by the diffusion of water molecules during the acquisition time~\cite{glover02}, since contrast at scales above the diffusion length will be attenuated by diffusion.
The RMS distance of a water molecule from its origin, after diffusing in 3D for a time $T\sub{acq}$, is
\[d\sub{rms} = \sqrt{6D\sub{water}T\sub{acq}}\]
where $D\sub{water}=\SI{2300}{\micro\meter\squared\per\second}$ is the self-diffusion coefficient of water.
For $T\sub{acq}\approx\SI{100}{\milli\second}$, $d\sub{rms}\approx\SI{37}{\micro\meter}$, which sets the approximate spatial resolution.
For ultra-short acquisitions at $T\sub{act}\approx\SI{10}{\milli\second}$, $d\sub{rms}\approx\SI{12}{\micro\meter}$.

More technically, as described above, MRI uses field gradients to encode spatial positions in the RF frequency (wavenumber) components of the emitted radiation.
The quality of the reconstruction of frequency space thus limits the achievable spatial resolution.
$\Delta t$, the sampling interval of the detector, and the field gradient $G$, determine the wavenumber increment as
\[\Delta k = \gamma G \Delta t\]
The spatial resolution is then given by~\cite{glover02}:
\[\Delta x\sub{$k$-space} = \frac{\pi}{\frac{T\sub{acq}}{\Delta t} \Delta k} = \frac{\pi}{T\sub{acq} \gamma G}\]
Note that it is the gradient field, not the polarizing field $B_0$, which determines the resolution. For a gradient field of \SI{100}{\milli\tesla\per\meter} and an acquisition time of \SI{100}{\milli\second}
\[\Delta x\sub{$k$-space} = \frac{\pi}{\left(\SI{100}{\milli\second}\right)\left(\SI{267}{\MHz\per\tesla}\right)\left(\SI{100}{\milli\tesla\per\meter}\right)}\approx \SI{1.17}{\micro\meter}\]

Furthermore, due to relaxation, the emissions from a spin at a given position do not constitute a pure tone with a well-defined frequency. Instead, each spin exhibits a frequency spread, which gives rise to a spatial resolution~\cite{glover02}:

\[\Delta x\sub{relaxation} = \frac{2}{\gamma G T_2^*}\]
where $T_2^*$ is the shortest relaxation time. Assuming $T_2^*=\SI{5}{\milli\second}$ and $G=\SI{100}{\milli\tesla\per\meter}$, gives
\[\Delta x\sub{relaxation}\approx \SI{14}{\micro\meter}\]
Therefore, for water protons, the resolution limit is set by diffusion over \SI{\ca 100}{\milli\second} acquisition timescales. For other spin species (e.g., with lower diffusion rate), it may be possible to achieve resolutions limited by frequency discrimination.

Notably, there exists a practical trade-off between spatial resolution, temporal resolution, and sensitivity (SNR). In particular, to achieve high spatial resolution, it is necessary to densely sample $k$-space.
Fast sampling sequences such as FLASH and EPI achieve speed by sampling each point of $k$-space using less signal and often at a lower resolution.
Even at high field strengths (\SI{11.7}{\tesla}), this tradeoff results in practical EPI-fMRI with a spatial resolution of \SI{150 x 150 x 500}{\micro\meter} and a temporal resolution of \SI{200}{\milli\second}~\cite{yu12}.
Achieving much higher spatial resolutions requires longer acquisitions and/or lower temporal sampling.
For example, achieving a \SI{20}{\micro\meter} anatomical resolution in MRI of \emph{Drosophila} embryos required 54 minutes for a small field of view of \SI{2.5 x 2.5 x 5}{\milli\meter}~\cite{null08}.
Furthermore, the flies were administered paramagnetic gadolinium chelates to shorten $T_1$ and thereby the acquisition time.
Separately, frame rates of \SI{50}{\milli\second} have been obtained for dynamic imaging of the human heart, but required the use of strong priors to reduce data collection requirements~\cite{zhang10}.

\subsubsection{Energy Dissipation}

Energy is dissipated into the brain when the excited spins relax to their equilibrium magnetization in the applied field.
The energy associated with this relaxation is of order the Zeeman energy:
\[\Delta E\sub{Zeeman} = \gamma h B_0\]
To obtain an upper bound on the heat dissipation of MRI, we first assume that the brain is entirely water, that every proton spin is initially aligned by the field and then excited by the RF pulse, and that all spins relax during a $T_1$ relaxation time of \SI{\ca 600}{\ms}.
In this scenario, even an applied field of as high as \SI{\ca 40}{\tesla} would generate dissipation within the \SI{\ca 50}{\milli\watt} energy dissipation limit.
In reality, the energy dissipation is 4--5 orders of magnitude smaller, because only a tiny fractional excess of the spins are initially aligned by the field (\num{\ca 1e-5} for fields on the order of \SI{1}{\tesla}).
Therefore, thermal dissipation associated with spin excitation in MRI is unlikely to cause problems unless field strengths much greater than the largest currently fields used (\SI{\ca 20}{\tesla}) are invoked, or spins with much higher gyromagnetic ratios are used.

Practically, the main energy consideration in MRI is the absorption by tissues of RF energy applied during imaging pulse sequences and the switching of magnetic field gradients.
Such absorption is often calculated through numerical solutions of the Maxwell Equations taking into account the precise geometry, tissue properties and applied fields for a particular experimental setup~\cite{collins04}.
The typical specific absorption rate (SAR) is well under \SI{10}{\watt\per\kilogram} (or \SI{5}{\milli\watt} per \SI{500}{\milli\gram}), and is restricted by the FDA to less than \SI{3}{\watt\per\kilogram} for human studies.

\subsubsection{Imaging Agents}

All the preceding discussion about spatiotemporal resolution presumes the existence of local time-varying signals (e.g., changes in $T_1$ or $T_2$) corresponding to the dynamics of neural activity.
Such signals are not naturally present in the brain with the exception of the hemodynamic BOLD response, the limitations of which are discussed above.
In the past 15 years, efforts have been undertaken to develop chemical and biomolecular imaging agents that can be introduced into the brain to produce MRI detectable signals corresponding to specific aspects of neural function (analogously to fluorescent dyes and proteins).
Notable examples include $T_1$ and $T_2$ sensors of calcium~\cite{atanasijevic06,li99} and a $T_1$ sensor of neurotransmitter release~\cite{shapiro10}.
Depending on their mode of action, these imaging agents can provide temporal resolutions ranging from \SI{10}{\milli\second} to \SI{10}{\second}~\cite{shapiro06}.
However, a major current limitation for fast agents is the requirement that they be present in tissues at \si{\micro\Molar} concentrations, posing major challenges for delivery and genetic expression.

\autoref{fig:mriresolution} shows the achievable temporal resolution for various classes of activity-dependent MRI contrast agents as well as the spatial resolution limit due to water proton diffusion.

\begin{figure}[htbp]
\caption{Key factors determining the spatiotemporal resolution of dynamic MRI imaging. (a) Temporal resolution and contrast agent concentration allowing \SI{>5}{\percent} contrast, for different classes of dynamic MRI contrast agent (reproduced from~\cite{shapiro06}, with permission). (b) Diffusion limited spatial resolution for water proton MRI as a function of temporal resolution.}
\label{fig:mriresolution}
\centering
\includegraphics[width=0.78\textwidth]{figs/Fig6.eps}
\end{figure}

\subsubsection{Conclusions and Future Directions}

Current MRI techniques rely on the excitation of proton spins in water, however, and are thus limited to imaging at \SI{>100}{\ms} timescales unless SNR is severely compromised, due to the low polarizability and long $T_1$ relaxation time of proton spins.
There is also a spatial resolution limit of tens of microns over these timescales due to water's fast diffusion. Methods which couple neural activity to non-diffusible, highly polarized spins could in principle ameliorate this situation.

\subsection{Molecular Recording}

An alternative to electrical, optical or MRI recording is the local storage of data in molecular substrates.
Each neuron could be engineered to write a record of its own time-varying electrical activities onto a biological macromolecule, allowing off-line extraction of data after the experiment.
Such systems could, in principle, be genetically encoded, and would thus naturally record from all neurons at the same time.

One proposed implementation of such a ``molecular ticker tape'' would utilize an engineered DNA polymerase with a Ca\textsuperscript{2$+$}-sensitive or membrane-voltage-sensitive error-rate~\cite{zamft12} to record time-varying neural activities onto DNA~\cite{glaser13} as patterns of nucleotide misincorporations relative to a known template DNA strand (for alternative local recording techniques see~\cite{friedland09,bonnet13}).
The time-varying signal would later be recovered by DNA sequencing and subsequent statistical analysis~\cite{glaser13}.
DNA polymerases found in nature can add up to \num{\ca 1000} nucleotides per second~\cite{kelman95}, and non-replicative polymerases such as DNA polymerase $\iota$ may have error rates of \SI{>70}{\percent} on template T bases~\cite{frank07}.
Similar strategies could be implemented using RNA polymerases or potentially using other enzyme/hetero-polymer systems.

\subsubsection{Spatiotemporal Resolution}

An analysis of the projected temporal resolution of molecular ticker-tapes as a function of polymerase biochemical parameters can be found in~\cite{glaser13}.
This work suggests that molecular ticker tapes are unlikely to record at \SI{<10}{\ms} temporal resolution for durations longer than seconds in the absence of engineered polymerases with kinetic parameters beyond the limits of those found in nature, even when \num{10000} templates per cell are recorded simultaneously.
Recording at lower temporal resolutions, however, appears feasible using naturalistic biochemical parameters.
Mechanisms to improve synchronization of the ensemble of polymerases within each cell, or to encode time-stamps into the synthesized DNA, could improve temporal resolution and decrease the number of required template strands per neuron.

\subsubsection{Energy Dissipation}
% swap paragraphs?
\paragraph{Nucleotide metabolism}
DNA polymerization imposes a metabolic load on the cell.
Replication of the 3 billion bp human genome takes approximately eight hours in normally dividing cells, which equates to a nucleotide incorporation rate of \SI{\ca 100}{\kHz}.
Therefore, in order not to exceed the metabolic rates associated with normal genome replication, molecular ticker tapes operating at \SI{1}{\kHz} polymerization speed~\cite{kelman95} would be limited to approximately 100 simultaneously replicated templates per cell.
Even more recordings would be possible for RNA ticker tapes.
The mammalian cell polymerizes at least \num{1e11} NTPs per 16-hour cell cycle (data from HeLa cells)~\cite{jackson00}.
Therefore, \num{\ca 1,700} RNA tickertapes, each operating at \SI{1}{\kHz}, could be placed in a cell before generating a metabolic impact equal to that of the cell's baseline transcription rate.
While these comparisons to baseline physiological levels are reasonable guidelines, it is likely that a neuron can support higher metabolic loads associated with larger numbers of templates.
The maximal rate of neuronal aerobic respiration is \SI{\ca 5}{\femto\mole} of ATP minute via oxidative respiration (see the section on bio-luminescence). Assuming \num{\ca 1} ATP equivalent consumed per nucleotide incorporation, if neuronal metabolism were entirely dedicated to polymerization, it could support the incorporation of up to \num{6e9} nucleotides per minute, or \num{1e5} simultaneously replicated DNA templates at \SI{1}{\kHz}. % ATP *per* minute?

\paragraph{Power dissipation}
Normal DNA and RNA synthesis do not produce problematic energy dissipation and molecular tickertapes will likewise not be highly dissipative, at least in the regime where nucleic acid polymerization rates do not exceed those associated with genome replication or transcription.

\subsubsection{Volume Displacement}

The nucleus of a neuron occupies \SI{\ca 6}{\percent} of a neuron's volume ($(\SI{4}{\um})^3/(\SI{10}{\um})^3$).
Ticker tapes operating at \SI{1}{\kHz} with \num{10000} simultaneously replicated templates could record for \num{300} seconds before the total length of DNA synthesized equals the human genome length.
In the case of RNA polymerase II-based transcription, \SI{2.75}{\hour} of recording by \num{10000} recorders is required to reach the net transcript length in the cell.
Therefore, with appropriate mechanisms to fold/pack the nucleic acids generated by molecular ticker tapes, they would not impose unreasonable requirements on cellular volume displacement over minutes to hours.

\subsubsection{Conclusions and Future Directions}

Molecular recording of neural activity has the advantages of inherent scalability, single-cell precision, and low energy and volume footprints.
Making molecular recording work at temporal resolutions approaching \SI{1}{\kHz}, however, will require multiple new developments in synthetic biology, including protein engineering to create a fast polymerase (\SI{>1}{\kHz}) that strongly couples proxies for neural activity to nucleotide incorporation probabilities.
An attractive potential payoff from molecular approaches to activity mapping is the prospect of seamlessly combining---within a single brain---the readout of activity patterns with the readout of structural connectome barcodes~\cite{zador12}, transcriptional profiles (cell type information) or other (epi-)genetic signatures which are accessible via high-throughput nucleic acid sequencing.


\section{Discussion}

We have analyzed the physical constraints on scalable neural recording for selected modalities of measurement, data storage, data transmission and power harvesting.
Each analysis is based on assumptions -- about the brain, device physics, or system architecture -- which may be violated.
Understanding these assumptions can point towards strategies to work around them, and in some cases we have suggested possible directions for such workarounds.
Even valid assumptions about natural brains may be subject to modification through synthetic biology or external perturbation.
Notably, methods for rapidly removing heat from the brain could be important for supporting a range of highly dissipative recording modalities, while assumptions about transmission bandwidth may be relaxed if some information is stored locally and read out after the fact.

We have not considered all possible recording modalities here.
For example, modalities like X-ray imaging have been used on live cells~\cite{moosmann13} and might find use in neural recording if suitable contrast agents could be devised.
X-rays interact with electron shells via photoelectric absorption and Compton scattering and with band structure in materials.
X-ray phosphors utilize substitutions in an ionic lattice to generate visible or UV light emission upon X-ray absorption~\cite{issler95}.
In principle, some of these mechanisms could be engineered as neural activity sensors, e.g., in an absorption-contrast mode suitable for tomographic reconstruction~\cite{larabell04}.
Similarly, electron spin resonance operates at $\ca$100$\times$ higher Larmor frequency compared to proton MRI which improves polarizability of the spins.
Due to Pauli exclusion, use of this technique requires unpaired electrons, which can be found e.g. in nitrogen vacancy diamond nano-crystals~\cite{horowitz12}, which are also highly voltage sensitive~\cite{dolde11} and amenable to optical control and readout of the spin state.

Our analysis illustrates challenges and opportunities for technology development.
While we have shown that MRI is limited by the diffusion of water, using non-diffusible spins could in principle allow micron resolutions.
While light scattering creates severe limitations on optical imaging, and multi-photon approaches are highly dissipative, embedded optical microscopies or novel fluorescent or bio-luminescent indicators (e.g., operating in the infrared) could overcome these limits.
Novel contrast agents that exploit unused parts of the EM spectrum could allow entirely new forms of imaging.
Ultra-low-power electronics is required to perform recording locally, but molecular recording devices could sidestep power constraints on electronics, at the cost of decreased temporal resolution, lack of real-time readout, and increased engineering complexity.
New signal processing architectures such as compressive sensing could reduce bandwidth requirements and inspire new microscope designs.
Hybrid techniques such as photo-acoustic~\cite{filonov12} or ultrasound-encoded optical~\cite{wang12} microscopies could result in performance greater than the sum of the component technologies.
Combining activity information with structural information could allow static and dynamic information to disambiguate one another.

Our goal here has not been to pick winners, but to aid a broad community in analyzing the problem.
A challenge of this magnitude requires a return to first principles, and a fundamental reconsideration of the architectures of neural recording systems, not just incremental improvement of existing methods.
We hope that knowledge of the constraints governing scalable neural recording will enable the invention of entirely new, transformative approaches.

\section{Acknowledgments}

We thank K. Esvelt for helpful discussions on bioluminescent proteins; D. Boysen for help on the fuel cell calculations; R.~Tucker and E.~Yablonovitch (\url{http://www.e3s-center.org}) for helpful discussions on the energy efficiency of CMOS; C.~Xu and C.~Schaffer for data on optical attenuation lengths; T. Dean and the participants in his CS379C course at Stanford/Google, including Chris Uhlik and Akram Sadek, for helpful discussions and informative content in the discussion notes (\url{http://www.stanford.edu/class/cs379c/}); and R.~Koene, S.~Rezchikov, A.~Bansal, J.~Lovelock, A.~Payne, R.~Barish, N.~Donoghue, J.~Pillow, W.~Shih and P.~Yin for helpful discussions.

A.~Marblestone is supported by the Fannie and John Hertz Foundation fellowship.
D.~Dalrymple is supported by the Thiel Foundation.
K.~Kording is funded in part by the Chicago Biomedical Consortium with support from the Searle Funds at The Chicago Community Trust.
E.~Boyden is supported by the National Institutes of Health (NIH), the National Science Foundation, the MIT
McGovern Institute and Media Lab, the New York Stem Cell Foundation Robertson Investigator
Award, the Human Frontiers Science Program, and the Paul Allen Distinguished Investigator in
Neuroscience Award.
B.~Stranges, B.~Zamft, R.~Kalhor and G.~Church acknowledge support from the Office of Naval Research and the NIH Centers of Excellence in Genomic Science.
M.~Shapiro is supported by the Miller Research Institute, the Burroughs~Wellcome Career~Award~at~the~Scientific Interface and the W.M. Keck Foundation.

\printbibliography[notsubtype=hide]

\end{document}
