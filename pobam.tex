\input preamble
\addbibresource{pobam_.bib}

\title{Physical Principles for Scalable Neural Recording}

\author[1,2]{\ \lift{$\jointfirst\,$}Adam~H.~Marblestone\rlap{,}}
\author[3]{\lift{$\jointfirst\,$}Bradley~M.~Zamft\rlap{,}}
\author[3,4]{Yael~G.~Maguire\rlap{,}}
\author[5]{Mikhail~G.~Shapiro\rlap{,}}
\author[6]{Thaddeus~R.~Cybulski\rlap{,}}
\author[6]{Joshua~I.~Glaser\rlap{,}}
\author[14]{Dario~Amodei\rlap{,}}
\author[3]{P.~Benjamin~Stranges\rlap{,}}
\author[3]{Reza~Kalhor\rlap{,}}
\author[1,7,8]{David~A.~Dalrymple\rlap{,}}
\author[9]{Dongjin~Seo}
\author[9]{Elad~Alon\rlap{,}}
\author[9]{Michel~M.~Maharbiz\rlap{,}}
\author[9,13]{Jose~M.~Carmena\rlap{,}}
\author[9]{Jan~M.~Rabaey\rlap{,}}
\author[$\jointlast$8,10]{Edward~S.~Boyden\rlap{,}}
\author[$\jointlast$1,2,3]{George~M.~Church\rlap{,}}
\author[$\jointlast$11,12]{Konrad~P.~Kording}

\affil[$\jointfirst$]{Joint first authors}
\affil[$\jointlast$]{Joint last authors}

\newcommand\et{{\em \&}}

\definecolor{deemph}{gray}{0.48}
\affil[1]{Biophysics {Program,} Harvard {Univ., Boston,~MA~02115, USA}}
\affil[2]{Wyss Institute {for Biologically Inspired Engineering at} Harvard {Univ., Boston,~MA~02115, USA}}
\affil[3]{{ Dept.\ of Genetics,} Harvard Medical School{, Boston,~MA~02115, USA}}
\affil[4]{Plum Labs LLC, Cambridge,~MA{~02142, USA}}
\affil[5]{Division of Chemistry and Chemical Engineering, California Institute of Technology{, Pasadena,~CA~91125, USA}}
\affil[6]{{Interdepartmental} Neuroscience {Program,} Northwestern Univ.{, Chicago,~IL~60611, USA}}
\affil[7]{Nemaload, San Francisco, CA{~94107, USA}}
\affil[8]{Media Lab{oratory,} Massachusetts Institute of Technology{, Cambridge,~MA~02139, USA}}
\affil[9]{{Dept.\ of} Electrical Engineering and Computer Science{, Univ. of California at} Berkeley{, Berkeley,~CA~94720, USA}}
\affil[10]{{Depts.\ of} Brain and Cognitive Sciences {\et\ of} Biological Engineering, Massachusetts Institute of Technology{, Cambridge,~MA~02139, USA}}
\affil[11]{{Depts.\ of} Physical Medicine and Rehabilitation {\et\ of} Physiology, Northwestern Univ.{\ Feinberg} School of Medicine{, Chicago,~IL~60611,~USA}}
\affil[12]{{Sensory Motor Performance Program,} The Rehabilitation Institute of Chicago{, Chicago,~IL~60611,~USA}}
\affil[13]{Helen Wills Neuroscience Institute, Univ. of California at Berkeley, Berkeley,~CA~94720, USA}
\affil[14]{Department of Radiology, Stanford University, Palo Alto, ~CA~94305, USA}

\renewcommand{\maketitlehookc}{{\small\raggedright Correspondence to: \texttt{adam.h.marblestone\,\textnormal{(at)}\,\,gmail.com}}}

\begin{document}
%\fontfamily{ugm}\selectfont
\maketitle
\pagestyle{plain}
\thispagestyle{empty}
%\captionwidth{0.8\linewidth}
%\changecaptionwidth

\begin{fquote}[Freeman Dyson][Imagined Worlds][1997]To understand in depth what is going on in a brain, we need tools that can fit inside or between neurons and transmit reports of neural events to receivers outside. We need observing instruments that are local, nondestructive and noninvasive, with rapid response, high band-width and high spatial resolution\ldots\hfill\ There is no law of physics that declares such an observational tool to be impossible.\end{fquote}

\begin{abstract}
\noindent
Simultaneously measuring the activities of all neurons in a mammalian brain at millisecond resolution is a challenge beyond the limits of existing techniques in neuroscience.
Entirely new approaches may be required, motivating an analysis of the fundamental physical constraints on the problem.
We outline the physical principles governing brain activity mapping using optical, electrical, magnetic resonance, and molecular modalities of neural recording.
Focusing on the mouse brain, we analyze the scalability of each method, concentrating on the limitations imposed by spatiotemporal resolution, energy dissipation, and volume displacement.
Based on this analysis, all existing approaches require orders of magnitude improvement in key parameters.
Electrical recording is limited by the low multiplexing capacity of electrodes and their lack of intrinsic spatial resolution,
optical methods are constrained by the scattering of visible light in brain tissue,
magnetic resonance is hindered by the diffusion and relaxation timescales of water protons,
and the implementation of molecular recording is complicated by the stochastic kinetics of enzymes.
Understanding the physical limits of brain activity mapping may provide insight into opportunities for novel solutions.
For example, unconventional methods for delivering electrodes may enable unprecedented numbers of recording sites,
embedded optical devices could allow optical detectors to be placed within a few scattering lengths of the measured neurons,
and new classes of molecularly engineered sensors might obviate cumbersome hardware architectures.
We also study the physics of powering and communicating with microscale devices embedded in brain tissue and find that, while radio-frequency electromagnetic data transmission suffers from a severe power--bandwidth tradeoff, communication via infrared light or ultrasound may allow high data rates due to the possibility of spatial multiplexing.
The use of embedded local recording and wireless data transmission would only be viable, however, given major improvements to the power efficiency of microelectronic devices.
\end{abstract}

\section{Introduction}
Progress in neuroscience depends on recording the electrical activities of neurons within functioning brains~\cite{alivisatos2012brain, bansal2012decoding}, and  the field has seen remarkable improvements in the underlying technologies. For example, the number of neurons simultaneously recorded using wired electrodes has doubled every seven years since the 1950s, currently allowing electrical observation of hundreds of neurons at millisecond timescales~\cite{stevenson11}. Recording techniques have also diversified: activity-dependent optical signals from neurons endowed with fluorescent indicators can be measured by photodetectors, and radio-frequency emissions from excited nuclear spins allow the construction of magnetic resonance images modulated by activity-dependent contrast mechanisms.
Ideas for alternative methods have been proposed, including the direct recording of neural activities into information-bearing biopolymers~\cite{zamft12,glaser13,kording11a}.

Each modality of neural recording has characteristic advantages and disadvantages.
Multi-electrode arrays enable the recording of \num{\ca 250} neurons at sub-millisecond temporal resolutions.
Optical microscopy can currently record \num{\ca 100000} neurons at a \SI{1.25}{\second} timescale in behaving larval zebrafish using light-sheet illumination~\cite{ahrens13}, or hundreds to thousands of neurons at a \SI{\ca100}{\milli\second} timescale in behaving mice using a 1-photon fiber scope~\cite{ziv13}.
Magnetic resonance imaging (MRI) allows non-invasive whole brain recordings at a \SI{1}{\second} timescale in humans, but is far from single neuron spatial resolution.
Finally, molecular recording devices have been proposed for scalable physiological signal recording but have not yet been demonstrated in neurons~\cite{zamft12,glaser13,kording11a}.

\autoref{fig:modalities} illustrates the recording modalities studied here.
While further development of these methods promises to be a crucial driver for future neuroscience research \cite{NeuroscienceThinksBigAndCollaboratively}, their fundamental scaling limits are not immediately obvious. Furthermore, inventing new technologies for scalable neural recording requires a quantitative understanding of the engineering problems that such technologies must solve: a landscape of constraints which should inform design decisions.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth]{figs/Fig1.eps}
\caption{Four generalized neural recording modalities. (a) \emph{Extracellular electrical recording} probes the voltage due to nearby neurons. (b) \emph{Optical microscopy} detects light emission from activity-dependent indicators. In two-photon laser scanning microscopy, shown here, an excitation beam at 2$\times$ the peak excitation wavelength of the fluorescent indicator is scanned across the sample, while an integrating detector captures the emitted fluorescence. (c) \emph{Magnetic resonance imaging} typically detects radio-frequency magnetic induction signals from aqueous protons, after weak thermal alignment of the proton spins by a static magnetic field. A resonant radio-frequency pulse tips the spins into a plane perpendicular to the static field, causing the net magnetization to precess. The resulting signals are affected by the local chemical and magnetic environment, which can be altered dynamically by imaging agents in response to neural activity. Activity-dependent contrast agents are necessary to transduce neural activity into an MRI readout, whereas current functional MRI methods rely on blood oxygenation signals which cannot reach single-neuron resolution. (d) \emph{Molecular recording} devices have been proposed, in which a “ticker-tape” record of neural activity is encoded in the monomer sequence of a biomolecular polymer – a form of nano-scale local data storage. This could be achieved by coupling correlates of neural activity to the nucleotide misincorporation probabilities of a DNA or RNA polymerase as it replicates or transcribes a known DNA strand.}  \label{fig:modalities}

\end{figure}

Our analysis is predicated on assumptions that enable us to estimate scaling limits.
These include assumptions about basic properties of the brain, which are treated in \anref{sec:constraints}, as well as those pertaining to the required measurement resolution and the limits to which a neural recording method may perturb brain tissue, which are treated in \anref{sec:challenges}.
Together, these considerations form the basis for our estimates of the prospects for scaling of neural recording technologies.
We analyze four modalities of brain activity mapping---electrical, optical, magnetic resonance and molecular---in light of these assumptions, and conclude with discussion on opportunities for new developments.

Importantly, our assumptions, analyses and the conclusions thereof are intended as \emph{first approximations and are subject to debate}.
We anticipate that as much can be learned from where our logic breaks down as from where it succeeds, and from methods to work around the limits imposed by our assumptions.

\section{Basic Constraints}
\label{sec:constraints}

\paragraph{Mouse brain}
The mouse brain contains \num{\ca 7.5e7} neurons in a volume of \SI{\ca 420}{\milli\meter\cubed}~\cite{vincent10} and weighs about \SI{0.5}{\gram}.
For comparison, the human brain has roughly \num{8e10} neurons~\cite{azevedo09} in a volume of \SI{1200}{\centi\meter\cubed}~\cite{allen02}.
The human brain consumes \SI{\ca 15}{\watt} of power (performing, at synapses, a rough equivalent of at least \num{1e17} floating point computational operations per second on that power budget, according to one definition~\cite{sarpeshkar10}).
Because power consumption scales approximately linearly with the number of neurons~\cite{houzel11}, the mouse brain is expected to utilize \SI{\ca 15}{\milli\watt} (for comparison, the metabolic rate of the \SIrange{\ca 20}{30}{\gram} mouse is \SIrange{\ca 200}{600}{\milli\watt} depending on its degree of physical activity~\cite{speakman13}).

\paragraph{Neural activities}
Action potentials (spikes) last \SI{\ca 2}{\milli\second}.
The rate of neuronal spiking is highly variable. Some authors have assumed an average rate of \SIrange{\ca 4}{5}{\hertz}~\cite{sarpeshkar10, harris2012synaptic}, but certain neurons spike at \SI{500}{\hertz} or faster~\cite{gittis10}, while many neurons spike much more slowly. In particular, cerebellar granule cells, which make up half of the neurons in the brain, have spontaneous firing rates of \SI{\ca 0.5}{\hertz} \cite{chadderton2004integration}. In neocortex, one analysis estimated 0.16 spikes per second per neuron (in primate) as energetically sustainable \cite{lennie2003cost}. There may be as much as a two-fold change in metabolism and hence firing rate across brain states \cite{howarth2012updated}. Certain neurons (possibly up to 90$\%$ for some neuron types in some brain areas) may be effectively silent \cite{Shoham2006, Barth2012345} (e.g., spiking less than once every ten seconds). Some studies have attempted to measure the distribution of neural firing rates in various cortical areas (as opposed to just the average rate), and have observed that these distributions are often long-tailed: a small minority of the neurons fires a majority of the spikes \cite{roxin2011distribution, oconnor2010neural, hromadka2008sparse, shafi2007variability}. While these estimates of  typical firing rates are useful numbers to have in mind, in the below we aim to sample all neurons at rates approaching \SI{1}{\kilo\hertz} (or higher for techniques requiring observation of detailed spike waveforms). The activities of neurons can be highly correlated locally or across large networks \cite{schneidman2006weak}. Measuring spike timing with millisecond precision is relevant for understanding network function \cite{markram2011history, Babadi2013, Taillefumier27032013, Gire2013416}. 

\paragraph{Absorption and scattering of radiation}

\begin{figure}[htbp]
\caption{%
Penetration depth (attenuation length) of electromagnetic radiation in water vs. wavelength (data from \cite{jonasz07}).
The approximate diameter of the mouse brain is shown as a black dashed line.
Inset: approximate tissue model based on Mie scattering theory and water absorption. Absorption length of water~\cite{kou93} (blue), tissue scattering length in a simple Mie scattering model (red) and the attenuation length (green) of infrared light calculated based on these approximations (inset reproduced from \cite{kou93}, with permission).}
\label{fig:attenuation}
\centering
\includegraphics[width=0.5\linewidth]{figs/Fig2.eps}
\end{figure}

All existing methods of neural recording utilize electromagnetic waves, from the near-DC frequencies of wired electrical recordings (\SI{\ca 1}{\kilo\hertz}) to the radio-frequencies of wireless electronics and fMRI (MHz--GHz) to visible light in optical approaches (\SI{\ca 500}{\tera\hertz}).
These electromagnetic waves are attenuated in brain tissue by absorption and scattering.
As an approximation to the electromagnetic absorption of brain tissue, we treat the absorption by water, the brain's main constituent (\SIrange{68}{80}{\percent} by mass in humans \cite{dobbing73,fatouros99}).
At visible and near-IR wavelengths, there is far worse scattering than absorption: absorption lengths are in the \SI{\ca 1}{\milli\meter} range, while scattering lengths are \SIrange{\ca 25}{200}{\micro\meter}~\cite{Wilt2009}. The combined effect of absorption and scattering is measured by the attenuation length, the distance over which the signal strength is reduced by $1/e$ along a path.
\autoref{fig:attenuation} shows the absorption length of water~\cite{kou93}, and the attenuation length in a Mie scattering model (from \cite{horton13}) intended to approximate the scattering properties of cortical tissue (and see \cite{gabriel1996} for tissue skin depth measurements in the \SI{10}{\hertz} to \SI{100}{\giga\hertz} range).
This gives a preliminary indication of which wavelengths can be used to measure deep-brain signals with external detectors. Note that the attenuation length is only one of several relevant metrics. Importantly, scattering not only causes signal attenuation, but also causes noise and impairs signal separation, so the magnitude of the scattering is a key figure of merit.

\section{Challenges for Brain Activity Mapping}
\label{sec:challenges}
Any activity mapping technology must ideally extract the required information without disrupting normal neuronal activity.
As such, we consider three primary challenges:

\subsection{Spatiotemporal Resolution and Informational Throughput}

A sampling rate of \SI{1}{\kilo\hertz} is necessary to capture the fastest trains of action potentials at single-spike resolution.
A minimal data rate of \num{7.5e10} bits processed per second is then required to record 1 bit per mouse neuron at \SI{1}{\kilo\hertz}.

In electrical recording, higher sampling rates (e.g. \SIrange{10}{40}{\kilo\hertz}) are often necessary to distinguish neurons based on spike shapes when each electrode monitors multiple neurons.
More fundamentally, one bit per neuron sampling at \SI{1}{\kilo\hertz} would likely not be sufficient to reliably distinguish spikes above noise: transmitting \SI{\ca 10}{\bit} samples at \SI{\ca 10}{\kilo\hertz} (full waveform) or \SIrange{\ca 10}{20}{\bit} time-stamps upon spike detection would be more realistic.

Conversely, it may be possible to locally compress measurements of a spike train before transmission.
The degree of compressibility of neural activity data is related to the variability in the distribution of neural responses (e.g., such a distribution may be defined across time bins or repeated stimulus presentations)~\cite{strong98}.
In the blowfly \textit{Calliphora vicina}, the entropy of spike trains has been measured to be up to \SI{\ca 180}{\bit\per\second}, and the information about a stimulus encoded by a spike train was as high as \SI{\ca 90}{\bit\per\second}~\cite{strong98}. Extrapolating from fly to mouse, this would suggest that in the worst case, a compression factor of 5$\times$--10$\times$ should be possible, relative to a \SI{1000}{\bit\per\second} raw binary sampling. As a na\"{\i}ve estimate of the entropy as a function of firing rate, one can write the entropy $H$ in \si{\bit\per\second}, assuming \SI{1}{\milli\second} long spikes and \SI{1000}{\hertz} sampling rate, as
\[H \approx \left(-P\sub{spike}\cdot\log_2\!\left(P\sub{spike}\right) - \left(1 - P\sub{spike}\right)\cdot\log_2\!\left(1 - P\sub{spike}\right)\right) \cdot \SI{1000}{\bit\per\second}\]

where $P\sub{spike}$ is the probability of spiking during the sampling interval.
For the average firing rate of \SI{5}{\hertz}, $P\sub{spike}=0.005$ and $H=\SI{45}{\bit\per\second}$, corresponding to a compression factor of $\ca 20\times$.
However, at \SI{500}{\hertz}, $P\sub{spike}=0.5$ with $H\approx\SI{1000}{\bit\per\second}$, i.e., there is no compressibility. 
Therefore, compression could conceivably reduce the data transmission burden for activity mapping by 1--2 orders of magnitude, depending on the neurons and activity regimes under consideration. Note that these compressibility calculations have assumed that firing patterns are independent across cells; they represent the temporal compressibility of the spike train from each cell, treated individually. Patterns across cells could conceivably be compressed by a much larger amount, to the extent that there is redundancy between cells. Based on the above, we assume \SI{1}{\bit\per neuron\per\milli\second} or \SI{100}{\giga\bit\per\second} for the entire mouse brain, as a ``minimal whole brain data rate'' in what follows.
In many cases, this likely constitutes a lower bound on what will be feasible in practice.

\subsection{Energy Dissipation}

Brain tissue can sustain local temperature increases ($\Delta T$) of \SI{\ca 2}{\celsius} without severe damage over a timescale of hours and, in rats, changes of this magnitude may occur naturally in response to varying activity levels \cite{Wolf2008}.
Assuming that the brain is receiving a constant power influx $P\sub{delivered}$ and that the local thermal transport properties of mouse brains are similar to those of humans, we can approximate the temperature change in deep-brain tissue as a function of the applied power \cite{sotero11, Lazzi2005}:
\[\frac{\od T}{\od t} = \left.\left(P\sub{delivered} + P\sub{metabolic} - \rho\sub{blood} C\sub{blood}\,f\sub{blood} \Delta T\right)\right/C\sub{tissue}\]
where $P\sub{metabolic} = \SI{0.0116}{\watt\per\gram}$ is the power per unit mass of basal metabolism, $C\sub{tissue} \approx \SI{3.7}{\joule\per\kelvin\per\gram} \approx 0.88\cdot C\sub{water}$ is the specific heat capacity of brain tissue, $\rho\sub{blood}=\SI{1.05}{\gram\per\centi\meter\cubed}$ is the density of blood, $C\sub{blood} = \SI{3.9}{\joule\per\kelvin\per\gram}$ is the specific heat capacity of blood, $f\sub{blood} = \SI{9.3e-9}{\meter\cubed\per\gram\per\second}$ is the volume flow rate of blood, and $\Delta T$ is the temperature difference between the brain tissue and the blood (at temperature \SI{37}{\celsius}).
A steady-state temperature increase ($\od T/\od t = 0$) of \SI{2}{\celsius} corresponds to a power dissipation of \SI{\ca 40}{\milli\watt} per \SI{500}{\milli\gram} mouse brain.
Therefore, a recording technique should not dissipate more than \SI{\ca 40}{\milli\watt} of power in a mouse brain at steady state.

This estimate of the power dissipation limit in mouse brains may be an under-estimate of the actual maximum steady-state power dissipation. 
Radiative loss of heat from the brain was ignored here since infrared light emitted by deep-brain tissue is quickly re-absorbed by nearby tissue.
We have also assumed that conductive heat loss is negligible at the whole-brain scale compared to the heat extracted by blood flow.

Higher power levels may be introduced into brains transiently.
According to the above equation, if a neural recorder dissipates \SI{\ca 40}{\milli\watt} per \SI{500}{\milli\gram} mouse brain, then the brain approaches the steady-state temperature in \SIrange{2}{3}{\minute}, making shorter experiments potentially feasible.
Increasing convective heat loss from the brain by increasing blood flow (e.g. via increased heart rate) or cooling the brain, the blood, the cerebrospinal fluid (CSF), or the whole animal~\cite{polderman2004}, could increase the allowable transient or steady-state power dissipation.

There are also limits on the power density of radiation applied to brain tissue.
For radio-frequency electromagnetic radiation, the specific absorption rate (SAR) limit on the power density exposed to human tissue (calibrated for \SI{\ca 1}{\celsius} temperature change) is \SI{\ca 10}{\milli\watt\per\centi\meter\squared}, while for ultrasound (which couples less strongly to dissipative loss mechanisms in tissue) the SAR limit is up to 72$\times$ higher.
The power density limit for visible and near-IR light exposures are also in the \SIrange{\ca 10}{100}{\milli\watt\per\centi\meter\squared} range for \SI{\ca 1}{\milli\second} long exposures, decreasing as the exposure time lengthens (based on the IEC 60825 formulas~\cite{iec60825}).

High local power dissipation (transient or steady-state) can also modify the electrical properties of excitable membranes, altering neuronal activity patterns.
For example, heating of cell membranes and surrounding solution by millisecond optical pulses leads to changes in membrane electrical capacitance mediated by the ionic double layer~\cite{shapiro12}.
Slower temperature changes (on a scale of seconds) resulting from RF radiation lead to accelerated ion channel and transporter kinetics~\cite{shapiro13}.
Both of these effects are appreciable when the temperature changes are on the order of \SIrange{1}{10}{\degreeCelsius}.

The above calculations are rough estimates, and further work (e.g., a whole-head simulation~\cite{Lazzi2005}) is needed to define the limits of volumetric heat production by neural recording systems distributed throughout the mouse brain. For comparison, common guidelines for chronic heat exposure from biomedical implants \cite{Wolf2008} use upper limits of \SI{2}{\celsius} temperature change, \SI{40}{\milli\watt\per\centi\meter\squared} heat flux from the surface of implanted brain machine interface (BMI) hardware, and an SAR limit of \[\frac{\sigma E^2}{2 \rho} < \SI{1.6}{\milli\watt\per\gram}\] for electromagnetic energy absorbed by tissue, where $E$ is the peak electric field amplitude of the applied radiation, $\sigma \approx \SI{0.18}{\siemens\per\meter}$ is the electrical conductivity of grey matter and $\rho \approx \SI{1}{\gram\per\centi\meter\cubed}$ is the tissue density \cite{Lazzi2005} (corresponding to an irradiance of $\epsilon_0 c E^2 / 2 \approx \SI{2.4}{\milli\watt\per\centi\meter\squared}$). A 96-channel BMI system demonstrated in living brains had dissipated areal power density approaching \SI{40}{\milli\watt\per\centi\meter\squared}~\cite{rizk2009}.

\subsection{Sensitivity to Volume Displacement}

To prevent damage to the brain, we assume that a recording technique should not cause a brain volume change of \SI{> 1}{\percent}. The appropriate damage threshold is not yet established, however, so this constitutes a first guess. One important consideration in this regard would be the disruption of blood circulation by inserted material; a high density of implanted material in a brain region could cause stroke due to widespread vascular damage. Recent studies have defined in microscopic detail the complete vascular network of the mouse cortex using high-throughput histology~\cite{Kleinfeld2013}; this type of information could be used to enumerate key vascular pathways which could be spared from damage. To apply this in a particular animal, however, would require a non-destructive method to image the vasculature at a similar resolution; otherwise, only a broad statistical view can be obtained, since the detailed vascular geometry will vary from animal to animal.

It is possible to insert large numbers of probes throughout multiple brain areas without compromising function. In rats, 96 electrodes of \SI{50}{\micro\meter} diameter were simultaneously inserted across four forebrain structures (cortex, thalamus, hippocampus and putamen)~\cite{Ribeiro2004}. In rhesus macaque, 704 electrodes of diameter \SI{50}{\micro\meter} and average depth \SI{2.5}{\milli\meter} were chronically implanted in cortex~\cite{Nicolelis2003}. Note, however, that the total volume displacement in these experiments was below \SI{0.1}{\percent}, and below \SI{0.01}{\percent}, respectively.  Furthermore, these studies used a low density of electrodes. Thus, detailed limits on the amount and density of inserted material are unknown.

The nature of the volume displacement is important---sheets of instrumentation that sever long-range connectivity, for example, would disrupt normal brain function regardless of the degree of volume displacement.
Conversely, higher volume displacement might be possible if introduced gradually, or during early development, insomuch as the brain can adapt without disrupting natural computation.

\section{Evaluation of Modalities}

We next evaluate neural recording technologies with respect to the above challenges, using the mouse brain as a model system.
\autoref{table:strategies} lists the modalities studied, the assumptions made, the analysis strategies applied, and the conclusions derived.

\begin{table}[htbp]
\caption{Summary of modalities, models, assumptions and conclusions}
\label{table:strategies}
\centering
\footnotesize
\tabulinesep=1mm
\newcommand{\iskip}{\par\vspace{3pt}}
\begin{tabu} to\linewidth{>{\itshape}X[2,l]X[2.5]X[4,l]X[5]}
\toprule
\rowfont[C]{\upshape\bfseries\small}
Modality & Analysis Strategy & Assumptions & Conclusions \\
\cmidrule[0.4pt](lr){1-1}
\cmidrule[0.4pt](lr){2-3}
\cmidrule[0.4pt](lr){4-4}

Extracellular electrical recording &
Compute minimal number recorders based on max distance from recorder to recorded neuron &
{Decay profile of extracellular voltage
\iskip Approximate noise levels at recording site}
&
{Maximum recording distance $r\sub{max}\approx\SIrange{100}{200}{\micro\meter}$ from electrode to neuron measured
\iskip \num{\ca 100000} recording sites are required per mouse brain at current noise levels
\iskip However, $\ca\num{1e7}$ electrodes are required in practice to enable sorting of noisy, temporally overlapping spikes using current algorithms}
\\

Implanted electrical recorders &
Compute power dissipation of electronic devices that digitally sample neuronal activity &
Physical limit: $\left.\kb T\ln\left(2\right)\right/\si{\bit}$ erased \iskip
Practical limit: $\left.\ca 10 \kb T\right/\si{\bit}$ processed \iskip
Current CMOS digital circuits: $\left.\num{>1e5}\kb T\right/\si{\bit}$ processed &
Requires at least 2--3 orders of magnitude increase in the power efficiency of electronics relative to current devices to scale to whole-brain simultaneous recordings \iskip
Minimalist architectures should be developed to reduce local data processing overhead
\\

Wireless data transmission &
Compute tradeoff between power efficiency and channel bandwidth using information theory &
Transmitter must supply enough power to overcome noise and path loss &
Data transmission at optical or near-optical frequencies is necessary to achieve sufficient single-channel data rates using electromagnetic radiation. Radio-frequency (RF) electromagnetic transmission of whole-brain data would draw excessive power due to bandwidth constraints
\iskip Bandwidth cannot effectively be split over multiple independent RF channels, but IR light or ultrasound may allow spatial multiplexing
\\

Optical imaging &
Relate the scattering and absorption lengths of optical wavelengths in brain tissue to signal-to-noise ratios for optical imaging &
Approximate values of scattering and absorption lengths as a function of wavelength &
Light scattering imposes severe limits on optical techniques, but strategies exist which could negate the effects of scattering, such as implantable optics, infrared fluorescence or bioluminescence, and online inversion of the scattering matrix
\\

Multi-photon optics &
Compute minimum total excitation light power to excite multi-photon transitions from indicators within each neuron in every imaging frame &
Approximate values of multi-photon cross-sections \iskip
Pulse durations similar to those currently used in multi-photon imaging &
Whole-brain multi-photon excitation will over-heat the brain except in very short experiments, unless ultra-bright inorganic indicators are used
\\

Beam scanning microscopies &
Calculate device and indicator parameters necessary for fast beam repositioning and signal detection &
Fast optical phase modulators could reposition beams at \SI{\ca 1}{\giga\hertz} switching rates \iskip
Fluorescence lifetimes in the \SIrange{0.1}{1.0}{\nano\second} range &
Beam repositioning time limits the speed of current systems but we are far from the physical limits of scan speed \iskip
Fluorescence lifetimes of indicators may constrain design of ultra-fast scanning microscopies
\\

Magnetic resonance imaging &
Calculate spatial and temporal resolution of MRI based on spin relaxation times and spin diffusion &
Proton MRI using tissue water \iskip
Approximate values of $T_1$ and $T_2$ relaxation times and self-diffusion times for tissue water &
To a first approximation, proton MRI is limited by the $T_1$ relaxation time of water to \SI{\ca 100}{\milli\second} temporal resolution and by the self-diffusion of water to spatial resolutions of \SI{\ca 40}{\micro\meter}. $T_1$ pre-mapping could allow $T_2$ contrast on a \SI{\ca 10}{\milli\second} timescale
\\

Ultrasound &
Calculate spatial resolution, signal strength and bandwidth limits on ultrasound imaging &
Speed of sound in brain \iskip
Attenuation rate of ultrasound in brain &
Attenuation of ultrasound by brain tissue and bone may be prohibitive at the \SI{\ca 100}{\mega\hertz} frequencies needed for single-cell resolution ultrasound imaging \iskip
Ultrasound may be a viable medium for spatially multiplexed data transmission from embedded devices~\cite{Seo2013}
\\

Molecular recording &
Compute metabolic load and DNA volume for rapid synthesis of large nucleic acid polymers \iskip
Evaluate temporal resolution in simulated experiments using kinetic models &
Polymerase biochemical parameter ranges \iskip
Metabolic requirements of genome replication &
Molecular recording devices appear to fall within physical limits but their development poses major challenges in synthetic biology

\\\bottomrule
\end{tabu}
\end{table}

\subsection{Electrical Recording}

In the oldest strategy for neural recording, an electrode is used to measure the local voltage at a recording site, which conveys information about the spiking activity of one or more nearby neurons.
The number of recording sites may be smaller than the number of neurons recorded since each recording site may detect signals from multiple neurons.
Traditional electrical recording techniques keep active devices such as amplifiers outside the skull and therefore do not pose a heat dissipation challenge; this may change if amplifiers are brought closer to the signal sources to reduce noise.

\subsubsection{Spatiotemporal Resolution}

\paragraph{Limits assuming perfect spike-sorting}
We begin with an idealized estimate of the number of electrodes required to record from the entire mouse brain, neglecting the difficulty of assigning observed spikes to specific cells (spike sorting), and focusing only on what is needed to detect spikes from every neuron on at least one electrode.  The key variable here is the 
maximum distance between an extracellular electrical recorder and a neuron from which it records spikes.
In a first approximation, this is determined by two factors: the decay of the signal with distance from the spiking neuron and the background noise level at the recording site.
We assume that for an electrode to reliably detect the signal from a given neuron, the magnitude of that neuron's signal must be larger than the electrode's noise level. Note, however, that knowledge of spike shape distributions could potentially be used to extract low-amplitude spikes from noise.

The peak signals of spikes from neurons immediately adjacent to an electrode are in the \SIrange{0.1}{1.0}{\milli\volt} range and scale roughly as $e^{-r/r_0}$, where $r$ is the distance from the cell surface and the $1/e$ falloff distance $r_0$ has been experimentally measured at \SI{\ca 28}{\micro\meter} in both~\cite{Shoham2006} salamander retina~\cite{segev04} and cat cortex~\cite{gray95}, and computed at \SI{\ca 18}{\micro\meter} in a biophysically realistic simulation~\cite{gold07}.
However, this decay is strongly influenced by the detailed geometry of neuronal currents and the properties of the extracellular space, making analytical calculation of the decay rate difficult (at large distances, a much slower $1/r^2$ dipole falloff is expected).

Several sources of background noise enter the recordings.
Johnson noise, which arises from thermal fluctuations in the electrode, is \[V\sub{johnson} = \left(4\kb T Z \BW\right)^{1/2}\]
which for physiological temperature, electrodes of impedance $Z = \SI{0.5}{\mega\ohm}$, and $\BW = \SI{10}{\kilo\hertz}$ bandwidth is $V\sub{johnson} \approx \SI{9}{\micro\volt}$.
The recordings are also affected by interference from other neurons, which has been reported to exceed the Johnson noise, and is non-stationary due to changes in the cells' firing properties~\cite{sahani99}. 
The noise and interference from these sources realistically produces \SIrange{>10}{20}{\micro\volt} of voltage fluctuations~\cite{camunas13}.
Current recording setups thus have signal to interference-plus-noise ratios (SINRs) of \num{<100}, where the SINR is defined as the ratio of the peak voltage from immediately adjacent neurons to the voltage fluctuation floor of the electrode.

A limit on the maximum recording distance is the distance at which the signal from the farthest neuron falls below the noise floor, $r\sub{max} \approx r\sub{0}\ln(\text{SINR})$. For $\text{SINR} \approx 100$, $r\sub{max} \approx \SI{130}{\micro\meter}$. For comparison, recent experimental data from multi-site silicon probes has shown few detectable neurons beyond \SI{\ca 100}{\micro\meter} and none detectable beyond \SI{160}{\micro\meter}~\cite{du11}. 
Recordings in the hippocampal CA1 region could not detect spikes from cells farther than \SI{140}{\micro\meter} from the electrode tip \cite{Henze2000}, even after averaging over observations triggered on an intracellularly recorded spike; in hippocampus, this corresponds to a detection volume containing approximately 1000 neurons \cite{Buzaki2004}. Furthermore, in many studies (in monkeys, rats and mice) using multi-electrode arrays with \SIrange{150}{300}{\micro\meter} inter-electrode spacings, no neuron is seen by more than one electrode \cite{Wessberg2000, Carmena2003, Koralek2012, Jin2010}.

Due to the steep local falloff, even improving the SINR by a factor of 10 only extends the maximal recording distance to $r\sub{max} \approx \SI{190}{\micro\meter}$. Assuming packing of the brain into equal sized cubes of side length $d = \frac{2}{\sqrt{3}}r\sub{max} \approx \SI{150}{\micro\meter}$ gives $N > 130000$ electrodes for whole brain recording using recording sites with $r\sub{max} \approx \SI{130}{\micro\meter}$. Note that N varies as the third power of $r\sub{max}$ and is therefore highly sensitive to variations in the assumed maximal recording distance; the number of required recorders can range from \num{38000} to \num{210000} as $r\sub{max}$ varies from \SI{190}{\micro\meter} to \SI{110}{\micro\meter}.

These calculations assuming perfect spike-sorting will greatly underestimate the required number of electrodes in practice.
First, signals from the weakest cells are far weaker than those from the strongest cells and the signals from some cells decay much faster than others~\cite{gray95}.
Second, because of neuronal synchronization, the local noise produced by nearby neurons may sometimes be large. 
Finally, with many neurons per electrode or at high firing rates, spikes from detectable neurons will often temporally overlap, making spike sorting difficult.

\begin{figure}[htbp]
\caption{
The voltage signal to interference-plus-noise ratio (SINR) for neurons immediately adjacent to the recording site sets an approximate upper bound on the distance, $r\sub{max}$, between the recording site and the farthest neuron it can sense (blue), due to the exponential falloff of the voltage SINR with distance.
Assuming at least one electrode per cube of edge length $\frac{2}{\sqrt{3}}r\sub{max}$ in the mouse brain in turn limits the number of neurons per recording site (gold), the total number of recording sites (red) and the diameter of wiring consistent with \SI{<1}{\percent} total brain volume displacement (turquoise).
SINR values for current recording setups are \num{<1e2}.
In practice, the number of neurons per electrode distinguishable by current spike-sorting algorithms is only \num{\ca 10}, with an estimated information theoretic limit of \num{\ca 100}, so these curves \emph{greatly under-estimate} the number of electrodes which would be required based on realistic spike-sorting approaches in a pure voltage-sensing scenario.
}
\label{fig:snrlimits}
\centering
\includegraphics[width=0.7\textwidth]{figs/Fig3.eps}
\end{figure}

\paragraph{Limits from spike sorting}

The previous calculations have assumed that any spike which is visible above the noise on at least one electrode can be detected and correctly assigned to a particular cell, i.e., that the problem of spike sorting can be solved perfectly.  
However, perfect spike sorting is far beyond current algorithmic capabilities and in fact may not be possible in principle. 

To achieve the scenario described above, with $N=\num{130000}$ recording sites per mouse brain, would require each electrode to sort spikes from all 
$\frac{4}{3} \pi r_0^3 \rho_{\text{neurons}}$ neurons in a sphere of radius $r_0 \approx \SI{130}{\micro\meter}$ surrounding the recording site, where $\rho_{\text{neurons}}$ is the density of neurons. Using the total number of neurons and the total mouse brain volume from above to obtain the average neuron density \[\rho_{\text{neurons}} \approx \frac{\num{7.5e7}}{\SI{420}{\milli\meter\cubed}} \approx \SI{179000}{\per\milli\meter\cubed}\] gives $>\num{1600}$ neurons within view of a single electrode. In the below, however, we will assume a cell density of $\rho_{\text{neurons}} \approx \SI{92000}{\per\milli\meter\cubed}$, as measured for mouse cortex \cite{braitenberg1991anatomy}. This assigns $\ca \num{800}$ neurons to a single electrode. Roughly half (i.e., \num{400}) of these neurons will lie at $>\SI{100}{\micro\meter}$ distance from the electrode and their signals on the electrode will therefore have voltage SINRs of $ < \num{100} \times e^{-\SI{100}{\micro\meter}/\SI{28}{\micro\meter}} \approx \num{2.8}$, assuming as above that extracellular spike amplitudes decay exponentially in space.
  
Electrical recording can be viewed as a data transmission problem, with the electrode playing the role of a communication channel (see section 4.4). According to the  Shannon Capacity Theorem~\cite{cover06}, the information capacity $C$ of a single analog channel (with additive white Gaussian noise)  is \[C = B \log_2 (1 + S/N)\] where $B$ is the bandwidth, $S$ is the signal power ($\propto$ voltage squared), and $N$ is the noise power. With bandwidth $B \approx \SI{10}{\kilo\hertz\per\second}$ and $S/N \approx \num{2.8}^{\num{2}}$, the channel capacity is $C \approx \SI{30}{\kilo\bit\per\second}$. This represents the maximum amount of information (e.g., about which neuron spiked when) that the population of spiking neurons can transmit via the electrode which measures them. To transmit \emph{uniquely identifiable} signals from all \num{400} neurons at millisecond temporal precision, however, requires $\SI{1}{\kilo\bit\per\second} \times 400 = \SI{400}{\kilo\bit\per\second}$, which is $>\num{10}\times$ greater than the channel capacity and is therefore not achievable.  Even with optimal temporal compression of $\ca \SI{5}{\hertz}$ spikes (see section 2), we would need to transmit $\ca 400/20 = \SI{20}{\kilo\bit\per\second}$: this is strictly less than the channel capacity and thus is possible in principle, but barely so.  

Thus, based on these rough estimates, perfect spike sorting may not be possible at $\ca \num{800}$ neurons per electrode, in a sphere of radius \SI{130}{\micro\meter} surrounding a recording site, at the noise levels typical of current electrodes. In essence, there may not be enough room on the electrode’s voltage trace to discriminate such a large number of weak, noisy signals. Note that these information-theoretic limits still apply even if it is possible to resolve temporally overlapping spikes. In fact, the channel capacity is what ultimately limits the ability of a spike-sorting algorithm to resolve such overlapping spikes.

Now suppose that each electrode is only responsible for spike sorting from the population of $\ca \num{100}$ neurons nearest to the electrode, i.e., in a sphere of radius $r \approx \SI{64}{\micro\meter}$, assuming the \SI{92000}{\per\milli\meter\cubed} cell density from mouse cortex. The outermost \num{50}$\%$ of these neurons are then positioned $>\SI{50}{\micro\meter}$ from the recording site. For these outermost \num{50} neurons, the voltage SINR is $ < \num{100} \times e^{-\SI{50}{\micro\meter}/\SI{28}{\micro\meter}} \approx \num{17}$ and $S/N \approx 17^2$. The channel capacity is then $\ca \SI{82}{\kilo\bit\per\second}$, whereas \SI{50}{\kilo\bit\per\second} is needed for signal transmission from \num{50} neurons without temporal compression versus \SI{\ca 2.5}{\kilo\bit\per\second} with temporal compression. Even 100 neurons per electrode may therefore still be close to the limits of information transmission through the noisy channel corresponding to a single electrode.

In practice these numbers are likely to be highly optimistic, since the set of spikes emerging from a neuronal population is far from an optimally designed code from the perspective of multiplexed signal transmission through a voltage-sensing electrode: the waveforms for different neurons are similarly-shaped rather than orthogonal, the spikes emitted by a given neuron vary somewhat in amplitude and exhibit shape fluctuations (signal-dependent noise), and it is not known in advance what the characteristic signal from each neuron looks like (or even how many neurons there are). 

Indeed, current practice is far from the above information-theoretic limits. At present, spike sorting algorithms operating on data from large-scale (\num{250}-\num{500} electrodes) densely spaced (\SI{\ca 30}{\micro\meter}) 2D multi-electrode arrays can reliably identify and distinguish spikes from nearly all of the \num{200}-\num{300} retinal ganglion cells~\cite{marre12,pillow13} in a small patch of retina, and can also infer approximate cell locations through spatial triangulation of spike amplitudes.  This represents a roughly $1:1$ ratio of cells to electrodes.  If we assume that these algorithms perform as well in 3D as in 2D and do not break down for larger numbers of neurons (and proportionately larger numbers of electrodes), $N=\num{7.5e7}$ electrodes would presently be required to record from all mouse neurons, which could correspond to recording sites placed on the vertices of a \num{\ca 400 x 400 x 400} site cubic lattice with \SI{\ca 20}{\micro\meter} edge length.  In practice, 3D geometry will increase the number of spikes that register on any given electrode. This could potentially worsen performance, by increasing noise and temporal overlap of spikes, or alternatively it could improve performance, by providing extra information for spike identification and triangulation.

It is difficult to assess the limits of the current state of the art spike sorting algorithms, because they presently succeed in detecting nearly all the cells in a region using dense arrays, but they have not been extensively tested in cases where electrodes are sparser.  Furthermore, many techniques optimize for signal separability (e.g. hand-placed tetrodes), not for the number of recorded neurons, so it is difficult to extrapolate their performance.  Optimistically, simulations of neural activity suggest that \num{5}-\num{10} neurons per electrode may be distinguishable using current spike sorting algorithms~\cite{pedreira12,sahani99,camunas13}, although these simulations are based on a small number of electrodes (tetrodes or single units) and may not generalize to large-scale recording.  A limit of $\ca\num{10}$ neurons per electrode would imply $N=\num{7.5e6}$ electrodes to record from all neurons in the mouse brain, which could be accomplished by positioning recording sites on a cubic lattice with \SI{\ca 40}{\micro\meter} edge length.

Future algorithmic improvements could enable sorting from more than $\ca\num{10}$ cells per electrode, but this becomes an increasingly challenging computational task as spike amplitudes decrease by an exponential factor, temporal overlaps between spikes become more common, and spikes from a given cell appear on a smaller number of electrodes.  One simple estimate of a reasonable practical limit, for the regime of many neurons per electrode, would be the largest number of neurons that can be sorted without requiring the frequent resolving of temporally overlapping spikes: if the average neuron fires at \SI{\ca 5}{\hertz} and spikes last \SI{\ca 2}{\milli\second}, then at most roughly \num{100} neurons per electrode can be sorted without requiring overlaps to be resolved.  Note that while some present-day algorithms can successfully resolve overlapping spikes,~\cite{marre12,pillow13,segev04,ge2011,prentice2011} they do so only in the case where electrodes are densely spaced and any given spike appears on many electrodes, such that spatial information can be used to resolve the overlap.  Resolving overlaps when spikes appear on only one or a few channels (as would be the case when there are $>\num{100}$ neurons per electrode) is much more difficult due to extrinsic noise and spike-shape variation.

Overall,  $\ca\num{100}$ cells per electrode may be taken as a rough estimate of the limits of spike sorting, and would imply $N = \num{750000}$ electrodes and an edge spacing of \SI{\ca 80}{\micro\meter} if a cubic lattice of recording sites were used.  However, we should not exclude the possibility of game-changers which could alter the nature of the recorded data to improve the available information. For instance, CCD cameras could be attached to multi-electrode arrays to aid in the identification and localization of cells, or directional information on the source of spikes could be obtained at each recording site, for example by measuring the directions of gradients in voltage. Systems that capture additional information in this manner could circumvent the above information-theoretic limits and improve spike sorting performance.

\subsubsection{Volume Displacement}

We require \SI{<1}{\percent} total volume displacement from $N$ recorders.
Wires from each electrode must make it to the surface of the brain, which implies an average length $\ell\approx\SI{4}{\milli\meter}$ for the mouse brain (depending on assumptions about the wiring geometry).

As a rough approximation, consider each recorder to produce a volume displacement associated with a single cylindrical wire, with length $\ell$ and radius $r$.
Thus $r$ must satisfy \[\pi r^2\ell N\sub{min,rd} < 0.01V\sub{brain}\]
Using $N\sub{min,rd} =$ \num{210000} or \num{38000} recording sites and $\ell\approx\SI{4}{\milli\meter}$ requires wires of radius $r\sub{max} \approx \SI{6.0}{\micro\meter}$, or \SI{2.5}{\micro\meter}, respectively. 
Even using $\num{7.5e6}$ electrodes, the required wire radius is \SI{\ca 200}{\nano\meter}.
While these dimensions are readily achievable using lithographic fabrication, there would be a challenge to produce \emph{isolated} wires of such dimensions at scale (perhaps suggesting the use of wire bundles).
Still, volume constraints per se are unlikely to fundamentally limit whole-mouse-brain electrical recording even in the most pessimistic scenario (e.g., assuming current spike-sorting capabilities).

\autoref{fig:snrlimits} illustrates the above considerations as a function of the electrode SINR.

\subsubsection{Implanting Electrodes in the Brain}

There are several technology options for introducing many electrodes into a brain.
For example, flexible nanowire electrodes could, in theory, be threaded through the capillary network~\cite{llinas05}.
Capillaries are present in the brain at a density of \SIrange{2500}{3000}{per \milli\meter\cubed}~\cite{schmidt89}, which equates to one capillary per \SI{73}{\micro\meter}, with each neuron lying within \SI{\ca 200}{\micro\meter} of a capillary~\cite{loffredo08}. The minimum capillary diameter is as small as \SIrange{3}{4}{\micro\meter}, although the average diameter is \SI{\ca 8}{\micro\meter}, comparable to the non-deformed size of the red blood cells \cite{Freitas1999}. Blocking a significant fraction of capillaries could lead to stroke or to unacceptable levels of tissue necrosis/liquifaction.
The cerebrospinal ventricles may also provide a convenient location for recording hardware. Furthermore, neural tissues could be grown around pre-fabricated electrode arrays~\cite{jadhav12}, or silicon probes arrays with many nano-fabricated recording sites per probe~\cite{du11} could be inserted into the brain.

Mechanical forces during insertion and retraction of silicon and tungsten microelectrodes from brain tissue have been measured in rat cortex at \SI{\ca 1}{\milli\newton} for electrodes of \SI{\ca 25}{\micro\meter} radius~\cite{jensen03}.
These forces are comparable to the Euler bucking force $F$ of a \SI{2}{\milli\meter} long cylindrical tungsten rod of $r=$\SI{5}{\micro\meter} radius
\[F=\frac{\pi^2 E I}{(K L)^2} \approx \SI{1}{\milli\newton}\]
where $E=\SI{411}{\giga\pascal}$ is the elastic modulus of tungsten, $I=(\pi/2)r^4$ is the area moment of inertia of the cylindrical wire cross-section, $L\approx\SI{2}{\milli\meter}$ is the length of the wire, and $K$ is the column effective length factor which depends on the boundary conditions and is set to $K=1$ here for simplicity.
This suggests that it may be possible to push structures of \SI{<10}{\micro\meter} diameter into brain tissue (see \cite{najafi90} for related calculations). It might be advantageous to pull rather than push wires into the brain (e.g., using applied fields, or cellular oxen~\cite{Weibel23082005} to carry the wires), since the thinnest wires could withstand tension forces much higher than the compressive force at which they buckle (although there may be ways to circumvent buckling, e.g., via rapid vibration).

\subsubsection{Conclusions and Future Directions}

Electrical recording has the advantage of high temporal resolution, but the large number of required recording sites poses challenges for delivery mechanisms.
Ongoing innovations in electrical recording that could be leveraged for dramatic scaling include the development of highly multiplexed probes, multilayer lithography for routing electrical traces, novel methods to implant large numbers of electrodes, smaller electrode impedances to reduce the Johnson noise, amplifiers with lower input-referred noise levels, spike sorting algorithms capable of handling temporally overlapping spikes and adaptively modeling the noise, and hybrid systems integrating electrical recording with implantable optics or other methods.

One challenge for a purely-electrical recording paradigm pertains to the ability to relate the measured electrical signals to specific cells within a circuit.
As the set of neurons recorded by each electrode grows to encompass a large volume around the electrode, it will become more difficult to attribute the recorded spikes to particular neurons.
Furthermore, given the complex geometries of neuronal processes, it is not obvious how to determine the spatial position or layout of a neuron from its electrical signature on a nearby electrode. A given electrode will be positioned near the axons or dendrites of some neurons, and near the cell bodies of other neurons, complicating data interpretation. If the spatial density of recording sites is increased such that many electrodes sample the same neuron, however, this could enable imaging of neuronal morphology and signal propagation via voltage signals across multiple electrodes \cite{bakkum2013tracking}. Currently, extracellular recording also does not allow extraction of molecular information on the cells being recorded, although intracellular electrophysiological recording methods (e.g., \cite{Kodandaramaiah2012}) might enable this for a limited number of cells.

\subsection{Optical Recording}

Optical techniques measure activity-dependent light emissions from neurons, typically generated by fluorescent indicator proteins (although activity-dependent bioluminescent emissions are an emerging possibility).
Current genetically encoded calcium indicators can only distinguish spikes below \SIrange{\ca 50}{100}{\hertz} firing rates without averaging~\cite{Smetters99} due to slow intra-molecular kinetics and indicator saturation at high firing rates, although significant improvements in speed are ongoing \cite{sun2013fast}. Intracellular calcium rises and drops can occur within \SI{1}{\milli\second} and \SIrange{10}{100}{\milli\second} respectively \cite{higley2008calcium}, which sets the ultimate speed limit for calcium indicators. The field of genetically-encoded high-speed fluorescent voltage indicators is also advancing quickly~\cite{Barnett2012, Kralj2012,gong2013enhanced, Storace2013, cao2013genetically} and these may find particular use in monitoring sub-threshold events \cite{scanziani2009electrophysiology}.

\subsubsection{Spatiotemporal Resolution}

\paragraph{Multiplexing strategies}
The signal from each neuron must be separated from emissions originating at other points in the brain.
Epi-fluorescence microscopy images a plane in the specimen onto a spatially-resolved two-dimensional detector (e.g., a CCD camera), while all neurons in a 3D volume are illuminated. The focal plane is scanned through the sample to achieve 3D coverage. Out-of-focus neurons add background noise; light sheet imaging illuminates only neurons near the focal plane, reducing this noise, but requires transparent brains~\cite{ahrens13}.
In multi-photon microscopy, nonlinearities result in fluorescence excitation occurring only near the focal point of the excitation laser, which is scanned across the sample.
In confocal scanning microscopy, only photons from a point of interest are measured due to geometric constraints (e.g., pinholes).
Optical techniques thus achieve signal separation by multiplexing spatially (e.g., direct imaging) or temporally (e.g., beam scanning), and often by a combination of the two.

\paragraph{Effects of light scattering}
Single-photon techniques limit imaging to a depth of a few scattering lengths at the excitation and emission wavelengths of activity indicators: up to \SIrange{\ca 1}{2}{\milli\meter} for certain infrared wavelengths \cite{horton13,kobat09,Kobat2011} vs. a few hundred microns for visible wavelengths \cite{Wilt2009}.
Activity dependent dyes are currently available only in the visible spectrum; indicators operating in the infrared (see \cite{filonov11,shcherbakova13, Shcherbo2009} for far-red fluorescent proteins) could improve imaging depth.

Multi-photon excitation takes advantage of the deeper penetration of infrared light.
Two or more infrared photons may together excite a fluorophore with an excitation peak in the visible range, leading to the emission of a visible photon.
If only one neuron is illuminated with sufficient intensity to generate multi-photon excitation, all photons captured by the detector originate from that neuron, regardless of the scattering of the outgoing light. Hence, the emission pathway is limited less by scattering than by absorption.
This has resulted in imaging at \SI{>1}{\milli\meter} depth \cite{horton13,kobat09, Kobat2011}.

There are at least four options for overcoming the scattering of visible light to enable signal-separation from deep-brain neurons~\cite{alivisatos2012brain, alivisatos13}:

\begin{enumerate}
\item Infrared light can excite multi-photon fluorescence in an excitation-scanning architecture.
\item Fluorophores with both excitation and emission wavelengths in the infrared could be developed.
\item Emerging techniques based on beam shaping allow transmission of focused light through random scattering media by inverting the scattering matrix~\cite{conkey12}.
Because the scattering properties change over time, this must be done quickly, possibly faster than the imaging frame rate, necessitating high-speed wavefront modulation.
This can currently be achieved with digital micro-mirror devices (DMDs), but not with phase-only spatial light modulators (SLMs), although GHz switching of phase modulators appears feasible in principle ~\cite{alivisatos13}. High speed focusing through turbid media is also achievable using all-optical feedback in a laser cavity~\cite{Nixon2013}.
It is possible to measure the scattering matrix non-invasively~\cite{Chaigne2013} using a photo-acoustic microscopy based on focused ultrasound. When using short optical pulses (e.g., in two-photon microscopy), similar techniques can be used to correct for temporal distortions due to scattering \cite{mccabe2011spatio, katz2011focusing}
\item Light sources and/or detectors could be positioned close to the measured neurons, necessitating the use of embedded optical devices.
This could be done using optical fiber~\cite{mahalati13} and/or waveguide~\cite{zorzos10,zorzos12} technologies, which are developing rapidly.
For example, single-mode fiber cables can support \SI{>1}{\tera\byte\per\second} data rates with low light loss over hundreds of kilometers.
\end{enumerate}

While optics might seem to require a number of photodetectors, fibers or waveguide ports comparable to the number of neurons, new developments suggest ways of imaging with fewer elements.
For example, compressive sensing or ghost imaging techniques based on random mask projections~\cite{wakin06,studer12,tian11,sun13} might allow a smaller number of photodetectors to be used.
In an illustrative case, an imaging system may be constructed simply from a single photodetector and a transmissive LCD screen presenting a series of random binary mask patterns~\cite{huang13}, where the number of required mask patterns is much smaller than the number of image pixels due to a compressive reconstruction.
Furthermore, it is possible to directly image through gradient index of refraction (GRIN) lenses~\cite{murray12} or optical fibers~\cite{mahalati13,kang10,flusberg05}, thus multiplexing multiple observed neurons per fiber.

Hybrid techniques combining optics with other modalities may also provide new ways to overcome scattering.
For example, ultrasound encoding~\cite{wang12}, which frequency-tags light emissions emerging from a known location via a mechanical Doppler shift of the emitter~\cite{mahan98}, is powerful in that it provides a generic mechanism to sidestep problems of elastic optical scattering, but it requires distinguishing MHz frequency modulations in THz light waves (part per million frequency discrimination). In principle, excitation and detection do not need to make use of the same modality. For example, photoacoustic microscopy \cite{filonov12} uses pulsed laser excitation to drive ultrasonic emission, leading to optical absorption contrast. Such asymmetric techniques impose fundamentally different requirements from pure-optical techniques relative to fluorphore properties, required light intensities and other parameters.

\paragraph{Speed of beam scanning}
The speed of scanning microscopes is limited by beam repositioning times (\SI{\ca 0.1}{\micro\second} for spinning disk~\cite{mahalati13,kang10,flusberg05}, \SI{\ca 3}{\micro\second} for piezo-controlled linear scan mirrors, \SI{\ca 10}{\micro\second} for acousto-optic deflectors~\cite{vucinic07}, \SI{\ca 8}{\kilo\hertz} line scans for resonant galvanometer mirrors), and the fluorescence lifetimes of activity indicators (\SI{\ca 1}{\nano\second}).
Note that \SI{0.1}{\micro\second} repositioning time for current spinning-disk confocal techniques would require 10 seconds per frame for whole mouse brain imaging with a single scanned beam $\left(\SI{1e-7}{\second\per site}\times\SI{1e8}{sites\per brain}\right)$. There is therefore a need for a \num{1e4} fold improvement in beam repositioning time and/or beam parallelization in order to achieve \SI{1}{\kilo\hertz} imaging frame rates for whole mouse brains.
The \SI{10}{\micro\second} repositioning time for acousto-optic deflectors is set by the speed of sound in the deflector crystal, while scanning mirrors and spinning disks are limited by inertia.
In principle, however, optical phase modulators could switch at GHz rates~\cite{alivisatos13} and arrays of such phase modulators could arbitrarily reshape coherent optical wavefronts to reposition beamlets.
Moreover, parallelization of beamlets and detectors could allow further speedups.
The speed of beam scanning is thus far from its physical limits.
Fluorescence lifetimes in the \SIrange{0.1}{1}{\nano\second} range~\cite{striker99} may ultimately constrain the design of scanning microscopies: a delay of \SI{0.1}{\nano\second} per mouse neuron per frame corresponds to \SI{100}{\hertz} frame rate with no parallelization.

In the context of two-photon microscopy, temporal focusing techniques (depth-dependent pulse duration) can excite an entire plane or line within the sample \cite{oron2005scanningless, tal2005improved, sela2013ultra, packer2013targeting}, potentially allowing fast axial scanning (in a manner somewhat analogous to light-sheet techniques used with transparent samples). This method can also intrinsically correct for scattering \cite{papagiakoumou2013functional}. Like other multi-photon techniques, however, these methods remain highly dissipative (see below).

\paragraph{Diffraction}
Using the small angle approximation, the diffraction-limited angular resolution of an aperture is $\theta \approx \frac{\Delta x}{y} \approx \frac{\lambda}{D}$, where $\Delta x$ is the spacing which must be resolved, $y$ is the imaging depth, $\lambda$ is the wavelength, and $D$ is the aperture diameter. Thus distinguishing neurons which \SI{10}{\micro\meter} apart and at a depth of \SI{10}{\milli\meter} requires a lens aperture $D$ of only \SI{1}{\milli\meter} when $\lambda \approx \SI{1}{\micro\meter}$. Diffraction therefore does not appear to be a limiting factor for cellular resolution imaging, except in the context of microscale apertures that might find use in embedded optics approaches.

\subsubsection{Energy Dissipation}

Light that does not leave the brain is ultimately dissipated as heat.
The total light power requirements for optical measurement of neuronal activity using fluorescent indicators depend on factors including
fluorophore quantum efficiency,
absorption cross-section,
activity-dependent change in fluorescence,
background fluorescence,
labeling density,
activation kinetics,
detector noise,
scattering and absorption lengths,
and others. Unfortunately, many of these variables are unknown or highly dependent on particular experimental parameters.

A statistical analysis of photon count requirements for spike detection (in the context of calcium imaging) can be found in~\cite{wilt13}, which derived a relationship between the number of background photon counts ($N\sub{bg}$) and the required number of signal photon counts required for high fidelity spike detection given photon shot noise, scaling roughly as $N\sub{signal} > 3\sqrt{2N\sub{bg}}$, even at low absolute photon count rates.
While this analysis governs the number of detected photons, the number of emitted photons will be higher due to losses.
In one example using two-photon excitation, \SI{5}{\percent} of the emitted photons were captured by the photodetector~\cite{kim99}. One implication of this photon shot noise constraint on reliable spike detection is that faster-responding indicators (e.g., voltage indicators which respond in near-real-time to the membrane potential) must be proportionately brighter, to achieve the same photon counts over a shorter interval of time. Increased brightness also improves the signal to background ratio.

\paragraph{Multi-photon: current technology}
Multi-photon excitation poses a particularly severe power problem due to the high light intensities required to excite nonlinear optical processes.
In typical multi-photon experiments on mice, \SI{\ca 50}{\milli\watt} of time-averaged laser power is used with a dwell time of \SI{\ca 3}{\micro\second}~\cite{wilson07}.
This would allow imaging \num{\ca 300} neurons at millisecond resolution with a single scanned excitation beam.
Current multi-photon imaging experiments are already near the permissible energy dissipation limit and improvements cannot come at the cost of greatly increased light power delivery.

\paragraph{Multi-photon: theoretical calculations}
Multi-photon experiments rely on short laser pulses with high peak light intensities at a focused excitation spot to excite nonlinear transitions~\cite{kim99}.
This imposes an experimentally relevant physical limit: at least one excitation pulse of sufficient intensity per neuron per frame is required in order to excite multi-photon fluorescence during each frame.
Assuming \SI{1}{\kilo\hertz} frame rate and \SI{0.1}{\nano\joule} pulses, delivering only one pulse per neuron per frame would dissipate roughly $\left(\num{1e8}\times\SI{1}{\kilo\hertz}\times\SI{0.1}{\nano\joule}\right) \SI{10}{\watt}$ in the mouse brain, which is clearly prohibitive.
This is a lower bound because, in general, more than one excitation pulse per neuron per frame may be required to excite detectable fluorescence (e.g., one reference reported 12 pulses per spot~\cite{kim99}).
For three-photon excitation, the situation will be even worse as higher peak light intensities are required to excite three-photon fluorescence.

Could the single-pulse energy be reduced while maintaining efficient two-photon excitation? The number of two-photon (2P) transitions excited per fluorophore per pulse is $n_a = F^2 C / t$, where $F$ is the number of photons per pulse per area, in units of \si{photon\per\centi\meter\squared}, $C$ is the two-photon cross-section in units of \si{\centi\meter\tothe{4}\second\per photon}, and $t$ is the pulse duration in seconds.
This can be approximated as
\[n_a = \left(\frac{\frac{E}{h c / \lambda}}{\left(\frac{\lambda}{2 \left(\NA\right)}\right)^2}\right)^2 \frac{C}{t} = \left(\frac{4E\left(\NA\right)^2}{h c \lambda}\right)^2 \frac{C}{t}\]
where $\NA$ is the numerical aperture of the focusing optics, $E$ is the pulse energy and $\lambda$ is the stimulation wavelength.
For a 2P experiment with \SI{100}{\femto\second}, \SI{0.1}{\nano\joule} pulses, assuming a 2P cross section~\cite{masters06, drobizhev2011} of \SI{1e-48}{\centi\meter\tothe{4}\second\per photon} (i.e., 100 Goeppert-Mayer units \cite{Goeppert-Mayer1931}, comparable to that of DsRed2 \cite{drobizhev2011}), $\lambda=\SI{900}{\nano\meter}$ and $\NA=1.0$, $n_a \approx \frac{1}{2}$.
Thus, a few pulses are likely necessary and sufficient to excite 2P fluorescence by each fluorophore within the focal spot. With a 2P cross section above \SI{1e-47}{\centi\meter\tothe{4}\second\per photon} (1000 Goeppert-Mayer units, higher than that of any fluorescent protein that we are aware of \cite{drobizhev2011}), one could reduce the pulse energy by an order of magnitude (and hence $n_a$ by two orders of magnitude) while maintaining $n_a > \frac{1}{20}$, i.e., one in twenty fluorophores excited by each pulse. Reducing the pulse energy much further might lead to unacceptably low excitation levels. Alternatively, shorter pulse durations could increase the light intensity, and hence 2P excitation probability, at fixed pulse energy. 

Quantum dots can have 2P cross sections much higher than those of fluorescent proteins:  water-soluble cadmium selenide–zinc sulfide quantum dots have been reported with 2P cross sections of 47000 Goeppert-Mayer units and are compatible with in-vivo imaging \cite{Larson30052003}. These would allow excitation efficiencies of $n_a > \frac{1}{20}$ at \si{\pico\joule} pulse energies, bringing whole-brain 2P imaging into the \SI{\ca 100}{\milli\watt} range. Thus, the use of quantum dots or other ultra-bright multi-photon indicators could be decisive for supporting the energetic feasibility of multi-photon methods at whole brain scale; fortunately, there are also plausible strategies for coupling quantum dot fluorescence to neuronal voltage \cite{Marshall2013}. Some quantum dots have long fluorescence lifetimes~\cite{Dahan2001}, however, which may constrain scan speed.

\subsubsection{Bioluminescence}
To work around the requirement for large amounts of excitation light, bioluminescent rather than fluorescent activity indicators could be used \cite{naumann2010monitoring, martin2007vivo, martin2008vivo}.
Consider a hypothetical activity-dependent bioluminescent indicator emitting at \SI{\ca 1700}{\nano\meter} (IR), in order to evade light scattering.
As a crude estimate, assuming that 100 photons must be collected by the detector per neuron per \SI{1}{\milli\second} frame, and \SI{1}{\percent} light collection efficiency by the detector relative to the emitted photons, \SI{\ca 100}{\micro\watt} of bioluminescent photons emissions are required for the entire mouse brain.
This would be feasible from the perspective of heat dissipation.
By contrast, in a 1-photon fluorescent scenario, if 100 excitation photons must be delivered into the brain to generate a single fluorescent emission photon, the power requirement becomes \SI{10}{\milli\watt}, which is on the threshold of the steady-state heat dissipation limit.
Therefore, bioluminescent indicators could potentially circumvent problems of heat dissipation associated with whole-brain optical imaging even in the 1-photon case.

The widely used bioluminescent protein firefly luciferase is \SI{\ca 80}{\percent} efficient in converting ATP hydrolysis coupled with luciferin oxidation into photon production, yielding \num{\ca 0.8} photons per ATP-luciferin pair consumed~\cite{seliger60}, and has \SI{\ca 90}{\percent} energetic efficiency in converting free energy to light production.
Heat dissipation associated with the luciferase biochemistry itself is therefore not a significant overhead relative to the \SI{100}{\micro\watt} of emitted photons calculated above. 
In the same scenario, however, the brain would consume \num{\ca 6e8} additional ATP molecules per minute per neuron in order to power the bioluminescence, which is within the limits of cellular aerobic respiration rates (\SI{\ca 1}{\femto\mole\ O\textsubscript{2}} per minute per cell~\cite{molter09}, with \num{\ca 30} ATP per 6 O\textsubscript{2}, hence \num{3e9} molecules ATP synthesized per minute from ADP via glucose oxidation), but not by a large margin.
Transient increases in metabolic rate are possible: energy dissipation more than doubles in the mouse during high physical activity~\cite{speakman13}.
Therefore, whole-brain activity-dependent bioluminescence, at speeds high enough to achieve millisecond frame rates, may be metabolically taxing for the cell but is nevertheless plausible as a light generation strategy. Note that we have not treated the energy required to bio-synthesize the luciferin compound, which may create additional overhead (though conceivably luciferin could be provided exogenously).

\subsubsection{Intrinsic signals}

The ideal technique would not require exogenous contrast agents or genetically encoded indicators, instead relying on signals intrinsic to neurophysiology. Neurons exhibit few-nano-meter scale \cite{iwasa1980swelling} membrane displacements (e.g., in response to Maxwell stresses from large local electric field variations) during the action potential. These can be measured using optical interferometry \cite{fang2004noncontact}, but in principle they could also be monitored acoustically (and related activity-associated membrane swellings have been directly observed by atomic force microscopy \cite{kim2007mechanical} in cultured neurons). Other intrinsic signals include changes in refractive index associated with neural activity, which will modulate the reflection and scattering of light \cite{stepnoski1991noninvasive}.

\subsubsection{Conclusions and Future Directions}

Scattering of visible light in the brain creates a problem of signal-separation from deep-brain neurons.
Multi-photon techniques, which scan an infrared excitation beam, can work around this scattering problem.
However, current multi-photon techniques using fluorescent protein indicators, when applied at whole brain scale, would dissipate too much power to avoid thermal damage to brain tissue.
Systems (such as plasmonic nano-antennas~\cite{blanchard11} or subwavelength metallic gratings~\cite{Harats11}) that could locally excite multi-photon fluorescence without the need for high-energy laser pulses could conceivably ameliorate this issue. 
Importantly, quantum dots show promise as ultra-bright multi-photon indicators, if they can be targeted to neurons and optimized in terms of fluorescence lifetime.
New methods besides multi-photon techniques could also work around the scattering of visible light in the brain.
For example, fluorophores or bio-luminescent proteins could be developed which operate at infrared wavelengths.
A compelling example from nature is the black dragonfish, which generates far red light (\SI{\ca 705}{\nano\meter}) via a multi-step bioluminescent process (using this light to see in deep ocean waters)~\cite{widder84,campbell87}.
A large set of activity indicators with distinguishable colors, generated through a combinatorial genetic recombination mechanism such as BrainBow~\cite{livet07}, could also improve signal separation (e.g., in conjunction with static post-mortem microscopy to map between cell colors and positions).
In addition, implanted optical devices, which place emitters and detectors within a few scattering lengths of the neurons being probed, could potentially obviate the negative effects of scattering and allow visible-wavelength indicators to be used without a need for multi-photon excitation.

\subsection{Embedded Active Electronics}

The preceding sections have assumed that electrical or optical signals from the recorded neurons are shuttled out of the brain before digitization and storage, but it is also conceivable to develop embedded electronic systems that locally digitize and then store or transmit (e.g., wirelessly) measurements of the activities of nearby neurons.
This could allow for shorter wires in electrical recording approaches, and for shorter light path lengths in optical recording approaches, as well as for more facile (e.g., non-surgical) delivery mechanisms for the recording hardware.

Integrated circuits have shrunk to a remarkable degree: in about 3 years, following the Moore's law trajectory, it will likely be possible to fit the equivalent of Intel's original 4004 micro-processor in a \SI{10 x 10}{\micro\meter} chip area.
Functional wirelessly powered radio-frequency identification (RFID) chips as small as \SI{50}{\micro\meter} in diameter have been developed~\cite{Usami2007} and tags with chip-integrated antennas function at the \SI{400}{\micro\meter} scale~\cite{ImpinjMonzaFive}.
Integrated neural sensors including analog front ends are also scaling to unprecedented form factors: a \SI{250 x 450}{\micro\meter} wireless implant -- including the antenna, but not including a \SI{\ca 1}{\milli\meter} electrode shank used to separate signal from ground -- draws only \SI{2.5}{\micro\watt} per recording channel~\cite{biederman13}. The system operates at \SI{\ca 1}{\milli\meter} range in air, powered by a transmitter generating \SI{\ca 50}{\milli\watt} of transmitted power.
Note that for a single such embedded recording device, the heat dissipation constraint is set not by the device's own dissipation (\SI{10}{\micro\watt} for four recording channels) but rather by the RF specific absorption rate limit associated with the \SI{50}{\milli\watt} transmit power.

Remarkably, cells such as macrophages (\SI{\ca 13}{\micro\meter} in size) can engulf structures up to at least \SI{20}{\micro\meter} in diameter~\cite{cannon92} and have been studied as potential delivery vehicles for nano-particle drugs~\cite{Kadiu11}, suggesting possibilities for non-surgical delivery of embedded electronics to the brain. T-cells and other immune cells can trans-migrate across the blood brain barrier \cite{Engelhardt2006} and ghost cells (membranes purged of their contents) engineered to encapsulate synthetic cargo \cite{Cinti2011} can fuse with neurons \cite{Hikawa1989162}. It may be possible to engineer such cell-based delivery vehicles to form electrically-connected gap junctions \cite{Spruston2001669} with target neurons or to act as local biochemical sensors \cite{nguyen2009vivo}.

If a large amount of local storage is used, the real-time transmission bandwidth requirements for neural recording could be significantly reduced if it is only desired to take a ``snapshot'' of neural activity patterns over a limited period of time.
For example, flash memory, which will likely be the densest form of electronic memory storage in the near future, can store \SI{1}{\mega\bit} of data in a device \SI{100}{\micro\meter} on a side.
Even denser forms of memory storage are under development and could perhaps be used in a one-time-write mode in the context of neural recording long before they become commercially viable for use as rewritable media in the consumer electronics industry.

Here we consider the power dissipation associated with embedded electronic recording devices, as well as the constraints on possible methods to power them.
In the next section, we describe how physics constrains the achievable data transmission rates from such devices.

\begin{figure}[htbp]
\caption{
Energy cost of elementary operations across a variety of recording and data transmission modalities, expressed in units of the thermal energy (left axis) and as a power assuming \SI{100}{\giga\hertz} switching rate (right axis). The Landauer limit of $\kb T \ln 2$ sets the minimum energy associated with a logically irreversible bit flip. The practical limit will likely lie in the tens of $\kb T$ per bit, comparable to the free energy release for hydrolysis of a single ATP molecule (or addition of a single nucleotide to DNA or RNA). The energy of a single infrared photon is \SI{\ca 50}{$\kb T$}. Single gates in current CMOS chips dissipate \SIrange{\ca 1e5}{1e6}{$\kb T$} per switching event, including the capacitive charging of the wires interconnecting the gates (red curve). The switching energy for the gate, not including wires, is \num{\ca 100}$\times$ lower (blue curve). The power efficiency of CMOS has been on an exponential improvement trend due to the miniaturization of components according to Moore's law (data re-digitized from~\cite{tucker11}), although power efficiency gains have slowed recently. Current RFID chips compute and communicate at \SIrange{\ca 1e9}{1e10}{$\kb T$} (\SI{>10}{\pico\joule}) per bit transmitted, while the total energy cost per floating point operation in a 2010 laptop was \SI{\ca 1e12}{$\kb T$}. The power associated with a minimal low-noise CMOS analog front end for signal amplification corresponds to \SI{\ca 500}{\milli\watt} at whole mouse brain scale. A single two-photon laser pulse at \SI{0.1}{\nano\joule} pulse energy corresponds to \SI{\ca 1e10}{$\kb T$}. For comparison, the \SI{40}{\milli\watt} approximate maximal power dissipation of a neural recording setup, according to \anref{sec:constraints} above, with its equivalent per-bit energy of \SI{\ca 1e8}{$\kb T$} at the minimal \SI{100}{\giga\bit\per\second} bit rate.
}
\label{fig:cmos}
\centering
\includegraphics[width=0.76\textwidth]{figs/Fig4.eps}
\end{figure}

\subsubsection{Power Requirements for Recording}

Any embedded system needs to process data, in preparation either for local storage or wireless transmission.
Physics defines hard limits on the required power consumption associated with data processing (neglecting the possibility of reversible logic architectures~\cite{bennett73}), arising from the entropy cost for erasing a bit of information~\cite{landauer61}:
\[E\sub{Landauer} = \ln(2)\ \kb T\approx \SI{3e-21}{\joule\per\bit} \tag{the Landauer limit}\]
Ambitious yet physically realistic values for beyond-CMOS logic lie in the tens of $\kb T$ per bit processed~\cite{yablonovitch08}.
Scaling \SI{40}{$\kb T$\per\bit} to record raw voltage waveforms at a minimal \SI{1}{\kilo\bit\per\second\per neuron} (e.g. \SI{1}{\kilo\hertz} sampling rate, 1 bit processed per neuron per sample), the total power consumption for whole mouse brain recording could in principle be as low as \SI{\ca 16}{\nano\watt}.
Thus, at the physical limits of power efficiency, implanted devices could in principle digitally buffer and locally store a complete record of a mammalian brain's activity.
While this leaves \num{>1e6}-fold room for overhead due to increased data processing burden (more required bit flips per second), or energetic inefficiency of the switching device (greater dissipation per bit), realistic devices in the near-term may in fact require this much overhead, if not more.
This necessitates a more detailed consideration of limiting factors for today's microelectronic devices.

In the context of electrical recording, the first step that must be performed by an embedded neural recording device is digitization of the voltage waveform.
Until \si{\milli\volt}-scale switching devices are developed (see discussion below), it is necessary to amplify the \SIrange{\ca 10}{100}{\micro\volt} spike potential in order to drive digital switching events in downstream gates.
During this sub-threshold amplification step, a CMOS (or BJT) device will dissipate static power (associated with a bias current). 
Importantly, in order to decrease the input-referred voltage noise of this amplification process, it is necessary to increase the bias current and hence the static power dissipation.
For a simple differential transistor amplifier, the minimal bias current scales as
\[I\sub{d} = \frac{\pi}{2} \frac{4\kb T}{V\sub{noise}^2} \frac{\kb T}{q} \BW\]
where $V\sub{noise}$ is the input-referred voltage noise of the amplifier and $q$ is the electron charge.
For an extracellular recording with $\BW = \SI{10}{\kilo\hertz}$ and $V\sub{noise} = \SI{10}{\micro\volt}$, this implies a minimal bias current $I\sub{d}\approx\SI{60}{\nano\ampere}$ or a minimal static power of $\left(I\sub{d} V\sub{dd}\right)\approx\SI{6e-8}{\watt}$ at $V\sub{dd}\approx\SI{1}{\volt}$ operating voltage.
Assuming 10 neurons per recording channel, there are then 7.5 million recording channels for a mouse brain, which gives a power dissipation associated with signal amplification of \SI{\ca 500}{\milli\watt}.
Note that realistic analog front ends (which are subject to $1/f$ noise and require multiple gain stages) draw 6$\times$--10$\times$ greater bias current, quantified by the noise efficiency factor (NEF)~\cite{steyaert87}, to achieve the same input-referred noise levels.

Local on-chip digital computation also incurs an energy cost.
Current CMOS digital circuits consume 5--6 orders of magnitude~\cite{tucker11,koomey11,yablonovitch08,tucker11b} more energy per switching event (\SI{\ca 1}{\femto\joule\per\bit} including charging of the wires~\cite{tucker11}) compared to the Landauer limit (e.g., for a digital CMOS inverter, and ignoring the static power associated with the leakage current).
This corresponds to a \SI{\ca 1}{\femto\farad} total load capacitance at \SI{1}{\volt} operating voltage. For \SI{100}{\giga\hertz} switching rates ($\SI{1e8}{neurons} \times \SI{1}{\kilo\hertz}$) as above, this corresponds to \SIrange{0.01}{0.1}{\milli\watt}.
Realistic architectures, however, will incur overhead in the number of switching events required to store, compress and/or transmit neural signals, likely bringing the power consumption into an unacceptable range (e.g., \num{1000} bits processed per sample would be \SI{100}{\milli\watt} here).
To take a concrete example, commercial RFID tags consume \SI{\ca 10}{\micro\watt}~\cite{rfidsheet}.
At a chip rate of \SI{256}{\kilo\bit\per\second} (with a Miller encoding of 2), this yields \SI{7.8e-11}{\joule\per\bit}, which is \num{\ca 10} orders of magnitude higher than the Landauer limit.
Applying current RFID technology to whole mouse brain recording at \SI{1}{\kilo\bit\per\second\per neuron} would thus draw \SI{\ca 8}{\watt} of power.
Therefore, at least 2--3 orders of magnitude reduction in power consumption will be necessary in order to apply embedded electronics for whole-brain neural recording.

Until recently, the energy efficiency of digital computing has scaled on an exponential improvement curve~\cite{koomey11}.
This was a consequence of Moore's law and Dennard scaling, where both the capacitance of each transistor and its associated interconnect, as well as the operating voltages, were reducing with the device dimensions.
Unfortunately, issues related to device variability and the 3D structures needed to maintain the on-to-off current ratio have largely stopped the reduction in effective capacitance per device; current devices are stuck at \SIrange{\ca 100}{200}{\atto\farad} for a minimum sized transistor.
Furthermore, the exponential increase in leakage current that comes along with the scaling of the threshold voltage in this scenario has precluded substantial further decreases in voltage at a given performance level.
Indeed, for the past several technology generations (since about 2005), CMOS devices have operated at a supply voltage of \SI{\ca 1}{\volt}.

While neural signal processing does not demand very stringent transistor speeds and so reductions below \SI{\ca 1}{\volt} are certainly feasible, a fundamental limitation in scaling the supply voltage still remains.
Specifically, CMOS has a well-defined minimum-energy per bit and an associated minimum-energy operating voltage that is defined by the tradeoff between static (leakage) and dynamic (switching) energy:
as the operating voltage is decreased, the capacitive switching energy decreases, but the ratio of currents in the on and off states, $I\sub{off}/I\sub{on}$, increases exponentially, increasing the energy associated with leakage (this effect is independent of the threshold voltage in the sub-threshold regime).
For practical circuits, the supply voltage that leads to this minimum energy is on the order of \SIrange{300}{500}{\milli\volt}, and thus supply voltage scaling will at most provide 3$\times$--10$\times$ improvement in energy over today's designs.

Thus, a paradigm shift in microelectronic hardware is needed to reduce power by several orders of magnitude if we are to approach the physical limits.
Developing a switching device operating in the \si{\milli\volt} range, rather than the \SI{1}{\volt} range of current transistors, would allow $\left(\SI{1}{\volt}/\SI{1}{\milli\volt}\right)^2=\num{1e6}$ fold reduction in power consumption~\cite{yablonovitch08}.
Electronic circuits constructed using analog techniques~\cite{sarpeshkar98}, which sometimes rely on bio-inspired computational architectures, show promise for reducing energy costs by up to five orders of magnitude~\cite{rapoport09,sarpeshkar98,mandal07}, depending on the nature of the computation and the required level of precision.

\autoref{fig:cmos} shows the power consumption per bit processed for several technology classes as well as the corresponding total power consumption required for whole brain readout, assuming a minimal whole-brain bit rate of \SI{100}{\giga\bit\per\second}.

\subsubsection{Powering Embedded Devices}

Embedded systems need power, which could be supplied via electromagnetic or acoustic energy transfer, or could be harvested from the local environment in the brain.

There are two key regimes for wireless electromagnetic power transfer: non-linear device rectification and photovoltaics.
If the single-photon energy is sufficient to allow electrons to move from the valence to the conduction band---that is, $\text{band gap} < h\nu/q$, where $q$ is the electron charge, $h$ is Planck's constant, and $\nu$ is the frequency of the photon---a photovoltaic effect can occur.
Otherwise, electromagnetic energy is converted to voltage by an antenna and non-linear device rectification may occur.

In this regime (single photon energy much lower than the band gap), power conversion is governed by the total RF power and by the impedances of the antenna and the rectifier, rather than by the individual photon energy.
For a monochromatic RF source, there is no thermodynamic or quantum limit to the RF to DC conversion efficiency, other than the resistive losses and threshold voltages for a semiconductor process.
For rectification, when the input voltage to the rectifier is much higher than a semiconductor process threshold, conversion efficiencies of \SI{85}{\percent} have been achieved~\cite{sun02}.
At low input voltages relative to the semiconductor process threshold, efficiencies as high as \SI{25}{\percent} and \SI{2}{\micro\watt} load have been achieved (see \cite{mandal07} for an analysis of power efficiency).
Ultimately, rectification improvements are dependent on the same improvements which will be needed for next-generation low-power computing: \si{\milli\volt} scale switching devices (promising research directions include tunnel FETs~\cite{ionescu11}, electromechanical relays~\cite{liu12} and other options). 

While efficient rectification is thus not a fundamental issue, capturing sufficient RF energy in the first place becomes increasingly challenging as microchips become smaller and more deeply embedded in tissue. Wireless electromagnetic power transfer imposes range constraints due to the loss in power density with distance.
For directional power transfer, placing the receiver at the edge of the transmitter's near field (the Rayleigh distance $D^2/4\lambda$ where $D$ is the transmitter aperture) has advantages in terms of energy capture efficiency~\cite{ozeri10}, whereas for omni-directional antennas it is advantageous to place the receiver as close as possible to the transmitter. If embedded chips are oriented randomly with respect to the transmitter, the radiation patterns of their antennas cannot be highly directional, i.e., their gains $G_r$ (a measure of directionality) must be close to one. In the far field, this lack of directionality limits power capture by the antenna (due antenna reciprocity~\cite{gershenfeld2000physics}): the maximal power $P_A$ available to the chip is \[P_A = \frac{G_r P\sub{rad} \lambda^2}{4\pi}\] where $P\sub{rad}$ is the power density of radiation around the antenna, $\lambda$ is the wavelength and $G_r \approx 1$ for a non-directional antenna \cite{mandal07}.

It may be possible to power devices with pure magnetic fields (which are highly penetrant) via near-field (non-radiative) inductive coupling, which is widely used in systems ranging from biomedical implants to electric toothbrushes, or conceivably by using magneto-electric materials~\cite{Kitagawa2010, Priya2009, Yue2012, Fiebig2005}. For the case of simple inductive coupling, however, the tiny cross-sections of micro-devices limit the amount of power which can be captured: a loop of \SI{10}{\micro\meter} diameter in an applied field of \SI{1}{\tesla} switching at \SI{1000}{\hertz} produces an induced electromotive force of only \SI{0.1}{\micro\volt}. Assuming a copper loop (\SI{\ca 17}{\nano\ohm\meter} resistivity) with \SI{1 x 1}{\micro\meter} cross-section and \SI{40}{\micro\meter} length (around the outer edge of the chip) gives a power ($V^2/R$) of only \SI{\ca 15}{\femto\watt} associated with the induced current. In general, the use of coupled high-$Q$ resonators can increase the range and efficiency of near-field electromagnetic power transfer by orders of magnitude \cite{Karalis2008} compared to non-resonant inductive power transfer and may be particularly relevant for implanted devices \cite{Ho2013}. Unfortunately, at the \SI{\ca 10}{\micro\meter} length scale, the achievable on-chip inductances and capacitances are severely limited, which restricts the operating range of any resonant device to high frequencies $\left( f\sub{resonant} = \left(2\pi\sqrt{LC}\right)^{-1} \right)$ which will be attenuated by tissue. Electromagnetic near-field power transfer though tissue to ultra-miniaturized microchips may thus be inefficient, again due to low capture efficiency of the applied fields by tiny device cross-sections.

Alternatively, if the photon energy is above the silicon band gap ($\lambda < \frac{h c}{qV\sub{th}} \approx \SI{3}{\micro\meter}$ or less for silicon), the chip is essentially acting as a photovoltaic cell.
There is no thermodynamic or quantum limit to the conversion efficiency of light to DC electrical power for monochromatic sources, other than resistive losses and dark currents in the material (\SI{86}{\percent} in GaAs for example~\cite{bett08}). Again, however, capturing sufficient light becomes difficult for tiny devices.
To supply \SI{10}{\micro\watt} (typical of current wirelessly-powered RFID chips) photovoltaically to a \SI{10 x 10}{\micro\meter} (cell sized) chip at \SI{34}{\percent} photovoltaic efficiency requires a light intensity of \SI{\ca 300}{\kilo\watt\per\meter\squared} at the chip, which is prohibitive. Furthermore, in the use of infrared light for photovoltaics, the penetration of the photons through tissue is decreased compared to radio frequencies.

Piezoelectric harvesting of ultrasound energy by micro-devices is a possibility \cite{Seo2013}. The efficiency of electrical harvesting of mechanical strain energy in piezoelectrics can be above \SI{30}{\percent} for materials with high electromechanical coupling coefficients (e.g., PZT)~\cite{safari08, xu12}. The losses in the piezoelectric transduction process are well described by models such as the KLM model~\cite{krimholtz70,castillo03}. 

An alternative to wireless energy transmission is the local harvesting of biochemical energy carriers. Implanted neural recording devices could conceivably be powered by free glucose, the main energy source used by the brain itself.
The theoretical maximum thermodynamic efficiency for a fuel cell in aqueous solution is equal to that of the hydrogen fuel cell: $\Delta G^0/\Delta H^0 = \SI{83}{\percent}$ at \SI{25}{\degreeCelsius}.
Furthermore, if glucose is only oxidized to gluconic acid, the Coulombic (electron extraction) efficiency is at most \SI{8.33}{\percent}~\cite{rapoport12}, which bounds the thermodynamic efficiency.
The blood glucose concentration in rats has been measured at \SI{\ca 7.6}{\milli\Molar}, with an extracellular glucose concentration in the brain of \SI{\ca 2.4}{\milli\Molar}~\cite{silver94}.
A hypothetical highly miniaturized neural recorder with a device area of \SI{25 x 25}{\micro\meter} and efficiency of \SI{80}{\percent}, processing a blood flow rate of \SI{\ca 1}{\milli\meter\per\second}~\cite{ivanov81} could extract $(\SI{80}{\percent})(\SI{7.6}{\milli\Molar})(\SI{25}{\micro\meter})^2(\SI{1}{\milli\meter\per\second})(\SI{2880}{\kilo\joule\per\mole})\approx \SI{11}{\micro\watt}$, which is sufficient for low-power device such as RFID chips~\cite{cho05}.
Unfortunately, current non-microbial glucose fuel cells obtain only \SI{\ca 180}{\micro\watt\per\centi\meter\squared} peak power and \SI{\ca 3.4}{\micro\watt\per\centi\meter\squared} steady state power~\cite{rapoport12}.
Thus there is a need for \num{1e4}- and \num{1e6}-fold improvements in peak and steady state power densities, respectively, for non-microbial glucose fuel cells to power brain-embedded electronics of the complexity of today's RFID chips (or better, the corresponding decrease in power requirements for the chips, as emphasized above).

\subsubsection{Conclusions and Future Directions}
The power consumption of today's microelectronic devices is more than 6 orders of magnitude higher than the physical limit for irreversible computing, and 2--3 orders of magnitude higher than would be permissible for use in whole brain millisecond resolution activity mapping, even under favorable assumptions on the required switching rates and neglecting both the power associated with noise rejection in the analog front end and the CMOS leakage current.
Thus, the first priority is to reduce the power consumption associated with embedded electronics.
In principle, methods such as infrared light photovoltaics, RF harvesting via diode rectification, or glucose fuel cells, could supply power to embedded neural recorders, but again, significant improvements in the power efficiency of electronics are necessary to enable this.
Other potential energy harvesting strategies include materials/enzymes harnessing local biological gradients such in voltage, osmolarity, or temperature.
An analysis of the energy transduction potential of each of these systems is beyond the scope of this discussion.
Fortunately, with many orders of magnitude potential for improvement before physical limits are reached, we may expect that embedded nano-electronic devices will emerge as an energetically viable neural interfacing option at some point in the future.

\subsection{Embedded Devices: Information Theory}

Most recording methods envisioned thus far rely on the real-time transmission of neural activity data out of the brain.
Physics and information theory impose fundamental limits on this process, including a minimum power consumption required to transmit data through a medium.
The most basic of these results hold irrespective of whether the data transmission is wired or wireless, and regardless of the particular physical medium (optical, electrical, acoustic) used as the information carrier.

A communication ``channel'' is a set of transmitters and receivers that share access to a single physical medium with fixed bandwidth.
The bandwidth is the range of frequencies present in the time-varying signals used to transmit information.
In wireless communications, information is transmitted by modulating a carrier wave.
To allow modulation, the frequency of the carrier wave must be higher than the bandwidth: for example, a \SI{400}{\tera\hertz} visible light wave may be modulated at a \SI{100}{\giga\hertz} rate.
The physical medium underlying a channel could be a wire (with a bandwidth set by its capacitive RC time constant), an optical fiber, free space electromagnetic waves over a certain frequency range, or other media.

As a concrete example, consider a police department with \num{100} officers, each possessing a hand-held radio.
The radios transmit vocalizations by modulating an \SI{80}{\mega\hertz} carrier wave at \SI{\ca 10}{\kilo\hertz}.
This constitutes a single shared communications channel with \SI{10}{\kilo\hertz} bandwidth.
Simultaneously, the fire department may communicate via a separate channel, also with a bandwidth of \SI{\ca 10}{\kilo\hertz}, by modulating a \SI{90}{\mega\hertz} carrier wave.
The channels are separate because modulation introduced into one does not affect the other.
If the neighboring town's police department makes the mistake of also operating at 80 MHz carrier frequency, then they share a channel and conflicts will arise.

\subsubsection{Power Requirements for Single-Channel Data Transmission}

We first treat the case in which there is a single channel for transmitting data out of the brain. As discussed above in the context of electrical spike-sorting, the Shannon Capacity Theorem~\cite{cover06} sets the maximal bit rate for a channel (assuming additive white Gaussian noise) to
\[R\sub{max} = \BW \log_2 \left(1 + \SNR\right)\]
where $\BW$ is the channel bandwidth and $\SNR$ is the signal-to-noise ratio.
If there is only thermal noise the $\SNR = P/(N_0 \BW)$, where $N_0$ is the thermal noise power spectral density of $\kb T$ \si{\watt\per\hertz} and $P=(\pathloss)P_0$ is the power of the transmitted signals $P_0$, weakened by path loss \pathloss.
Therefore the transmitted power $P_0$ is lower-bounded:
\[P_0 > \kb T\ \BW\ \frac{2^{R\sub{max}/\BW}-1}{\pathloss}\]
as shown in \autoref{fig:rfpower} (bottom).
In a minimal model of a transmitter-receiver system, there thus exists a tradeoff between the required signal power and the bandwidth of the carrier radiation, due to the thermal noise floor, even in the absence of path loss ($\pathloss = 1$).

Path loss weakens the proportion of the power that can reach the detector.
Using the above equation, we can calculate, as a function of bandwidth, the power necessary to transmit a target whole-brain bit rate of \SI{100}{\giga\bit\per\second} through a medium with path loss dependent on the carrier wavelength, as shown in \autoref{fig:rfpower} (top).

For RF wavelengths, the radiation penetrates deeply but the achievable data rates are low without excessive power consumption, due to the limited bandwidth.
For wavelengths intermediate between RF and infrared, the penetration depth is low and power must be expended to combat these losses, despite the high carrier bandwidth.
Only in the infrared and visible ranges do the tradeoffs between power, bandwidth and penetration depth allow transmission of \SI{>100}{\giga\bit\per\second} out of the brain through a single channel without unacceptable power consumption.

The analysis above has ignored the effects of noise sources other than thermal noise, but many additional noise sources will increase the amount of power needed to transmit data, via a decrease in the SNR at fixed input power.
For optical transmission in the brain, the noise is dominated by time-correlated ``speckle noise'' below \SI{200}{\kilo\hertz}, which arises mostly from local blood flow~\cite{carp11}.
This correlated noise, which cannot be filtered by simple averaging, could be avoided by modulating optical signals at frequencies above \SI{200}{\kHz}.

\begin{figure}[htbp]
\caption{%
Fundamental power requirements imposed by information theory on data transmission through a single (additive white Gaussian noise) channel with carrier frequency $\nu$ (an upper bound on the bandwidth), given thermal noise and path loss.
Bottom: absorption length of water as a function of frequency (blue), minimal power to transmit data at \SIlist{100;1000;10000}{\giga\bit\per\second} (green) as a function of frequency, assuming thermal noise but no path loss.
Top: minimal power to transmit data at \SIlist{100;1000;10000}{\giga\bit\per\second} as a function of frequency, assuming thermal noise and a path loss corresponding to the attenuation by water absorption over a distance of \SI{2}{\milli\meter}.
While formulated for a single channel, at certain wavelengths (e.g., RF) these factors also constrain multiplexed data transmissions between many transmitters and many receivers, depending on capacity of the system for spatial multiplexing.
Horizontal dashed lines: \SI{40}{\milli\watt}, the approximate maximal whole-brain power dissipation in steady state.
}
\label{fig:rfpower}
\centering
\includegraphics[width=0.78\textwidth]{figs/Fig5.eps}
\end{figure}

\subsubsection{Spatially Multiplexed Data Transmission}

As discussed above, transmitting information through a single channel imposes direct limits on bit rate, carrier frequency and input power.
However, it is conceivable to divide the data transmission burden over many independent channels, i.e., over many pairs of transmitters and receivers, each operating at lower bandwidth (e.g., at radio frequencies).
Indeed, this would be optimal in a scenario where many embedded devices measure and then transmit the activities of nearby neurons.
As a concrete example of such ``spatial multiplexing,'' an effective capacity of \SI{1}{\tera\bit\per\second} could conceivably be obtained by splitting the data over \num{1000} transmitter-receiver pairs each operating at \SI{1}{\giga\bit\per\second}, with the transmitters arranged in a \num{10 x 10 x 10} grid.
Importantly, in order to exceed the above limits for single-channel data transmission, it must be possible for these transmitter receiver pairs to share the same bandwidth and operate simultaneously without conflicts, for example by modulating distinguishable carrier waves or by transferring data over separate wires.
The conditions under which this may occur, however, can be counter-intuitive.
For example, for antennas to operate independently, they must be spaced apart from one another by roughly a wavelength.
For \SI{10}{\giga\hertz} microwaves, the wavelength is \SI{\ca 3}{\centi\meter}, so no more than a handful of microwave transmitters can co-occupy the mouse brain while operating independently.

Even with many non-independent transmitters co-occupying the brain and operating simultaneously over the same frequency spectrum, it may be possible under some conditions to ``factor out'' the effects of the coupling and allow an increase in channel capacity relative the single-channel result.
To treat such scenarios, a generalization to Shannon's capacity theorem to multi-input-multi-output (MIMO) channels has shown that the maximal total data rate is
\[R\sub{max} = \BW \cdot \log_2\left| \mat{I} + ( \SNR ) \mat{H}\mat{H}^* \right|\]
where $\mat{I}$ is the identity matrix, $|\cdot|$ denotes the matrix determinant, $\mat{H}$ is the ($M \times N$ for $N$ transmitters and $M$ receivers) channel matrix giving the coupling between the vector of transmitted signals and the vector of received signals and $\mat{H}^*$ denotes the matrix adjoint of $\mat{H}$ \cite{tulino04}. The vector of received signals is then $\vec{y}=\mat{H}\vec{x}+\vec{n}$ where $\vec{x}$ is the vector of transmitted signals and $\vec{n}$ is a noise vector. Any matrix can be written as $\mat{H}=\mat{U}\mat{\Sigma}\mat{V}^*$ where $\mat{U}$ and $\mat{V}$ are unitary matrices, and $\mat{\Sigma}$ is a diagonal matrix whose elements are the \emph{singular values} $\lambda_i$. One can re-write the above equation as
\[R\sub{max} = \BW \cdot \sum_{i=1}^{\min(M,N)} \log_2\left(1+\SNR \cdot \lambda_i^2\right)\]
If the matrix $\mat{H}$ is of full rank, then the capacity for the multi-channel system can increase over the single-input-single-output (SISO) result by $\min(M,N)$ times~\cite{shiu00}.
Note that the rank of the matrix corresponds to the number of non-zero singular values, so an analysis of the singular values of channel matrices can inform us about the multiplexing capacity of the channel.
Furthermore, this multiplexing capacity can in principle be achieved even when the transmitters are not in communication with each other, which could potentially be important for scenarios involving many brain embedded transmitters~\cite{spencer04}.

Transmission through a medium with negligible scattering is the simplest situation to analyze.
In this case, evaluating the matrix $\mat{H}$ requires knowledge of the transmitter-transmitter, transmitter- receiver, and receiver-receiver distances, as well as the orientations and radiation patterns of the antennas (e.g., high gain antennas will have a highly directional radiation pattern).
Depending on these factors, the beam from each transmitter will spread to impinge upon multiple receivers and the effective number of spatially independent beams will be reduced.
With transmitter-transmitter and receiver-receiver distances larger than the wavelength, and highly directional antennas with appropriately chosen orientations, it is possible to increase the channel capacity linearly with $\min(M,N)$.

Random scattering, in a coherent disordered medium where the mean free-path $\ell$ is much larger than the wavelength $\lambda$ and much smaller than the size of the disordered medium, is another condition where the matrix $\mat{H}$ is a random scattering matrix of full rank~\cite{moustakas00,popoff10}.
Intuitively, for the case of two transmitters and two receivers separated by a disordered medium larger than the mean free path:
if transmitter 1 is at least a mean-free path from transmitter 2 (or potentially as close as a few wavelengths~\cite{berkovits91}) the path from transmitter 1 to receiver 1 and the path from transmitter 2 to receiver 2 would be uncorrelated with respect to one another (in terms of physical path, phase, amplitude fluctuations, and other properties).
The rank of the matrix $\mat{H}$ would then be 2.
Devising a code on the transmitter such that the receivers can distinguish between these two uncorrelated streams results in a doubling of the capacity, rather than simply averaging the noise floor, which would provide only a logarithmic capacity gain due to the increased SNR.

Thus, contrary to intuition, a high degree of random scattering can potentially be useful for data transmission, by enabling spatial multiplexing of channels.
This idea has been demonstrated experimentally in the context of ultrasound transmissions~\cite{derode03}.
Biological tissue in the infrared range is well described as such a random scattering medium (e.g., mean free path \SI{\ca 200}{\micro\meter} at \SI{\ca 800}{\nano\meter} \emph{in vivo}).
Therefore infrared light could be used for spatially multiplexed data transmission out of the brain.
At wavelengths $\lambda$ comparable to critical brain dimensions in the mouse, however, an insufficient number of scattering events will occur to create multiple independent pathways for $N$ transmitters.
Mathematically, the matrix $\mat{H}$ will have one highly dominant singular value and a number of much smaller remaining terms, such that the signals appearing at a receiver from two separate transmitters will be highly linearly dependent, differing by only a small phase angle.
Therefore, there will be no capacity gain from multiple transmitters, and distinct transmitters will effectively share a single channel (reducing to the SISO result).

Little is known about the biological interaction with electromagnetic fields at wavelengths much shorter than the critical brain dimensions but beyond the infrared, approximately \SI{100}{\giga\hertz} (\SI{\ca 3}{\milli\meter}) to \SI{100}{\tera\hertz} (\SI{\ca 3}{\micro\meter}) in the mouse.
If multiple scattering occurs and the absorption is low, this may also be a regime conducive to MIMO communications~\cite{bakopoulos09}.
Efficiently generating and processing radiation in this regime by embedded devices is an outstanding problem, however.
The so-called ``THz-gap''~\cite{tonouchi07} exists because (moving towards higher frequencies starting from DC electronics), parasitic capacitances and passive losses limit the maximum frequency at which a field-effect transistor (FET) may oscillate and on the other hand (moving downward in frequency starting from optics), the band-gaps of opto-electronic devices limit the minimum frequency at which quantum transitions occur.
Thus there is no high-power, low-cost, portable, room temperature \si{THz} source available.
Advances in \si{THz} light generation, e.g. through the use of tunneling transistors, could be enabling.

\subsubsection{Ultrasound as a Data Transmission Modality}
An important caveat to these conclusions on wireless data transfer occurs if we consider the use of ultrasound rather than electromagnetic radiation.
Because the speed of sound is dramatically slower than that of light, the wavelength of \SI{10}{\mega\hertz} ultrasound is only \SI{\ca 150}{\micro\meter} (approximating the speed of sound in brain as the speed of sound in water, \SI{\ca 1500}{\meter\per\second}).
Thus, many \SI{10}{\mega\hertz} ultrasound transmitters/receiver could be placed inside a mouse brain while maintaining their spatial separation above the wavelength, and a linear scaling of the MIMO channel capacity with the number of devices is likely possible in this regime, assuming that appropriate antenna gains and orientations can be achieved inside brain tissue. Beam orientation could present a challenge if micro-devices are oriented randomly after implantation.
With an attenuation of \SI{0.5}{\dB\per\centi\meter\per\mega\hertz}~\cite{hoskins10}, the attenuation at \SI{10}{\mega\hertz} is only \SI{5}{\dB\per\centi\meter}.
Thus ultrasound-based transmission of power and data from embedded recording devices may be viable \cite{Seo2013}.

In contrast, direct imaging of neural activity by ultrasound (e.g., using contrast agents which create local variations in tissue elastic modulus or density) may be more difficult.
The wavelength of \SI{100}{\mega\hertz} ultrasound is \SI{\ca 15}{\micro\meter}, providing a theoretical diffraction limited spatial resolution that would be sufficient for resolving neuronal somas.
Practical transducer designs operating at this frequency achieve axial and lateral resolutions in the range of \SIrange{15}{60}{\um}~\cite{foster00}.
However, at these frequencies, power is attenuated by brain tissue with a coefficient of \SI{\ca 50}{\dB\per\centi\meter}~\cite{hoskins10} (\num{1e5}-fold attenuation per cm), which imposes a penetration limit (e.g., for
measurements with a dynamic range of 80 dB~\cite{foster00}).
Attenuation of ultrasound by bone is stronger still, at \SI{22}{\dB\per\cm\per\MHz}~\cite{hoskins10}.
Attenuation could therefore limit the use of ultrasound as a high-resolution neural recording modality in direct imaging modes, but multiplexed transmission of lower-frequency ultrasound from embedded devices could sidestep this issue.

\subsubsection{Conclusions and Future Directions}

Physics and information theory impose a tradeoff between bandwidth and power consumption in sending data through any communication channel.
Considering only thermal noise and no path loss, achieving \SI{100}{\giga\bit\per\second} data rates through a single channel necessitates either a bandwidth above a few \si{\giga\hertz} or a transmitted power above \SI{\ca 100}{\milli\watt}, the latter of which may be prohibitive from a heat dissipation perspective if the signals are to be generated by dissipative microelectronic devices.
Researchers have proposed to use thousands or millions of tiny~\cite{gomez10} wireless transmitters embedded in the brain to transmit local neural activity measurements to an external receiver via microwave radiation~\cite{dyson09}.
However, based on the above power-bandwidth tradeoff, this will require a bandwidth above a few \si{\giga\hertz}.
At the corresponding carrier frequencies, the penetration depth of the microwave radiation drops significantly, requiring increased power to combat the resulting signal loss.
While one might hope that multiple independent channels could be multiplexed inside the brain, reducing the bandwidth and power requirements for each individual channel, the long wavelengths of microwave radiation compared to the mouse brain diameter suggest that such channels cannot be independent, as is confirmed by an analysis of the multi-input-multi-output (MIMO) channel capacity for this scenario.
Therefore, radio-frequency electromagnetic transmission of whole brain activity data from embedded devices does not appear to be a viable option for brain activity mapping.

On the other hand, an analysis of the channel capacity for IR transmissions in a diffusive medium suggests that, because of its high frequency and decent penetration depth, infrared radiation may provide a viable substrate for transmitting activity data from embedded devices.
For example, data could be transmitted via modulating the multiple-scattering speckle pattern of infrared light by varying the backscatter from an embedded optical device, such as an LCD pixel, in an activity-dependent fashion.
Because the speckle pattern is sensitive to the motion of a single scatterer~\cite{berkovits91}, coherent multiple scattering could effectively act as an optical amplifier and as a means to create independent communication pathways. Furthermore, multiplexed data transmission via ultrasound is likely possible because of its short wavelength in tissue at reasonable carrier frequencies.
It may also be of interest to explore network architectures~\cite{Bush2011} in which data is transmitted at low transmit power over short distances via local hops between neighboring nodes capable of signal restoration.

\subsection{Magnetic Resonance Imaging}

Magnetic resonance imaging (MRI) uses the resonant behavior of nuclear spins in a magnetic field to non-invasively probe the spatiotemporally varying chemical and magnetic properties of tissues.
Although originally conceived as a means to image anatomy, MRI can be used to observe neural activity provided such activity is reflected in dynamic changes in local chemistry or magnetism.

In an MRI study, a strong static field ($B = \SIrange{1}{15}{\tesla}$) is applied to polarize nuclear spins (usually \textsuperscript{1}H), causing them to resonate at a field-dependent Larmor frequency \[f = \frac{\gamma}{2\pi} B\] where $\gamma$ is the gyromagnetic ratio of the nucleus (\SI{267.522}{\mega\hertz\per\tesla} for \textsuperscript{1}H~\cite{codata10}).
To obtain positional information, spatial field gradients are applied such that nuclei at different positions in the sample resonate at slightly different frequencies.
Sequences of RF pulses and gradients are then applied to the sample, eliciting resonant emissions that contain information about spins' local chemical environment, magnetic field anisotropy and various other properties.

Most functional studies rely on dynamic changes in two forms of relaxation experienced by RF-excited spins.
The first form results from energy dissipation through interactions with other species (e.g. other spins or unpaired electrons), causing the spins to recover their lowest energy state on a timescale $T_1$ of \SIrange{100}{1000}{\milli\second}~\cite{rooney07}.
The second form of relaxation reflects the dephasing of spin signals in a given sampling volume (voxel) over a timescale $T_2$ of \SIrange{10}{100}{\milli\second}~\cite{deichmann95} due to non-uniform Larmor frequencies caused, e.g., by the presence of local magnetic field inhomogeneities.

In blood-oxygen level dependent functional MRI (BOLD-fMRI)---the most widely used form of neural MR imaging---increased neural activity in a given brain region alters the vascular concentration of paramagnetic deoxy-hemoglobin, which affects local magnetic field homogeneity and thereby alters $T_2$.
Although the existence of this paramagnetic reporter of oxygen metabolism is fortuitous, the data it provides is only an indirect readout of neural activity, which is limited in its spatial and temporal resolution to the dynamics of blood flow in the brain's capillary network (\SIrange{1}{2}{\second}).
A significant area of current and future work is aimed at developing new molecular reporters that can be introduced into the brain to transduce aspects of neural signaling such as calcium spikes and neurotransmitter release into MRI- detectable magnetic or chemical signals~\cite{shapiro10,koretsky12,hsieh12}, as described in section 4.5.3, below.

\subsubsection{Spatiotemporal Resolution}

The temporal resolution of MRI is limited by the dynamics of spin relaxation. For sequential MR signal acquisitions to be fully independent, spins must be allowed to recover their equilibrium magnetization on the timescale of $T_1$ (\SIrange{100}{1000}{\milli\second}).
However, if local $T_1$ is static its pre-mapping could enable temporally variant $T_2$ effects to be observed at refresh rates on the faster $T_2$ timescale (\SIrange{10}{100}{\milli\second})~\cite{deichmann95}.
It may also be possible to detect events that occur on a timescale shorter than $T_1$ and $T_2$, if the magnitude of the resulting change in spin dynamics overcomes the lack of independence between acquisitions.
Note that these limitations on the repetition time of the underlying pulse sequence are not eliminated by ``fast'' pulse sequences such as echo-planar imaging (EPI)~\cite{stehling91} and fast low-angle shot (FLASH)~\cite{haase86} or by the use of multiple detector coils~\cite{wiesinger06}.
These techniques accelerate the acquisition of 2D and 3D images, but still require spins to be prepared for readout.

The spatial resolution of current MRI techniques is limited by the diffusion of water molecules during the acquisition time~\cite{glover02}, since contrast at scales above the diffusion length will be attenuated by diffusion.
The RMS distance of a water molecule from its origin, after diffusing in 3D for a time $T\sub{acq}$, is
\[d\sub{rms} = \sqrt{6D\sub{water}T\sub{acq}}\]
where $D\sub{water}=\SI{2300}{\micro\meter\squared\per\second}$ is the self-diffusion coefficient of water.
For $T\sub{acq}\approx\SI{100}{\milli\second}$, $d\sub{rms}\approx\SI{37}{\micro\meter}$, which sets the approximate spatial resolution.
For ultra-short acquisitions at $T\sub{acq}\approx\SI{10}{\milli\second}$, $d\sub{rms}\approx\SI{12}{\micro\meter}$.

More technically, as described above, MRI uses field gradients to encode spatial positions in the RF frequency (wavenumber) components of the emitted radiation.
The quality of the reconstruction of frequency space thus limits the achievable spatial resolution.
$\Delta t$, the sampling interval of the detector, and the field gradient $G$, determine the wavenumber increment as
\[\Delta k = \gamma G \Delta t\]
The spatial resolution is then given by~\cite{glover02}:
\[\Delta x\sub{$k$-space} = \frac{\pi}{\frac{T\sub{acq}}{\Delta t} \Delta k} = \frac{\pi}{T\sub{acq} \gamma G}\]
Note that it is the gradient field, not the polarizing field $B_0$, which determines the resolution. For a gradient field of \SI{100}{\milli\tesla\per\meter} and an acquisition time of \SI{100}{\milli\second}
\[\Delta x\sub{$k$-space} = \frac{\pi}{\left(\SI{100}{\milli\second}\right)\left(\SI{267}{\MHz\per\tesla}\right)\left(\SI{100}{\milli\tesla\per\meter}\right)}\approx \SI{1.17}{\micro\meter}\]

Furthermore, due to relaxation, the emissions from a spin at a given position do not constitute a pure tone with a well-defined frequency. Instead, each spin exhibits a frequency spread, which gives rise to a spatial resolution~\cite{glover02}:

\[\Delta x\sub{relaxation} = \frac{2}{\gamma G T_2^*}\]
where $T_2^*$ is the shortest relaxation time. Assuming $T_2^*=\SI{5}{\milli\second}$ and $G=\SI{100}{\milli\tesla\per\meter}$, gives
\[\Delta x\sub{relaxation}\approx \SI{14}{\micro\meter}\]
Therefore, for water protons, the resolution limit is set by diffusion over \SI{\ca 100}{\milli\second} acquisition timescales. For other spin species (e.g., with lower diffusion rate), it may be possible to achieve resolutions limited by frequency discrimination.

Notably, there exists a practical trade-off between spatial resolution, temporal resolution, and sensitivity (SNR). In particular, to achieve high spatial resolution, it is necessary to densely sample $k$-space.
Fast sampling sequences such as FLASH and EPI achieve speed by sampling each point of $k$-space using less signal and often at a lower resolution.
Even at high field strengths (\SI{11.7}{\tesla}), this tradeoff results in practical EPI-fMRI with a spatial resolution of \SI{150 x 150 x 500}{\micro\meter} and a temporal resolution of \SI{200}{\milli\second}~\cite{yu12}.
Achieving much higher spatial resolutions requires longer acquisitions and/or lower temporal sampling.
For example, achieving a \SI{20}{\micro\meter} anatomical resolution in MRI of \emph{Drosophila} embryos required 54 minutes for a small field of view of \SI{2.5 x 2.5 x 5}{\milli\meter}~\cite{null08}.
Furthermore, the flies were administered paramagnetic gadolinium chelates to shorten $T_1$ and thereby the acquisition time.
Separately, frame rates of \SI{50}{\milli\second} have been obtained for dynamic imaging of the human heart, but required the use of strong priors to reduce data collection requirements~\cite{zhang10}.

\subsubsection{Energy Dissipation}

Energy is dissipated into the brain when the excited spins relax to their equilibrium magnetization in the applied field.
The energy associated with this relaxation is of order the Zeeman energy:
\[\Delta E\sub{Zeeman} = \frac{\gamma}{2\pi} h B_0\]
To obtain an upper bound on the heat dissipation of MRI, we first assume that the brain is entirely water, that every proton spin is initially aligned by the field and then excited by the RF pulse, and that all spins relax during a $T_1$ relaxation time of \SI{\ca 600}{\ms}.
In this scenario, even an applied field of as high as \SI{\ca 200}{\tesla} would generate dissipation within the \SI{\ca 50}{\milli\watt} energy dissipation limit.
In reality, the energy dissipation is 4--5 orders of magnitude smaller, because only a tiny fractional excess of the spins are initially aligned by the field (\num{\ca 1e-5} for fields on the order of \SI{1}{\tesla}).
Therefore, thermal dissipation associated with spin excitation in MRI is unlikely to cause problems unless field strengths much greater than the largest currently fields used (\SI{\ca 20}{\tesla}) are invoked, or spins with much higher gyromagnetic ratios are used.

Practically, the main energy consideration in MRI is the absorption by tissues of RF energy applied during imaging pulse sequences and the switching of magnetic field gradients.
Such absorption is often calculated through numerical solutions of the Maxwell Equations taking into account the precise geometry, tissue properties and applied fields for a particular experimental setup~\cite{collins04}.
The typical specific absorption rate (SAR) is well under \SI{10}{\watt\per\kilogram} (or \SI{5}{\milli\watt} per \SI{500}{\milli\gram}), and is restricted by the FDA to less than \SI{3}{\watt\per\kilogram} for human studies.

\subsubsection{Imaging Agents}

All the preceding discussion about spatiotemporal resolution presumes the existence of local time-varying signals (e.g., changes in $T_1$ or $T_2$) corresponding to the dynamics of neural activity.
Such signals are not naturally present in the brain with the exception of the hemodynamic BOLD response, the limitations of which are discussed above (although there have been studies working towards direct detection of the minute neuronal magnetic fields associated with action potentials by MRI~\cite{Bodurka2002}, as well as MRI detection of the mechanical displacement of active neurons due to the Lorentz force in an applied magnetic field~\cite{roth2009mechanical}).
In the past 15 years, efforts have been undertaken to develop chemical and biomolecular imaging agents that can be introduced into the brain to produce MRI detectable signals corresponding to specific aspects of neural function (analogously to fluorescent dyes and proteins).
Notable examples include $T_1$ and $T_2$ sensors of calcium~\cite{atanasijevic06,li99} and a $T_1$ sensor of neurotransmitter release~\cite{shapiro10}.
Depending on their mode of action, these imaging agents can provide temporal resolutions ranging from \SI{10}{\milli\second} to \SI{10}{\second}~\cite{shapiro06}.
However, a major current limitation for fast agents is the requirement that they be present in tissues at \si{\micro\Molar} concentrations, posing major challenges for delivery and genetic expression.

\autoref{fig:mriresolution} shows the achievable temporal resolution for various classes of activity-dependent MRI contrast agents as well as the spatial resolution limit due to water proton diffusion.

\begin{figure}[htbp]
\caption{Key factors determining the spatiotemporal resolution of dynamic MRI imaging. (a) Temporal resolution and contrast agent concentration allowing \SI{>5}{\percent} contrast, for different classes of dynamic MRI contrast agent (reproduced from~\cite{shapiro06}, with permission). (b) Diffusion limited spatial resolution for water proton MRI as a function of temporal resolution.}
\label{fig:mriresolution}
\centering
\includegraphics[width=0.78\textwidth]{figs/Fig6.eps}
\end{figure}

\subsubsection{Conclusions and Future Directions}

Current MRI techniques rely on the excitation of proton spins in water, however, and are thus limited to imaging at \SI{>100}{\ms} timescales unless SNR is severely compromised, due to the low polarizability and long $T_1$ relaxation time of proton spins.
There is also a spatial resolution limit of tens of microns over these timescales due to water's fast diffusion. Methods which couple neural activity to non-diffusible, highly polarized spins could in principle ameliorate this situation.

\subsection{Molecular Recording}

An alternative to electrical, optical or MRI recording is the local storage of data in molecular substrates.
Each neuron could be engineered to write a record of its own time-varying electrical activities onto a biological macromolecule, allowing off-line extraction of data after the experiment.
Such systems could, in principle, be genetically encoded, and would thus naturally record from all neurons at the same time.

One proposed implementation of such a ``molecular ticker tape'' would utilize an engineered DNA polymerase with a Ca\textsuperscript{2$+$}-sensitive or membrane-voltage-sensitive error-rate~\cite{zamft12} to record time-varying neural activities onto DNA~\cite{glaser13} as patterns of nucleotide misincorporations relative to a known template DNA strand (for alternative local recording techniques see~\cite{friedland09,bonnet13}).
The time-varying signal would later be recovered by DNA sequencing and subsequent statistical analysis~\cite{glaser13}.
DNA polymerases found in nature can add up to \num{\ca 1000} nucleotides per second~\cite{kelman95}, and certain non-replicative polymerases such as DNA polymerase $\iota$ have error rates of \SI{>70}{\percent} on template T bases~\cite{frank07}.
Similar strategies could be implemented using RNA polymerases or potentially using other enzyme/hetero-polymer systems.

\subsubsection{Spatiotemporal Resolution}

Polymerases proceed along their template DNA strands in a stochastic, thermally driven fashion; thus, polymerases that are initially synchronized will de-phase with respect to one another over time, occupying a range of positions on their respective templates. The rate of this de-phasing is a key parameter governing the temporal resolution of molecular recording. By averaging over many (e.g., hundreds to thousands) of simultaneously replicated templates, it is theoretically possible to precisely associate nucleotide misincorporations with the times at which these misincorporations occurred, and thus to obtain recordings of the cation concentration at high temporal resolution. 

Furthermore, the development of mechanisms to improve synchronization of the ensemble of polymerases within each cell, or to encode time-stamps into the synthesized DNA (e.g., molecular clocks), could improve temporal resolution and decrease the number of required template strands per neuron. Mutation-based molecular clocks over evolutionary timescales are widely used in the field of phylogenetics \cite{Ochman1987}, and new tools from synthetic biology \cite{Elowitz2000} and optogenetics or thermogenetics \cite{Bernstein2012} also suggest strategies for building molecular clocks on faster timescales. As an example of a possible synchronization mechanism, optogenetic methods (e.g., similar to \cite{konermann2013optical}) could be used to halt, and thus re-phase, a sub-population of polymerases at a light-dependent pause site in the template DNA, while another sub-population of polymerases reads through this pause site to maintain temporal continuity of recording; then the second population could be re-synchronized at an orthogonal light-dependent pause site while the first population reads through. Alternatively, some form of optogenetics could be used to directly write bit strings encoding time stamps into the synthesized DNA.  These strategies would require one or two, sufficiently strong global clock signals to be optically broadcast to all neurons. The optics involved would be comparatively simple: this could be done using far fewer optical fibers than would be required for fiber-based activity readout, for instance.

An analysis of the projected temporal resolution of molecular ticker-tapes as a function of polymerase biochemical parameters can be found in~\cite{glaser13}.
This work suggests that molecular ticker tapes require synchronization mechanisms if they are to record at \SI{<10}{\ms} temporal resolution for durations longer than seconds, even when \num{10000} templates per cell are recorded simultaneously, unless engineered polymerases with kinetic parameters beyond the limits of those found in nature can be developed.
Recording at lower temporal resolutions, however, appears feasible using naturalistic biochemical parameters, even in the absence of synchronization mechanisms.

Spatial resolution for molecular recording would naturally reach the single cell level. To determine which nucleic acid tape originated from which neuron, static cell-specific DNA barcoding could be used \cite{zador12} to associate the synthesized DNA strands with nodes in a topological connectome map obtained via DNA sequencing.  Fluorescence in-situ DNA sequencing (FISSEQ) \cite{Lee2013InSitu} on serially-sectioned or intact tissue (fixed post-mortem) \cite{chung2013structural} could be used to obtain explicit geometric information.

\subsubsection{Energy Dissipation}
% swap paragraphs?
\paragraph{Nucleotide metabolism}
DNA polymerization imposes a metabolic load on the cell.
Replication of the 3 billion bp human genome takes approximately eight hours in normally dividing cells, which equates to a nucleotide incorporation rate of \SI{\ca 100}{\kHz}.
Therefore, in order not to exceed the metabolic rates associated with normal genome replication, molecular ticker tapes operating at \SI{1}{\kHz} polymerization speed~\cite{kelman95} would be limited to approximately 100 simultaneously replicated templates per cell.
Even more recordings would be possible for RNA ticker tapes.
The mammalian cell polymerizes at least \num{1e11} NTPs per 16-hour cell cycle (data from HeLa cells)~\cite{jackson00}.
Therefore, \num{\ca 1,700} RNA tickertapes, each operating at \SI{1}{\kHz}, could be placed in a cell before generating a metabolic impact equal to that of the cell's baseline transcription rate.
While these comparisons to baseline physiological levels are reasonable guidelines, it is likely that a neuron can support higher metabolic loads associated with larger numbers of templates.
The maximal rate of neuronal aerobic respiration is \SI{\ca 5}{\femto\mole} of ATP minute via oxidative respiration (see the section on bio-luminescence). Assuming \num{\ca 1} ATP equivalent consumed per nucleotide incorporation, if neuronal metabolism were entirely dedicated to polymerization, it could support the incorporation of up to \num{6e9} nucleotides per minute, or \num{1e5} simultaneously replicated DNA templates at \SI{1}{\kHz}. % ATP *per* minute?

\paragraph{Power dissipation}
Normal DNA and RNA synthesis do not produce problematic energy dissipation and molecular tickertapes will likewise not be highly dissipative, at least in the regime where nucleic acid polymerization rates do not exceed those associated with genome replication or transcription.

\subsubsection{Volume Displacement}

The nucleus of a neuron occupies \SI{\ca 6}{\percent} of a neuron's volume ($(\SI{4}{\um})^3/(\SI{10}{\um})^3$).
Ticker tapes operating at \SI{1}{\kHz} with \num{10000} simultaneously replicated templates could record for \num{300} seconds before the total length of DNA synthesized equals the human genome length.
In the case of RNA polymerase II-based transcription, \SI{2.75}{\hour} of recording by \num{10000} recorders is required to reach the net transcript length in the cell.
Therefore, with appropriate mechanisms to fold/pack the nucleic acids generated by molecular ticker tapes, they would not impose unreasonable requirements on cellular volume displacement over minutes to hours.

\subsubsection{Conclusions and Future Directions}

Molecular recording of neural activity has the advantages of inherent scalability, single-cell precision, and low energy and volume footprints.
Making molecular recording work at temporal resolutions approaching \SI{1}{\kHz}, however, will require multiple new developments in synthetic biology, including protein engineering to create a fast polymerase (\SI{>1}{\kHz}) that strongly couples proxies for neural activity to nucleotide incorporation probabilities.
Synchronization mechanisms would likely be required to perform molecular recording at single-spike temporal resolution.
An attractive potential payoff for molecular approaches to activity mapping is the prospect of seamlessly combining---within a single brain---the readout of activity patterns with the readout of structural connectome barcodes~\cite{zador12}, transcriptional profiles \cite{Lee2013InSitu} (e.g., to determine cell type) or other (epi-)genetic signatures which are accessible via high-throughput nucleic acid sequencing.

\section{Discussion}

We have analyzed the physical constraints on scalable neural recording for selected modalities of measurement, data storage, data transmission and power harvesting.
Each analysis is based on assumptions -- about the brain, device physics, or system architecture -- which may be violated.
Understanding these assumptions can point towards strategies to work around them, and in some cases we have suggested possible directions for such workarounds.
Even valid assumptions about natural brains may be subject to modification through synthetic biology or external perturbation.
For example, methods for rapidly removing heat from the brain could work around our assumptions about its natural cooling capacity, supporting a range of highly dissipative recording modalities. Likewise, assumptions about the necessary bandwidth for data transmission could be relaxed if some information is stored locally and read out after the fact.

The analysis of physical limits illustrates challenges and opportunities~\cite{Dean2013} for technology development. While the opportunities can only be touched upon here, we anticipate further analyses which could explore design spaces in detail. Here we briefly summarize a sampling of new directions suggested by our analysis.

\paragraph{Electrical recording} The signal to noise ratio for a voltage sensing electrode imposes limits on the number of neurons per electrode from which signals can be detected and spike-sorted, likely requiring roughly one electrode per \num{100} neurons. To go beyond this, pure voltage sensing nodes could be augmented with the ability to directionally resolve distinct sources. For example, the 3D motion of a charged nanoparticle in an electric field, or of a dielectric nanoparticle in an electric field gradient, could be monitored at each recording site \cite{WoodPersonalCommunication}.

\paragraph{Optical recording} While light scattering creates severe limitations on optical imaging, embedded optical microscopies could overcome these limits. Embedded optical imaging systems with high signal multiplexing capacity would be desirable, to minimize the required number and size of implanted optical probes. 

One option might be to use time-of-flight information to multiplex many sensor readouts into a single optical fiber: this could potentially be realized using time-domain reflectometry techniques, commonly used to determine the positions of defects in optical fibers, coupled to neural activity sensors arranged along the fiber, which would modulate the fiber's local absorption or backscatter \cite{WoodPersonalCommunication}. Time-domain reflectometry techniques have already reached \SI{40}{\micro\meter} resolution in one dimension \cite{Lamy1981fi}.

Alternatively, novel fluorescent or bio-luminescent activity indicators could in principle relax the limits associated with light scattering, either by enabling efficient two-photon excitation at lower light dosages, or through all-infrared imaging schemes. Infrared bio-luminescence may be a particularly high-value target.

\paragraph{Delivery} For both embedded optical and electrical recording strategies, new delivery mechanisms will be needed to scale to whole mammalian brains. Many of the basic parameters for scalable delivery mechanisms are still unknown. For example, can a large number of ultra-thin nano-wire electrodes or optical fibers be delivered via the capillary network? Can cells such as macrophages engulf ultra-miniaturized microchips and transport them into brain tissue? Can the blood brain barrier be locally opened (e.g., using ultrasonic stimulation \cite{hynynen2005local}) to allow targeted delivery of recording probes?

\paragraph{Intrinsic acoustic signals} Nanometer-scale acoustic vibrations of cell membranes during the action potential are intrinsic signals which have not yet been exploited for in-vivo recording. Sensors could be embedded in or around tissue to transduce these acoustic vibrations into an electrical or optical readout. This could potentially allow recording at larger distances than the \SI{\ca 130}{\micro\meter} maximum recording radius for a voltage sensing node.

\paragraph{Data transmission through diffusive media} Unlike radio-frequency electromagnetics, infrared wavelengths may allow spatially multiplexed data transmissions from embedded recording devices, creating multiple independent channels by taking advantage of the stochasticity of light paths in strongly-scattering tissue. Alternatively, techniques are emerging to dynamically measure and invert the optical scattering matrix of a turbid medium, using pure-optical or hybrid techniques.

\paragraph{Ultrasound} Certain wavelengths of ultrasound exhibit potentially-favorable combinations of wavelength (spatial resolution), bandwidth (frequency) and attenuation compared to radio-frequency electromagnetics. Ultrasound could be used as a mechanism for powering and communicating with embedded local recording chips \cite{Seo2013}. Novel indicators \cite{ShapiroGasNanostructures} would likely need to be developed to perform neural activity imaging using pure ultrasound. Hybrid techniques such as photo-acoustic~\cite{filonov12} or ultrasound-encoded optical~\cite{wang12} microscopies are also of interest.

\paragraph{Molecular recording}  For local recording, molecular recording devices could sidestep power constraints on embedded electronics, at the cost of increased engineering complexity. For molecular recording to become practical at temporal resolutions approaching the millisecond scale, sophisticated protein and viral engineering would likely be required to create a high-speed polymerase-based recorder operating in the neuronal cytoplasm. This would also necessitate molecular synchronization or time-stamping mechanisms to maintain phasing between multiple polymerases within a single cell, as well as between different cells.

On the other hand, molecular recording devices operating at slower timescales (e.g., seconds) could perhaps be engineered via more conservative combinations of known mechanisms, such as CREB-mediated signaling to the nucleus \cite{Deisseroth2012}. In either case, the nucleic acid strands resulting from such molecular recorders could be space-stamped with cell-specific viral connectome barcodes for later readout by bulk sequencing. Alternatively, the ticker-tapes could be read within their anatomical contexts by in-situ sequencing, i.e., nucleic acid sequencing performed inside intact tissue \cite{Lee2013InSitu}.

\paragraph{Combining static and dynamic datasets} Combining dynamic activity information with static structural or molecular information could allow these datasets to disambiguate one another. For example, a diversity of colors for fluorescent activity indicators (e.g., BrainBow calcium imaging) could ease requirements on spatial separation of optical signals, and the color pattern across cells could be mapped post-mortem at single-cell resolution using in-situ microscopy. Generalizing further, in-situ sequencing enables the extraction of vast quantities of molecular data from fixed tissue, in effecting allowing observations with a palette of $4^N$ colors, where $N$ is the length of the nucleic acid polymer. It is still unclear, however, whether this exponential informational resource can be harnessed for the readout of dynamic activity information, e.g., using molecular ticker-tapes.

\paragraph{MRI} Current MRI is limited by its reliance on intrinsic hemodynamic contrast mechanisms and on rapidly diffusing aqueous protons. Indicators coupling neural activity to spin relaxation rates are being developed to move beyond hemodynamic contrast. In principle, MRI could also abandon the use of water protons as the signal sources, although this would pose significant implementation challenges: the use of non-diffusible spin species could allow micron-scale resolutions, spins with higher gyromagnetic ratios could give higher sensitivity, and accelerated spin relaxation times could enable higher temporal resolution. There may also be opportunities to apply spin manipulations analogous to those of MRI in the context of novel hybrid techniques.

\paragraph{Readout methods} New signal processing frameworks such as compressive sensing could reduce bandwidth requirements and inspire new microscope designs exploiting computational imaging principles. Techniques and technologies from electrical engineering and physics may play a key role. Fast readout mechanisms \cite{lauxtermann2001mega} applied to giga-pixel arrays (e.g., the 3.2 giga-pixel CCD camera planned for the Large Synoptic Survey Telescope, which will have \SI{\ca 1}{\second} readout time) might be adapted to large-scale electrical or optical recording methods. For example, linear photodiode arrays can achieve 70 kHz line readout rates \cite{PSeriesLinearArrayImager}, and many such linear arrays could be read out in parallel Hybrid optoelectronic methods used for imaging cells under high-speed flow \cite{goda2012high, goda2009serial, goda2008amplified, goda2009theory, mahjoubfar2011high} could inspire designs for even faster readouts (e.g., 10 MHz frame rates).

\paragraph{Alternative modalities} We have not considered all possible recording modalities.
For example, modalities like X-ray imaging have been used on live cells~\cite{moosmann13} and might find use in neural recording if suitable contrast agents could be devised.
X-rays interact with electron shells via photoelectric absorption and Compton scattering and with band structure in materials.
X-ray phosphors utilize substitutions in an ionic lattice to generate visible or UV light emission upon X-ray absorption~\cite{issler95}.
In principle, some of these mechanisms could be engineered as neural activity sensors, e.g., in an absorption-contrast mode suitable for tomographic reconstruction~\cite{larabell04}. While tissue damage due to ionizing radiation would ultimately be prohibitive (e.g., on a timescale of minutes \cite{WoodPersonalCommunication}), very brief experiments might still be possible.

Likewise, electron spin resonance (ESR) operates at $\ca$100$\times$ higher Larmor frequency compared to proton MRI, which improves polarizability of the spins.
Due to Pauli exclusion, use of this technique requires an indicator with unpaired electrons. These can be found in nitrogen vacancy diamond nano-crystals~\cite{horowitz12} (nano-diamonds), which are also sensitive to voltage~\cite{dolde11} and to magnetic fields~\cite{Hall2012}, and are amenable to optical control and fluorescent readout of the spin state (although the 2P cross-section of the $(N-V)^-$ center appears to be relatively low~\cite{Tse-Luen2007}).

\paragraph{Hybrid systems} New combinations of input, sensing, and readout modalities may be essential. Electrical or acoustic sensors could be used with optical \cite{sadek2010wiring} (e.g., fiber) or ultrasonic readouts and power supplies. An MRI machine could interact with embedded electrical circuits powered by the action potentials themselves \cite{JasanoffInductorsGrant}. Combining electrical recording with embedded optical microscopies or other spatially-resolved methods could work around the limits of purely electrical spike sorting. Arguably, the traditional notions of neural recording techniques or modalities should give way to a focus on system architectures which combine a wide range of technological primitives to satisfy otherwise-intractable engineering constraints.

Our goal has not been to pick winning technologies (which may have not yet been conceived), but to aid a multi-disciplinary community of researchers in analyzing the problem. 
The challenge of observing the real-time operation of entire mammalian brains requires a return to first principles, and a fundamental reconsideration of the architectures of neural recording systems.
We hope that knowledge of the constraints governing scalable neural recording will enable the invention of entirely new, transformative approaches.

\section{Acknowledgments}

We thank K. Esvelt for helpful discussions on bioluminescent proteins; D. Boysen for help on the fuel cell calculations; R.~Tucker and E.~Yablonovitch (\url{http://www.e3s-center.org}) for helpful discussions on the energy efficiency of CMOS; C.~Xu and C.~Schaffer for data on optical attenuation lengths; T. Dean and the participants in his CS379C course at Stanford/Google, including Chris Uhlik and Akram Sadek, for helpful discussions and informative content in the discussion notes (\url{http://www.stanford.edu/class/cs379c/}); and L.~Wood, R.~Koene, S.~Rezchikov, A.~Bansal, J.~Lovelock, A.~Payne, R.~Barish, N.~Donoghue, J.~Pillow, W.~Shih and P.~Yin for helpful discussions.

A.~Marblestone is supported by the Fannie and John Hertz Foundation fellowship.
D.~Dalrymple is supported by the Thiel Foundation.
K.~Kording is funded in part by the Chicago Biomedical Consortium with support from the Searle Funds at The Chicago Community Trust.
E.~Boyden is supported by the National Institutes of Health (NIH), the National Science Foundation, the MIT
McGovern Institute and Media Lab, the New York Stem Cell Foundation Robertson Investigator
Award, the Human Frontiers Science Program, and the Paul Allen Distinguished Investigator in
Neuroscience Award.
B.~Stranges, B.~Zamft, R.~Kalhor and G.~Church acknowledge support from the Office of Naval Research and the NIH Centers of Excellence in Genomic Science.
M.~Shapiro is supported by the Miller Research Institute, the Burroughs~Wellcome Career~Award~at~the~Scientific Interface and the W.M. Keck Foundation.

\printbibliography[notsubtype=hide]

\end{document}
